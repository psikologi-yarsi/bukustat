[
  {
    "objectID": "3_1_sentral.html",
    "href": "3_1_sentral.html",
    "title": "7  Ukuran Pemusatan Data",
    "section": "",
    "text": "7.1 Mean\nBayangkan, Anda sedang melakukan pengamatan terhadap hasil belajar di satu sekolah, misalnya pelajaran matematika dari 150 anak kelas X. Dari daftar nilai itu, Anda mempunyai informasi mengenai nilai dari setiap anak. Namun, bagaimana Anda akan mengatakan kepada khalayak, mengenai capaian nilai matematika dari ke-150 anak ini? Seberapa baik capaian tersebut? Untuk menjawabnya, Anda memerlukan satu perwakilan angka yang dapat dinilai sebagai baik, cukup atau buruk. Inilah yang disebut dengan konsep central tendency atau ukuran pemusatan data, yaitu satu angka yang menjadi ukuran sentral dari semua kumpulan angka yang diwakilinya. Terdapat tiga macam ukuran sentral, yaitu mean, median dan modus.\nMean (rerata) merupakan ukuran tendensi sentral yang paling umum digunakan karena mempertimbangkan semua nilai dalam distribusi. Mean diperoleh dengan cara menjumlahkan seluruh nilai data dibagi dengan banyaknya data. Mean sangat sensitif terhadap nilai ekstrem (outlier) yang dapat memengaruhi hasilnya secara signifikan.\nMisalnya kita memperoleh data dari 10 orang seperti di bawah ini:\nSetiap angka menggambarkan skor dari setiap orang. Berikut adalah cara menghitung mean dari data tersebut:\n\\[\n\\text{Mean} \\;=\\; \\frac{\\sum x}{n} \\;=\\; \\frac{4+4+6+6+7+4+7+3+5+4}{10} \\;=\\; \\frac{50}{10} \\;=\\; 5\n\\]",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "3_1_sentral.html#mean",
    "href": "3_1_sentral.html#mean",
    "title": "7  Ukuran Pemusatan Data",
    "section": "",
    "text": "4\n4\n6\n6\n7\n4\n7\n3\n5\n4",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "3_1_sentral.html#median",
    "href": "3_1_sentral.html#median",
    "title": "7  Ukuran Pemusatan Data",
    "section": "7.2 Median",
    "text": "7.2 Median\nMedian adalah nilai tengah dari data yang telah diurutkan dari yang terkecil ke terbesar. Jika jumlah data ganjil, median adalah nilai di posisi tengah; jika genap, median adalah rata-rata dari dua nilai tengah. Median berguna ketika data mengandung pencilan atau distribusinya tidak simetris, karena tidak terpengaruh oleh nilai-nilai ekstrem.\nMenggunakan data yang sama dengan yang di atas, maka untuk memperoleh nilai median kita perlu mengurutkan data dari yang paling kecil hingga yang paling besar. Nilai median merupakan nilai yang ada di tengah dari urutan data tersebut. Sehingga, dari data tersebut, dapat ditentukan bahwa nilai median adalah sebagai berikut:\n\n\n\n3\n4\n4\n4\n4\n5\n6\n6\n7\n7\n\n\n\nMengingat jumlah data yang diperoleh genap (10), maka nilai median dihitung dengan menghitung rata-rata dari dua nilai yang berada di tengah. Dalam hal ini, maka median dari data adalah:\n\\[\n\\text{Median} \\;=\\; \\frac{4+5}{2} \\;=\\; 4.5\n\\]",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "3_1_sentral.html#modus",
    "href": "3_1_sentral.html#modus",
    "title": "7  Ukuran Pemusatan Data",
    "section": "7.3 Modus",
    "text": "7.3 Modus\nModus adalah nilai yang paling sering muncul dalam suatu kumpulan data. Tidak seperti mean dan median, modus bisa digunakan pada data kategorikal dan dapat memiliki lebih dari satu nilai (bimodal atau multimodal). Modus cocok digunakan untuk mengidentifikasi nilai yang paling umum dalam suatu populasi atau kelompok.\nLangkah penting untuk memperoleh nilai modus dalam kelompok data adalah dengan membuat tabel distribusi frekuensi. Tabel ini berfungsi untuk mengidentifikasi nilai, skor, atau data apa yang paling sering muncul (frekuensi tertinggi). Masih menggunakan data yang sama dengan yang di atas, perlu dibuat tabel distribusi frekuensi sebagai berikut:\n\n\n\nNilai\nFrekuensi\n\n\n\n\n3\n1\n\n\n4\n4\n\n\n5\n1\n\n\n6\n2\n\n\n7\n2\n\n\n\nBerdasarkan pengelompokan data berdasarkan frekuensi kemunculannya yang ditampilkan pada tabel Distribusi frekuensi tersebut, maka kita dapat menentukan bahwa nilai Modus dari data adalah 4.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Tentang Penulis",
    "section": "",
    "text": "Dr. Sunu Bagaskara  \nadalah akademisi dan peneliti di bidang Psikologi dengan latar belakang pendidikan S1 hingga S3 di Fakultas Psikologi Universitas Indonesia. Ia berpengalaman mengajar Psikologi Sosial, Metode Penelitian Kuantitatif dan Statistik, serta Konstruksi Alat Ukur Psikologi. Minat penelitiannya mencakup kognisi sosial, psikologi lalu lintas, dan penerapan statistik dalam psikologi, dengan berbagai publikasi di jurnal ilmiah nasional dan internasional yang mencerminkan dedikasinya pada pengembangan ilmu psikologi dan keselamatan masyarakat.\n\n\nDr. Entin Nurhayati  \nberpengalaman mengajar kurang lebih selama 20 tahun. Pernah mengajar berbagai mata kuliah, seperti Faal, Psi Perkembangan, Psikodiagnosis (TAT/CAT, Rorschach) hingga beberapa tahun terakhir fokus di rumpun penelitian, khususnya mata kuliah metodologi penelitian dan statistik. Berdasar pengalaman mengajar ini serta membimbing penelitian mahasiswa, penulis memahami berbagai kesulitan yang dihadapi mahasiswa dalam memahami metopen dan statistik. Bersama sejawat, penulis berusaha melahirkan rangkaian buku praktis, agar mahasiswa dapat dengan mudah dan cepat memahami ilmu alat mengembangkan pengetahuan ini. Buku ini merupakan buku pertama yang dirancang untuk keperluan tersebut.\n\n\nSari Zakiah Akmal, Ph.D., Psikolog  \nadalah akademisi dan peneliti di bidang Psikologi Pendidikan. Ia lulusan dari program Sarjana dan Magister Profesi Psikologi Pendidikan, Fakultas Psikologi Universitas Indonesia dan program doktoral dari School of Applied Psychology, Griffith University, Australia. Sebagai dosen psikologi, ia pernah mengampu matakuliah terkait Metode Penelitian Kuantitatif, Statistik, Logika – Penulisan Ilmiah, Konstruksi Alat Ukur Psikologi, Asesmen Inteligensi, dan Pengembangan Diri dan Karier. Ia juga aktif dalam melakukan penelitian dan pengabdian masyarakat dengan fokus utama pada pengambilan keputusan karier, adaptabilitas karier, ketahanan akademik di kalangan mahasiswa, dan berbagai permasalahan terkait pendidikan siswa SMA/SMK dan mahasiswa di perguruan tinggi. Karya-karyanya telah dipublikasikan dalam berbagai jurnal akademik dan konferensi, mencerminkan komitmennya dalam mengembangkan penelitian dan pendidikan psikologi.\n\n\nTiti Sahidah, M.Psi, M.Sc., Ph.D., Psikolog  \nadalah pengajar di Fakultas Psikologi Universitas YARSI, Jakarta. Sejak memulai karier akademiknya pada tahun 2012, ia secara konsisten mengampu mata kuliah Psikometri dan Konstruksi Alat Ukur, yang menjadi bidang minat dan keahliannya. Ia melanjutkan studi doktoralnya di bidang Psikologi Medis di Erasmus MC, Rotterdam, Belanda. Di bawah bimbingan ahli dalam bidang psikometri, Titi menulis disertasi mengenai validitas, reliabilitas dan norma alat ukur EQ-5D-Y di Indonesia. Karya-karya publikasinya, khususnya dalam pengembangan alat ukur psikologi kesehatan yang dipresentasikan di berbagai konferensi dan diterbitkan di jurnal internasional, menjadikannya salah satu pakar dalam bidang pengukuran psikologi kesehatan di Indonesia.\n\n\nAswin Januarsjaf, S.Psi., M.M \nadalah akademisi dan praktisi di bidang Psikologi serta Manajemen Sumber Daya Manusia. Lulusan Psikologi Universitas Padjadjaran dan Magister Manajemen PPM School of Management ini memiliki pengalaman lebih dari dua dekade di berbagai industri, khususnya dalam bidang rekrutmen, asesmen, dan pengembangan SDM. Ia mendirikan Talentlytica, sebuah platform asesmen berbasis data, serta aktif mengajar statistik psikologi dan melatih topik manajemen SDM di berbagai institusi. Karya-karya dan inovasi perangkat asesmennya mencerminkan komitmennya untuk menghubungkan ilmu psikologi dengan praktik manajemen modern di Indonesia.",
    "crumbs": [
      "Tentang Penulis"
    ]
  },
  {
    "objectID": "1_pengantar.html",
    "href": "1_pengantar.html",
    "title": "PENGANTAR STATISTIK",
    "section": "",
    "text": "Statistik memainkan peran yang sangat penting dalam dunia psikologi, khususnya dalam konteks penelitian dan pengambilan keputusan berbasis data. Bab-bab awal buku ini bertujuan memberikan pemahaman dasar tentang konsep-konsep statistik yang relevan bagi mahasiswa psikologi. Mulai dari sejarah dan definisi statistik, pembahasan ini menjelaskan bagaimana perkembangan ilmu ini dipengaruhi oleh berbagai tokoh dan kebutuhan untuk memahami variasi dalam kehidupan manusia. Selain itu, bab-bab ini juga menguraikan prinsip-prinsip dasar seperti hubungan antara sampel dan populasi, serta peran parameter dan statistik dalam menginterpretasikan data penelitian.\nLebih jauh, buku ini membahas pentingnya statistik dalam penelitian psikologi, terutama untuk mengakomodasi kompleksitas perilaku manusia. Dengan menggunakan pendekatan deskriptif dan inferensial, statistik membantu peneliti menggambarkan data secara efektif sekaligus membuat generalisasi yang valid dari sampel ke populasi. Bab-bab ini dirancang untuk menjadi landasan kokoh bagi mahasiswa dalam memahami bagaimana statistik dapat digunakan untuk menjawab berbagai pertanyaan penelitian, mengatasi tantangan analisis data, dan mendukung validitas ilmiah psikologi sebagai disiplin ilmu.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 1. Pengertian & Sejarah Ringkas Statistik:\n\nMemahami definisi statistik dan konsep dasar yang meliputi parameter dan statistik.\nMengidentifikasi hubungan antara sampel dan populasi dalam konteks penelitian.\nMemahami peran statistik sebagai alat untuk mengorganisasi, merangkum, dan menginterpretasi informasi.\n\n\nBab 2. Statistik dalam Penelitian Psikologi:\n\nMenjelaskan peran statistik dalam mendukung psikologi sebagai ilmu ilmiah.\nMengevaluasi signifikansi statistik dalam memahami variasi perilaku dan membuat inferensi dari data penelitian.\n\n\nBab 3. Jenis-jenis Statistik: Deskriptif & Inferensial:\n\nMengidentifikasi perbedaan utama antara statistik deskriptif dan statistik inferensial, termasuk ruang lingkup dan tujuan keduanya.\nMemahami bagaimana kombinasi statistik deskriptif dan inferensial mendukung analisis data yang kuat, khususnya dalam ilmu perilaku dan sosial.",
    "crumbs": [
      "PENGANTAR STATISTIK"
    ]
  },
  {
    "objectID": "1_1_sejarah.html",
    "href": "1_1_sejarah.html",
    "title": "1  Pengertian & Sejarah Ringkas Statistik",
    "section": "",
    "text": "1.1 Definisi Statistik\nSejarah statistik bermula dari kebutuhan memahami variasi dalam ilmu hayati dan sosial (Gravetter & Wallnau, 2017). Variasi ini menjadi pusat perhatian dengan diperkenalkannya teori evolusi oleh Charles Darwin pada abad ke-19. Pionir seperti Francis Galton, sepupu Darwin, berusaha menguantifikasi pewarisan sifat biologis dan memunculkan konsep regresi terhadap rata-rata. Galton juga mengembangkan metode korelasi, yang menjadi dasar statistik modern. Selanjutnya, Karl Pearson memperkukuh landasan matematis statistik dengan memperkenalkan koefisien korelasi dan uji chi-kuadrat. Perkembangan ini melibatkan kajian biometrika dan genetik, dengan fokus pada pewarisan sifat yang dipengaruhi oleh gerakan eugenika.\nPada abad ke-20, Ronald Fisher memperkenalkan analisis varians dan metode eksperimental untuk memperluas penerapan statistik, terutama dalam ilmu perilaku (Cowles, 2000). Fisher, bersama Pearson, menekankan pentingnya inferensi statistik untuk mengatasi variasi alami. Pada saat yang sama, probabilitas berkembang sebagai dasar teoretis statistik, berakar dari upaya menjawab masalah dunia nyata seperti perjudian dan prediksi aktuarial. Normalisasi distribusi data, yang diperkenalkan oleh Lambert Quetelet, menjadi inti statistik inferensial. Hingga kini, statistik terus berkembang dengan mengintegrasikan metode baru untuk menjawab tantangan dalam berbagai disiplin ilmu.\nStatistik adalah kumpulan prosedur matematis yang digunakan untuk mengorganisasi, merangkum, dan menginterpretasi informasi (Gravetter & Wallnau, 2017). Dalam konteks penelitian, statistik membantu para peneliti untuk memahami hasil studi dan menyampaikan informasi tersebut secara akurat dan informatif. Statistik juga menyediakan teknik-teknik standar yang diakui dalam komunitas ilmiah sehingga hasil analisis dapat diinterpretasikan dengan konsistensi yang tinggi oleh peneliti lainnya.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pengertian & Sejarah Ringkas Statistik</span>"
    ]
  },
  {
    "objectID": "1_1_sejarah.html#sampel-dan-populasi",
    "href": "1_1_sejarah.html#sampel-dan-populasi",
    "title": "1  Pengertian & Sejarah Ringkas Statistik",
    "section": "1.2 Sampel dan Populasi",
    "text": "1.2 Sampel dan Populasi\nPopulasi adalah keseluruhan individu atau elemen yang menjadi fokus penelitian. Karena populasi biasanya terlalu besar untuk dianalisis secara langsung, peneliti memilih sampel, yaitu sekelompok individu yang mewakili populasi. Sampel bertujuan untuk menyederhanakan penelitian sambil tetap memungkinkan penarikan kesimpulan yang dapat digeneralisasi ke populasi. Hubungan antara sampel dan populasi bersifat dua arah: sampel diambil dari populasi, dan hasil penelitian pada sampel digeneralisasikan kembali ke populasi.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pengertian & Sejarah Ringkas Statistik</span>"
    ]
  },
  {
    "objectID": "1_1_sejarah.html#parameter-dan-statistik",
    "href": "1_1_sejarah.html#parameter-dan-statistik",
    "title": "1  Pengertian & Sejarah Ringkas Statistik",
    "section": "1.3 Parameter dan Statistik",
    "text": "1.3 Parameter dan Statistik\nParameter adalah nilai yang menggambarkan suatu karakteristik dari populasi, seperti rata-rata populasi, sedangkan statistik adalah nilai yang menggambarkan karakteristik dari sampel, seperti rata-rata sampel. Dalam penelitian, data yang diperoleh berasal dari sampel, sehingga statistik digunakan untuk memperkirakan parameter populasi. Proses ini menciptakan hubungan erat antara statistik sampel dan parameter populasi, yang menjadi dasar dari banyak prosedur statistik.\n\n\n\n\nCowles, M. (2000). Statistics in Psychology: An Historical Perspective. Psychology Press.\n\n\nGravetter, F. J., & Wallnau, L. B. (2017). Statistics for the Behavioral Sciences. Cengage Learning.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pengertian & Sejarah Ringkas Statistik</span>"
    ]
  },
  {
    "objectID": "1_2_stat_psiko.html",
    "href": "1_2_stat_psiko.html",
    "title": "2  Statistik dalam Penelitian Psikologi",
    "section": "",
    "text": "Statistik memegang peran penting dalam perkembangan ilmu psikologi, khususnya dalam upaya menjadikannya ilmu yang lebih ilmiah (Dancey & Reidy, 2017). Dimulai dengan prinsip determinisme yang mengasumsikan adanya keteraturan dalam alam, psikologi mencoba meniru pendekatan ilmu alam untuk memprediksi dan mengontrol perilaku. Hal ini dipopulerkan oleh tokoh seperti John B. Watson melalui behaviorisme yang mengedepankan studi eksperimental untuk mengendalikan variabel-variabel perilaku. Namun, pendekatan deterministik ini dipadukan dengan model probabilistik untuk mengakomodasi kompleksitas dan variasi yang melekat pada manusia.\nStatistik memungkinkan psikologi menangani variasi data dan membuat inferensi dari sampel ke populasi. Misalnya, Ronald Fisher mengembangkan desain eksperimen dan analisis varians (ANOVA) untuk membantu peneliti memahami hubungan sebab-akibat meskipun terdapat variabilitas. Selain itu, pengembangan metode korelasi oleh Francis Galton dan Karl Pearson membantu mengukur hubungan antar variabel, sementara analisis faktor yang diperkenalkan Charles Spearman mengidentifikasi faktor-faktor dalam kecerdasan (Coolican, 2014).\nDalam sejarahnya, statistik tidak hanya digunakan untuk menganalisis data, tetapi juga sebagai alat eksplorasi. Contohnya, metode analisis faktor sering digunakan untuk memetakan domain baru dalam psikologi sebelum eksperimen langsung dilakukan. Statistik juga membantu memperjelas perbedaan antara pendekatan eksperimental yang berfokus pada manipulasi variabel independen dan pendekatan korelasional yang mempelajari hubungan antar variabel dalam kondisi alami.\nSignifikansi statistik dalam psikologi tidak lepas dari pengaruh pionir seperti Gustav Fechner, yang memulai pendekatan kuantitatif untuk mengukur hubungan antara stimulus dan sensasi. Meskipun beberapa konsep awal seperti hukum psikofisik Fechner kini telah direvisi, kontribusinya mendasari metode eksperimental modern. Statistik memungkinkan peneliti psikologi untuk mengatasi tantangan dalam memahami kondisi manusia yang penuh variasi, sekaligus menyediakan dasar untuk menguji hipotesis secara objektif (Salsburg, 2002).\nStatistik juga memperkuat nilai-nilai keilmiahan psikologi, seperti keterbukaan terhadap koreksi, validasi empiris, dan kemampuan untuk memprediksi. Dengan demikian, statistik tidak hanya menjadi alat teknis tetapi juga kerangka filosofis yang mendukung psikologi sebagai ilmu yang dapat menjembatani antara determinisme dan kebebasan manusia, serta antara pandangan positivistik dan humanisme.\n\n\n\n\nCoolican, H. (2014). Research methods and statistics in psychology (hlm. 773). Psychology Press, Taylor & Francis Group.\n\n\nDancey, C. P., & Reidy, J. (2017). Statistics without maths for psychology (7th ed.). Pearson Education Limited.\n\n\nSalsburg, D. (2002). The lady tasting tea: how statistics revolutionized science in the twentieth century. Henry Holt; Company.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistik dalam Penelitian Psikologi</span>"
    ]
  },
  {
    "objectID": "1_3_jenis_stat.html",
    "href": "1_3_jenis_stat.html",
    "title": "3  Jenis-jenis Statistik: Deskriptif & Inferensial",
    "section": "",
    "text": "Statistik dapat dibagi menjadi dua kategori utama, yaitu statistik deskriptif dan statistik inferensial, yang masing-masing memiliki peran penting dalam analisis data. Statistik deskriptif (Bagian 3) digunakan untuk merangkum, mengorganisasi, dan menyederhanakan data mentah menjadi informasi yang lebih mudah dipahami. Teknik-teknik ini termasuk distribusi frekuensi, tabel, grafik, rata-rata (mean), median, mode, serta ukuran dispersi seperti variansi dan standar deviasi. Statistik deskriptif membantu memberikan gambaran umum tentang data tanpa membuat kesimpulan lebih luas.\nSebaliknya, statistik inferensial (Bagian 4) digunakan untuk membuat generalisasi tentang populasi berdasarkan data sampel. Teknik ini melibatkan analisis data dari sampel untuk menjawab pertanyaan penelitian dan menyimpulkan parameter populasi. Statistik inferensial sering menggunakan konsep probabilitas untuk memperkirakan sejauh mana kesimpulan dari sampel dapat mewakili populasi secara keseluruhan. Contoh aplikasinya termasuk uji hipotesis, analisis varians (ANOVA), dan regresi.\nPerbedaan utama antara keduanya terletak pada tujuan dan ruang lingkupnya. Statistik deskriptif fokus pada penggambaran data yang ada, sedangkan statistik inferensial fokus pada pengambilan keputusan atau prediksi berdasarkan data tersebut. Misalnya, statistik deskriptif digunakan untuk menghitung rata-rata usia partisipan dalam sebuah survei, sementara statistik inferensial menggunakan data tersebut untuk memprediksi rata-rata usia seluruh populasi.\nDalam praktiknya, kedua jenis statistik ini saling melengkapi. Statistik deskriptif menyediakan dasar untuk memahami data, sedangkan statistik inferensial memberikan kerangka untuk mengambil keputusan yang lebih luas. Sebagai contoh, analisis distribusi frekuensi dalam statistik deskriptif dapat menjadi langkah awal sebelum melakukan uji-t atau ANOVA dalam statistik inferensial.\nKombinasi kedua pendekatan ini mendukung analisis data yang kuat, terutama dalam ilmu perilaku dan sosial. Statistik deskriptif membantu menggambarkan data dengan jelas, sementara statistik inferensial memberikan justifikasi yang didukung oleh probabilitas untuk menjawab pertanyaan-pertanyaan penelitian yang kompleks. Hal ini menjadikan statistik alat yang tak tergantikan dalam proses penelitian ilmiah.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Jenis-jenis Statistik: Deskriptif & Inferensial</span>"
    ]
  },
  {
    "objectID": "1_latihan.html",
    "href": "1_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bab 1 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "2_persiapan.html",
    "href": "2_persiapan.html",
    "title": "PERSIAPAN DATA",
    "section": "",
    "text": "Bab ini akan membahas mengenai mengenali dan mempersiapkan data penelitian agar dapat diolah lebih lanjut secara statistik. Untuk menghasilkan analisis yang valid dan bermakna, peneliti perlu memahami jenis data yang dimiliki, melakukan proses pembersihan data secara sistematis, serta menjaga akuntabilitas dalam setiap tahap pengelolaan data. Tahapan ini bukan sekadar teknis, melainkan fondasi penting untuk memastikan bahwa hasil analisis benar-benar mencerminkan realitas yang diteliti.\nBab ini diawali dengan penjelasan tentang jenis data, termasuk cara mengidentifikasi tipe data serta prinsip dalam penamaan dan pengkodean variabel agar konsisten dan mudah diinterpretasikan. Selanjutnya, pembahasan berlanjut pada proses pembersihan data, yang mencakup analisis deskriptif awal, penanganan missing value, serta deteksi pencilan (outlier) yang dapat memengaruhi hasil analisis. Terakhir, bab ini menekankan pentingnya akuntabilitas data, yaitu tanggung jawab peneliti untuk mendokumentasikan, menyimpan, dan mengelola data secara transparan agar dapat dipertanggungjawabkan secara ilmiah. Dengan memahami dan menerapkan ketiga aspek ini, mahasiswa akan memiliki dasar yang kuat dalam mempersiapkan data untuk analisis statistik yang sahih dan terpercaya.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 4. Jenis Data:\n\nMengidentifikasi berbagai jenis data dalam konteks penelitian psikologi (nominal, ordinal, interval, rasio).\nMenerapkan prinsip penamaan dan pengkodean variabel secara konsisten dan sistematis.\nMemahami pentingnya kesesuaian antara jenis data dan teknik analisis statistik yang akan digunakan.\n\n\nBab 5. Pembersihan Data:\n\nMelakukan analisis deskriptif awal untuk mengevaluasi distribusi dan karakteristik dasar data.\nMengidentifikasi dan menangani data hilang (missing value) serta outlier secara tepat untuk memastikan keakuratan analisis lanjutan.\n\n\nBab 6. Akuntabilitas Data:\n\nMenjelaskan pentingnya pencatatan proses analisis statistik sebagai bentuk akuntabilitas ilmiah.\nMemahami pentingnya transparansi dalam meningkatkan kualitas dan integritas penelitian psikologi.",
    "crumbs": [
      "PERSIAPAN DATA"
    ]
  },
  {
    "objectID": "2_1_jenis_data.html",
    "href": "2_1_jenis_data.html",
    "title": "4  Jenis Data",
    "section": "",
    "text": "4.1 Mengidentifikasi Jenis Data\nSebelum data dianalisis, peneliti perlu memahami terlebih dahulu jenis data yang dimiliki. Pengklasifikasian data menjadi nominal, ordinal, interval, atau rasio akan menentukan teknik statistik apa yang tepat untuk digunakan. Selain itu, proses penamaan dan pengkodean variabel juga merupakan bagian penting dalam pengelolaan data yang baik. Pengkodean yang konsisten akan memudahkan dalam proses input data, analisis, maupun interpretasi hasil. Oleh karena itu, pengenalan jenis data dan cara mengelola variabel adalah fondasi penting sebelum melangkah ke tahap analisis statistik.\nData adalah kumpulan informasi berupa angka. Informasi ini biasanya dicatat sesuai dengan definisi yang diinginkan oleh peneliti. Sebagai contoh, data tinggi badan dicatat dalam centimeter per individu untuk anak-anak usia 0-10 tahun di Indonesia. Pada data tersebut terdapat data tinggi badan anak yang dapat diolah per individu. Di saat yang sama, terdapat pula kelompok data yang lebih besar, misalnya data tinggi badan untuk wilayah DKI Jakarta, Jawa Barat, dan wilayah lainnya yang kemudian dapat diolah dan dibandingkan per wilayah.\nData disebut dengan raw score (data mentah) apabila data tersebut adalah data langsung dari partisipan, tidak dimodifikasi, dan tidak dikonversi ke dalam nilai tertentu. Contoh data mentah:\nData dapat memberikan berbagai jenis informasi yang berbeda. Misalnya, informasi dasar seperti jenis kelamin, atau informasi lainnya yang lebih rumit seperti sikap atau perasaan seseorang. Terdapat berbagai jenis data di dalam penelitian psikologi, yaitu:",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Jenis Data</span>"
    ]
  },
  {
    "objectID": "2_1_jenis_data.html#mengidentifikasi-jenis-data",
    "href": "2_1_jenis_data.html#mengidentifikasi-jenis-data",
    "title": "4  Jenis Data",
    "section": "",
    "text": "ID Partisipan\nSkor Mentah Matematika (jumlah menjawab benar dari 50 soal)\nSkor Konversi dalam rentang 0-100 (raw/50 x 100)\n\n\n\n\n1\n25\n50\n\n\n2\n35\n70\n\n\n3\n45\n90\n\n\n4\n15\n30\n\n\n5\n37\n74\n\n\n\n\n\nData kategorikal atau nominal\nData kategorikal atau nominal adalah penunjuk karakteristik, label, atau golongan pada subjek. Sebagai contoh: jenis kelamin (laki-laki dan perempuan), daerah tempat tinggal (Jakarta, Bekasi, Bogor) dan lain sebagainya. Pemberian kode pada data-data ini hanya bersifat dummy dan tidak memiliki makna apa-apa secara statistik.\nData ordinal\nSebagai contoh, pada sebuah data penelitian, laki-laki diberikan kode 0 dan perempuan kode 1. Hal ini tidak berarti perempuan memiliki nilai yang lebih tinggi daripada laki-laki, begitu pula sebaliknya. Pemberian kode ini hanya untuk kemudahan pengolahan data dan tidak berarti secara statistik. Misalnya pada jenis kelamin, nilai rata-rata (mean) tidak dapat dihitung meski laki-laki disematkan angka 0 dan perempuan disematkan angka 1.\nData interval\nData interval adalah data yang memiliki makna, terdapat informasi mengenai jarak antara satu skor dengan skor lainnya namun tidak ada informasi mengenai seberapa mutlak nilai tersebut karena titik 0 tidak definitif. Misalnya suhu udara 0o Celsius tidak berarti ‘tidak ada temperatur’. Titik tersebut adalah definisi dari kondisi di mana air membeku. Perbedaan suhu antara 30oC dan 20o C adalah 10oC. Namun, tidak dapat dikatakan bahwa 20oC adalah dua kali lebih panas daripada 10oC karena suhu tidak memiliki titik 0oC yang definitif.\nData rasio\nData rasio adalah data yang memiliki titik 0 yang mutlak sehingga jarak antara satu skor dengan skor lainnya dapat dilakukan secara definit. Sebagai contoh, berat badan 100 kilogram dapat dikatakan lebih berat dua kali lipat dibandingkan seseorang dengan berat badan 50 kg.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Jenis Data</span>"
    ]
  },
  {
    "objectID": "2_1_jenis_data.html#penamaan-dan-pengkodean-datavariabel",
    "href": "2_1_jenis_data.html#penamaan-dan-pengkodean-datavariabel",
    "title": "4  Jenis Data",
    "section": "4.2 Penamaan dan Pengkodean Data/Variabel",
    "text": "4.2 Penamaan dan Pengkodean Data/Variabel\nLangkah awal yang penting dalam mempersiapkan data adalah memberikan nama atau kode variabel dengan jelas, mudah dipahami, dan mengikuti pola penamaan yang konsisten. Penamaan variabel yang baik tidak hanya memudahkan peneliti dalam mengolah data, tetapi juga memastikan bahwa data dapat dipahami dan digunakan kembali oleh peneliti lain, terutama ketika bekerja dengan data set yang besar atau di dalam tim.\nSebagai contoh, dalam sebuah penelitian yang melibatkan tiga kali pengambilan data menggunakan dua kuesioner – EQ-5D dan PedsQL – penamaan variabel dapat menggunakan kode yang menggambarkan waktu pengambilan data dan jenis instrumen secara ringkas dan jelas. Misalnya:\n\nData pengambilan pertama diberi kode B (Baseline)\nPengambilan kedua diberi kode R (Retest),\nDan pengambilan ketiga diberi kode F (Follow-up).\n\nSelanjutnya, nama variabel dibentuk dengan menggabungkan kode waktu dan nama instrumen. Dengan demikian:\n\nUntuk pengambilan pertama dengan EQ-5D, variabel dinamai BEQ5D, dan untuk PedsQL dinamai BPedsQL.\nUntuk pengambilan kedua: REQ5D dan RPedsQL.\nDan seterusnya untuk pengambilan ketiga.\n\nPola penamaan yang konsisten seperti ini akan mempermudah proses analisis, mengurangi risiko kesalahan, serta meningkatkan transparansi dan akuntabilitas, khususnya jika pengolahan data dilakukan oleh pihak lain atau pada proyek penelitian berskala besar.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Jenis Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html",
    "href": "2_2_cleaning.html",
    "title": "5  Pembersihan Data",
    "section": "",
    "text": "5.1 Melakukan Analisis Deskriptif\nSetelah data dikumpulkan dan diklasifikasikan, langkah selanjutnya adalah memastikan data tersebut layak untuk dianalisis. Proses ini dikenal sebagai data cleaning atau pembersihan data. Dalam tahap ini, peneliti melakukan analisis deskriptif awal untuk mendapatkan gambaran umum data, serta mengecek kemungkinan adanya missing valueatau outlier yang dapat memengaruhi hasil analisis. Pembersihan data bukan hanya soal menghapus skor-skor yang tidak wajar, tetapi juga tentang membuat keputusan yang tepat berdasarkan konteks penelitian. Dengan data yang bersih, hasil analisis akan menjadi lebih akurat dan dapat dipercaya.\nSetelah peneliti memberi nama variabel dan mengidentifikasi jenis data sesuai dengan sifat masing-masing variabel, langkah berikutnya adalah melakukan analisis deskriptif awal terhadap data. Analisis deskriptif ini bertujuan untuk memastikan kualitas data sebelum masuk ke tahap analisis lebih lanjut.\nBeberapa hal penting yang perlu diperhatikan dalam tahap ini antara lain:\nDengan melakukan analisis deskriptif ini secara teliti, peneliti dapat memastikan bahwa data yang akan dianalisis lebih lanjut sudah bersih, valid, dan siap untuk digunakan, sehingga hasil penelitian menjadi lebih akurat dan dapat dipertanggungjawabkan.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html#melakukan-analisis-deskriptif",
    "href": "2_2_cleaning.html#melakukan-analisis-deskriptif",
    "title": "5  Pembersihan Data",
    "section": "",
    "text": "Memeriksa sebaran skor\nPeneliti perlu melihat apakah nilai total skor, minimum, maksimum, rata-rata (mean), dan simpangan baku (standar deviasi) dari setiap variabel berada dalam rentang yang sesuai dengan instrumen alat ukur dan sampel yang diteliti. Hal ini membantu mendeteksi adanya kesalahan input data atau anomali yang tidak sesuai dengan ekspektasi.\nMemeriksa data hilang (missing values)\nIdentifikasi jumlah dan pola missing values pada setiap variabel sangat penting, karena dapat mempengaruhi validitas hasil analisis.\nMendeteksi nilai pencilan (outliers)\nNilai-nilai pencilan dapat mengindikasikan kesalahan pencatatan data atau variasi yang ekstrem di dalam sampel. Oleh karena itu, penting untuk mengidentifikasi outlier pada tahap awal, kemudian menentukan apakah nilai tersebut merupakan bagian dari variasi alami atau justru kesalahan yang perlu diperbaiki atau dikeluarkan dari analisis.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html#data-hilang",
    "href": "2_2_cleaning.html#data-hilang",
    "title": "5  Pembersihan Data",
    "section": "5.2 Data Hilang",
    "text": "5.2 Data Hilang\nTerdapat sejumlah hal yang perlu Anda lakukan sebelum memulai analisis utama terhadap data Anda. Hal pertama adalah memeriksa apakah terdapat missing data (data hilang). Data hilang terjadi ketika terdapat pernyataan yang tidak diisi oleh seseorang yang menjawab survei atau kuesioner Anda. Partisipan mungkin tidak menjawab salah satu item pada survei karena berbagai alasan. Mereka mungkin melewatkan sebuah pertanyaan, enggan menjawab pertanyaan tertentu, atau merasa bosan dan berhenti mengisi survei. Ketidaklengkapan jawaban pada satu atau beberapa item ini menimbulkan masalah dalam analisis.\nData hilang dapat dikategorikan menjadi (1) missing completely at random (MCAR), (2) missing at random (MAR), atau (3) missing not at random (MNAR) (Buuren, 2018).\n\nMissing completely at random (MCAR) berarti probabilitas sebuah data hilang sama besar untuk semua responden. Misalnya, seseorang secara acak melewatkan satu pertanyaan di survei Anda, sehingga data hilang itu benar-benar acak.\nJika probabilitas sebuah nilai hilang hanya sama dalam kelompok-kelompok tertentu yang didefinisikan oleh data yang teramati, maka data tersebut disebut missing at random (MAR). Karena itu, MCAR dan MAR adalah konsep yang saling terkait. Sebagai contoh, ditemukan bahwa responden yang tingkat stresnya tinggi cenderung melewatkan pertanyaan tentang tidur, mungkin karena merasa pertanyaan tersebut terlalu sensitif atau tidak relevan bagi mereka dalam kondisi stres.\nJika data hilang tidak memenuhi asumsi MCAR maupun MAR, maka disebut missing not at random (MNAR). Sebagai contoh, jika sejumlah besar peserta sengaja melewati satu pertanyaan tertentu pada survei, maka hal itu tidak terjadi secara acak. Kemungkinan ada alasan tertentu mengapa pertanyaan itu dilewati, misalnya karena pertanyaan kurang jelas, terlalu pribadi, atau tersembunyi di bagian bawah halaman.\n\nTerdapat sebuah uji untuk mengetahui apakah data hilang secara acak atau tidak, yaitu Little’s MCAR test. Secara sederhana, jika hasil uji tidak signifikan, maka data hilang kemungkinan terjadi secara acak. Sebaliknya, jika hasil uji signifikan, ada kemungkinan data hilang karena alasan sistematis atau tidak acak.\nLalu, apa yang bisa dilakukan peneliti untuk menangani data hilang? Secara umum, terdapat dua cara utama untuk menangani data hilang, yaitu:\n\nPenggantian dengan rata-rata (mean replacement). Dalam prosedur ini, Anda mengganti titik data yang hilang dengan nilai rata-rata variabel tersebut. Namun, teknik ini hanya disarankan jika data hilang secara acak (at random) dan proporsinya kurang dari 5% pada variabel yang bersangkutan.\nImputasi majemuk (multiple imputation). Teknik ini dilakukan dengan bantuan program statistik yang Anda gunakan, yang menganalisis pola data dan menetapkan nilai untuk variabel yang hilang pada kasus tertentu. Nilai ini didasarkan pada jawaban sebelumnya pada variabel terkait, serta jawaban tidak hilang pada variabel tersebut di kasus lain. Disarankan menggunakan metode ini jika data hilang secara acak dengan proporsi antara 5–10% dari total respons pada variabel tersebut.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html#data-pencilan",
    "href": "2_2_cleaning.html#data-pencilan",
    "title": "5  Pembersihan Data",
    "section": "5.3 Data Pencilan",
    "text": "5.3 Data Pencilan\nSalah satu hal yang perlu diperhatikan saat menganalisis data adalah pengaruhoutlier — yaitu data yang nilainya sangat tinggi atau sangat rendah dibandingkan data lainnya — terhadap hasil keseluruhan. Contohnya, jika Anda bertanya kepada orang-orang tentang berapa cangkir kopi yang mereka minum dalam sehari, sebagian besar jawabannya mungkin berkisar antara nol hingga empat cangkir. Sebaran ini disebut dengan sebaran jawaban yang normal. Namun, jika ada satu orang yang menjawab bahwa ia minum 17 cangkir kopi sehari, maka jawaban ini bisa dianggap sebagai outlier bila dibandingkan dengan partisipan lainnya.\nKita bisa mengasumsikan bahwa orang tersebut memang memiliki masalah dengan kafein atau mungkin salah memasukkan jawaban. Apa pun alasannya, jawaban ini bisa meningkatkan rata-rata (mean) konsumsi kopi dalam sampel, padahal sebetulnya jawaban ini tidak mewakili kebiasaan rata-rata peminum kopi.\nAda beberapa cara secara statistik untuk mengidentifikasi outlier dalam kumpulan data Anda (Tabachnick & Fidell, 2014):\n\nMengubah jawaban peserta untuk setiap variabel menjadi skor-z (z-score).\nSkor-z adalah transformasi dasar untuk membandingkan jawaban peserta dengan distribusi standar yang memiliki rata-rata 0 dan standar deviasi 1.\nJika suatu jawaban memiliki skor-z lebih besar dari +3.3 atau kurang dari -3.3, maka jawaban ini dianggap sebagai outlier.\nMemvisualisasikan data menggunakan box plot atau bar graph, lalu melihat secara langsung apakah ada data yang tampak menyimpang jauh. Lihat Gambar 5.1 untuk visualisasi dari outlier menggunakan box plot.\n\n\n\n\n\n\n\nGambar 5.1: Outlier dalam boxplot\n\n\n\nSetelah menemukan outlier, Anda punya dua pilihan (Dancey & Reidy, 2017):\n\nTetap menyertakan dalam analisis jika Anda menganggap outlier ini bukan kebetulan.\nMenghapus dari analisis jika outlier ini muncul karena alasan yang tidak valid, misalnya kesalahan input atau jawaban yang tidak realistis.\n\nJika jawaban outlier tersebut tidak masuk akal dalam konteks pertanyaan, atau terlalu ekstrem tanpa alasan yang jelas, maka sebaiknya dianggap sebagai jawaban tidak valid (spurious response) dan dihapus dari analisis. Namun, jika jawaban tersebut masih masuk akal atau hanya sedikit melampaui batas skor-z (± 3.3), Anda bisa mempertimbangkannya sebagai outlier yang valid dan tetap menyertakannya dalam analisis.\n\n\n\n\nBuuren, S. van. (2018). Flexible Imputation of Missing Data. CRC Press.\n\n\nDancey, C. P., & Reidy, J. (2017). Statistics without maths for psychology (7th ed.). Pearson Education Limited.\n\n\nTabachnick, B. G., & Fidell, L. S. (2014). Using Multivariate Statistics (6th ed.). Pearson Education Limited.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_3_akuntabilitas.html",
    "href": "2_3_akuntabilitas.html",
    "title": "6  Akuntabilitas Data",
    "section": "",
    "text": "Salah satu langkah penting yang sering kali terabaikan dalam pengolahan data statistik adalah mencatat secara sistematis setiap proses analisis yang dilakukan. Pencatatan ini merupakan inti dari prinsip akuntabilitas, yaitu kemampuan untuk mempertanggungjawabkan seluruh proses analisis kepada diri sendiri maupun komunitas ilmiah (Gelfond dkk., 2014). Dengan memiliki catatan lengkap, peneliti lain dapat menelusuri, memverifikasi, atau mereplikasi prosedur yang telah dilakukan, sehingga penelitian menjadi lebih transparan dan dapat dipercaya.\nPentingnya akuntabilitas semakin terasa ketika terjadi hasil yang tidak sesuai harapan atau tampak tidak wajar. Dalam situasi ini, dokumentasi proses analisis akan sangat membantu peneliti untuk menelusuri kembali langkah-langkah yang telah diambil, mengidentifikasi potensi kesalahan (seperti pengkodean yang keliru, pemilihan teknik analisis yang tidak tepat, atau salah input data), dan memperbaikinya tanpa harus mengulang seluruh proses dari awal.\nPencatatan proses analisis dapat dilakukan melalui script atau syntax di perangkat lunak statistik. Tools ini memungkinkan setiap langkah (misalnya transformasi variabel dan filtering data) untuk terekam secara otomatis dan dapat dijalankan ulang. Penggunaan syntax bukan hanya efisien, tetapi juga menciptakan audit trail yang sangat berguna dalam kerja tim atau revisi laporan.\nJika perangkat lunak yang digunakan tidak menyimpan jejak analisis secara otomatis, maka pencatatan manual menjadi penting. Hal ini bisa dilakukan dengan menuliskan setiap prosedur analisis dalam dokumen pendamping, seperti di Microsoft Word, Google Docs, atau aplikasi pencatat lain. Format catatan sebaiknya mencakup: nama file data, langkah-langkah analisis yang dilakukan, alasan memilih teknik tertentu, serta ringkasan hasil yang diperoleh.\nMenjaga akuntabilitas bukan hanya menunjukkan profesionalisme peneliti, tetapi juga mendukung prinsip replikasi, transparansi, dan validitas ilmiah. Dokumentasi proses analisis dianggap sebagai bagian dari etika penelitian, terutama di era open science. Oleh karena itu, mahasiswa perlu membiasakan diri untuk tidak hanya fokus pada hasil akhir, tetapi juga menaruh perhatian serius pada proses yang ditempuh untuk sampai ke hasil tersebut.\n\n\n\n\nGelfond, J. A. L., Klugman, C. M., Welty, L. J., Heitman, E., Louden, C., & Pollock, B. H. (2014). How to Tell the Truth with Statistics: The Case for Accountable Data Analyses in Team-based Science. Journal of translational medicine & epidemiology, 2.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Akuntabilitas Data</span>"
    ]
  },
  {
    "objectID": "2_latihan.html",
    "href": "2_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bab 1 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "PERSIAPAN DATA",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "3_deskriptif.html",
    "href": "3_deskriptif.html",
    "title": "STATISTIK DESKRIPTIF",
    "section": "",
    "text": "Setelah data dikumpulkan dan dipersiapkan, langkah selanjutnya dalam proses analisis adalah memahami karakteristik umum dari data tersebut. Bab ini membahas tentang statistik deskriptif, yaitu serangkaian teknik yang digunakan untuk merangkum, menyederhanakan, dan menyajikan data mentah menjadi informasi yang lebih mudah dipahami. Statistik deskriptif tidak berfokus pada pengambilan keputusan atau generalisasi, melainkan pada penggambaran pola, kecenderungan, dan sebaran data yang ada.\nBab ini terdiri dari tiga bagian utama. Pertama, pembahasan mengenai ukuran pemusatan data (central tendency), mencakup mean (rata-rata), median, dan modus yang menggambarkan nilai pusat dari sekumpulan data. Kedua, penjelasan tentang sebaran data (dispersi) yang mencakup rentang, varians, dan standar deviasi untuk memahami seberapa jauh data menyebar dari pusatnya. Terakhir, akan dibahas mengenai bentuk distribusi data, termasuk konsep simetri, skewness, dan kurtosis, yang penting untuk mengetahui apakah data berdistribusi normal atau memiliki penyimpangan tertentu.",
    "crumbs": [
      "STATISTIK DESKRIPTIF"
    ]
  },
  {
    "objectID": "3_2_dispersi.html",
    "href": "3_2_dispersi.html",
    "title": "8  Ukuran Penyebaran Data",
    "section": "",
    "text": "8.1 Range\nSetelah mengetahui nilai pusat dari suatu data melalui ukuran pemusatan data, langkah berikutnya adalah memahami seberapa jauh data menyebar dari nilai pusat tersebut. Ukuran penyebaran data, atau dispersi, memberikan informasi penting tentang variasi atau keragaman dalam kumpulan data. Dua set data bisa memiliki mean yang sama, tetapi penyebarannya bisa sangat berbeda, dan perbedaan ini dapat memengaruhi cara interpretasi data secara keseluruhan. Dalam sub-bab ini, akan dibahas beberapa ukuran utama penyebaran, yaitu rentang (range), standar deviasi, dan varians, yang membantu menggambarkan tingkat homogenitas atau heterogenitas suatu data secara lebih mendalam.\nRange, atau rentang data, adalah selisih antara nilai tertinggi dengan nilai terendah dalam sebuah set data. Range menunjukkan seberapa lebar sebaran nilai dalam data, namun karena hanya mempertimbangkan dua nilai ekstrem, ukuran ini sangat sensitif terhadap outlier dan tidak menggambarkan variasi data secara keseluruhan. Meskipun demikian, range tetap berguna sebagai gambaran awal tentang sebaran data.\nUntuk dapat memahami fungsi range dalam memahami set data, mari kita pelajari kasus berikut ini. Misalnya, seorang peneliti memiliki data nilai tugas mata pelajaran Matematika dari 3 kelas yang berbeda:\nPertanyaan penting mengenai data tersebut adalah apakah ketiga kelas tersebut memperoleh capaian belajar yang sama. Jika hanya mengandalkan nilai rata-rata, maka ketiga kelas tersebut akan tampak sama karena memiliki nilai rata-rata yang sama, yaitu 5. Padahal jika dilihat ke perolehan nilai individual, terlihat berbeda. Nilai range pada data dapat membantu kita untuk menggambarkan seberapa berbeda dan bervariasi data yang dimiliki dan makna variasi tersebut dalam memahami setiap poin data. Untuk itu, kita perlu menghitung selisih skor terbesar dengan skor terkecil untuk setiap data kelas.\n\\[\n\\begin{aligned}\nRange\\; kelas\\; A &= nilai\\; tertinggi - nilai\\; terendah = 7 -3 = 4\\\\\nRange\\; kelas\\; B &= nilai\\; tertinggi - nilai\\; terendah = 8 -2 = 6\\\\\nRange\\; kelas\\; C &= nilai\\; tertinggi - nilai\\; terendah = 6 -2 = 4\n\\end{aligned}\n\\]\nDari hasil penghitungan, dapat dilihat bahwa kelas B memiliki lebar data yang paling besar, artinya terdapat perbedaan atau variasi yang lebih besar di dalam kelas tersebut dibandingkan dengan kelas-kelas lainnya. Sebaliknya, kelas C memiliki rentang skor paling kecil di antara ketiganya. Dalam hal ini, satu skor yang sama (misalnya, 4) dapat dimaknai secara berbeda berdasarkan nilai range tiap kelas.\nSatu hal yang perlu diingat adalah bahwa variasi skor yang digambarkan dalam range hanya menunjukkan perbedaan antara yang mendapatkan nilai paling tinggi dan yang mendapatkan nilai paling rendah. Dari nilai range tersebut kita tidak memiliki informasi mengenai seberapa besar ukuran variabilitas (atau seberapa bervariasi) sebuah set data. Untuk mendapatkan gambaran ini, kita menggunakan ukuran penyebaran data berikutnya, yaitu varians.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_2_dispersi.html#range",
    "href": "3_2_dispersi.html#range",
    "title": "8  Ukuran Penyebaran Data",
    "section": "",
    "text": "Kelas A\n\n4\n4\n6\n6\n7\n4\n7\n3\n5\n4\n\n\nKelas B\n\n2\n6\n6\n7\n7\n8\n4\n4\n3\n3\n\n\nKelas C\n\n6\n5\n6\n4\n5\n6\n4\n4\n5\n5",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_2_dispersi.html#varians",
    "href": "3_2_dispersi.html#varians",
    "title": "8  Ukuran Penyebaran Data",
    "section": "8.2 Varians",
    "text": "8.2 Varians\nVarians (s2) adalah ukuran penyebaran data yang menunjukkan seberapa jauh nilai-nilai dalam suatu kumpulan data menyimpang dari nilai mean. Varians dihitung dengan menjumlahkan kuadrat selisih setiap nilai (X) terhadap mean (\\(\\bar{x}\\)), kemudian dibagi dengan jumlah data (N) (untuk populasi) atau jumlah data dikurangi satu (n-1) (untuk sampel). Dapat juga ditulis sebagai:\n\\[\ns^2 = \\frac{\\sum (X - \\bar{x})^2}{N - 1}\n\\]\nHasil varians menunjukkan “rata-rata kuadrat penyimpangan” dari mean, sehingga semakin besar nilai varians, semakin besar pula variasi data di sekitar mean. Dengan kata lain, varians juga menggambarkan homogenitas data, di mana semakin kecil varians maka semakin kecil perbedaan antar poin data, dan sebaliknya semakin besar varians semakin besar pula perbedaan antar poin data.\nSebagai ilustrasi, misalnya terdapat data set skor skala sikap dari dua kelompok partisipan yang berbeda (a & b), dengan masing-masing sebaran data sebagai berikut:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKelompok a\n\n6\n6\n6\n6\n7\n7\n7\n7\n7\n8\n8\n8\n\\(\\bar{x}\\)=6.9\n\n\nKelompok b\n\n2\n3\n5\n5\n6\n6\n6\n7\n9\n9\n10\n12\n\\(\\bar{x}\\)=6.7\n\n\n\nUntuk dapat memperoleh nilai varians, kita perlu menghitung simpangan atau selisih dari setiap data poin terhadap mean kemudian dikuadratkan, seperti pada Tabel 8.1.\n\n\nTabel 8.1: Perhitungan simpangan dan varians dua kelompok\n\n\n\n\n\n\n\n  \n\n\n\nKelompok a\nKelompok b\n\n\nSkor (X)\nSimpangan (X − x̄)\nKuadrat simpangan (X − x̄)²\nSkor (X)\nSimpangan (X − x̄)\nKuadrat simpangan (X − x̄)²\n\n\n\n\n6\n-0.9\n0.81\n2\n-4.7\n22.09\n\n\n6\n-0.9\n0.81\n3\n-3.7\n13.69\n\n\n6\n-0.9\n0.81\n5\n-1.7\n2.89\n\n\n6\n-0.9\n0.81\n5\n-1.7\n2.89\n\n\n7\n0.1\n0.01\n6\n-0.7\n0.49\n\n\n7\n0.1\n0.01\n6\n-0.7\n0.49\n\n\n7\n0.1\n0.01\n6\n-0.7\n0.49\n\n\n7\n0.1\n0.01\n7\n0.3\n0.09\n\n\n7\n0.1\n0.01\n9\n2.3\n5.29\n\n\n8\n1.1\n1.21\n9\n2.3\n5.29\n\n\n8\n1.1\n1.21\n10\n3.3\n10.89\n\n\n8\n1.1\n1.21\n12\n5.3\n28.09\n\n\nΣ(X − x̄)²\n6.92\nΣ(X − x̄)²\n92.68\n\n\ns² =  Σ(X − x̄)² N − 1 \n0.6\ns² =  Σ(X − x̄)² N − 1 \n8.4\n\n\n\n\n\n\n\nDari hasil penghitungan tersebut, kita menemukan perbedaan varians yang cukup besar antara kedua kelompok, meskipun mean keduanya tidak jauh berbeda. Hal ini menandakan bahwa kelompok b memiliki sebaran data yang jauh lebih beragam (heterogen) dibandingkan kelompok a (lihat Gambar 8.1). Oleh karena itu, pemaknaan terhadap nilai mean tiap kelompok juga berbeda, relatif terhadap variansnya masing-masing.\nVarians memiliki fungsi penting dalam memahami keragaman atau variasi data di sekitar nilai rata-rata. Informasi ini sangat berguna untuk a) menilai konsistensi data (misalnya, dua kelompok dengan rata-rata yang sama bisa memiliki varians yang berbeda; kelompok dengan varians kecil berarti anggotanya lebih homogen.) dan b) dasar dari analisis statistik lanjutan, di mana varians menjadi komponen penting dalam berbagai teknik analisis, seperti standar deviasi, analisis varians (ANOVA), uji-t, dan regresi. Dengan demikian, varians bukan hanya ukuran penyebaran, tetapi juga alat untuk mengevaluasi struktur dan kualitas data sebelum melakukan interpretasi atau pengambilan keputusan lebih lanjut.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_2_dispersi.html#standar-deviasi",
    "href": "3_2_dispersi.html#standar-deviasi",
    "title": "8  Ukuran Penyebaran Data",
    "section": "8.3 Standar Deviasi",
    "text": "8.3 Standar Deviasi\nStandar deviasi (s) adalah ukuran penyebaran data yang menunjukkan rata-rata penyimpangan (deviasi) nilai data dari mean. Ukuran ini memberikan gambaran yang lebih intuitif tentang seberapa besar variasi dalam data. Artinya, semakin besar standar deviasi, semakin lebar sebaran data dari nilai tengahnya. Standar deviasi diperoleh dengan mengambil akar kuadrat dari varians:\n\\[\ns = \\sqrt{s^2}\n\\]\nDengan menggunakan data pada pembahasan varians, kita dapat menghitung standar deviasi dari data tiap kelompok, yaitu:\nKelompok a: \\(s = \\sqrt{s^2} = \\sqrt{0.6} = 0.77\\)\nKelompok a: \\(s = \\sqrt{s^2} = \\sqrt{8.4} = 2.90\\)\nHasil penghitungan standar deviasi di atas memperkuat pemahaman bahwa Kelompok a lebih homogen (s = 0,77) dibandingkan Kelompok b yang lebih bervariasi (s = 2,90). Meskipun informasi ini serupa dengan yang diperoleh dari varians (0,6 vs 8,4), standar deviasi lebih mudah diinterpretasikan karena satuannya kembali ke satuan asli data, tidak dalam bentuk kuadrat seperti varians. Dengan demikian, standar deviasi memberikan gambaran yang lebih intuitif tentang jarak rata-rata setiap data dari mean, sehingga lebih sering digunakan dalam pelaporan dan interpretasi hasil statistik.\n\n\n\n\n\n\nGambar 8.1: Visualisasi data dengan: a) varians kecil & b) varians besar",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html",
    "href": "3_3_distribusi.html",
    "title": "9  Bentuk Distribusi Data",
    "section": "",
    "text": "9.1 Kurva Normal\nSetiap nilai dalam sekumpulan data memiliki frekuensi kemunculan yang berbeda-beda; nilai ekstrem biasanya muncul lebih jarang, sedangkan nilai yang mendekati mean lebih sering muncul. Pola ini membentuk distribusi data, yang jika digambarkan dalam grafik seperti poligon frekuensi, akan membentuk kurva. Pada distribusi yang ideal, yaitu distribusi normal, kurva berbentuk lonceng (bell-shaped) dan simetris di sekitar nilai ukuran pemusatan data seperti mean atau median. Namun, pada kenyataannya, data bisa saja miring (skewed) jika nilai-nilai terkonsentrasi di satu sisi, atau memiliki kurtosis jika kurvanya lebih runcing atau lebih datar dari distribusi normal. Pemahaman tentang bentuk distribusi ini penting karena banyak analisis statistik, terutama yang bersifat inferensial, mengasumsikan bahwa data terdistribusi normal. Untuk itu, bagian-bagian berikut akan membahas lebih lanjut mengenai kurva normal, skewness, kurtosis, dan z-score sebagai alat untuk menstandarkan data.\nSeperti telah disampaikan sebelumnya, distribusi data dapat dikatakan normal jika kurvanya membentuk lonceng dan simetris. Pada distribusi data yang demikian, frekuensi dari setiap nilai data tersebar secara simetris antara yang terletak di atas tendensi sentral dan yang di bawah tendensi sentral. Data tersebar 50% di atas dan 50% di bawah tendensi sentral, dengan frekuensi yang semakin mengecil pada nilai data yang semakin ekstrem, baik yang kecil maupun yang besar (lihat Gambar 9.1).\nPada kurva normal, tiga pengukuran data terpusat (mean, median, dan modus) berada pada satu titik atau nilai yang relatif sama. Dari Gambar 9.1 dapat lebih terlihat jelas bahwa 50% data tersebar di atas tendensi sentral dan 50% data tersebar di bawah tendensi sentral, di mana semakin jauh dari tendensi sentral maka semakin sedikit frekuensinya.\nUntuk menjawab masalah-masalah tertentu, kita perlu mencari besaran frekuensi sebuah nilai atau cakupan nilai berdasarkan sebaran data yang ada. Misalnya, kita ingin memperkirakan ada berapa jumlah mahasiswa yang nilai ujiannya antara 70 dan 85, di mana nilai mean = 80 SD = 5, dan N = 250. Dengan memanfaatkan informasi standar deviasi (s), proporsi frekuensi data pada distribusi normal dapat kita hitung berdasarkan luas area dalam kurva. Gambar 9.2 menunjukkan besaran proporsi frekuensi pada data dilihat dari luas area berdasarkan nilai standar deviasi.\nDari kurva normal yang ditampilkan pada Gambar 3.3, kita dapat mengetahui bahwa setiap belahan kurva dibagi menjadi 4 area berdasarkan standar deviasi, yaitu (1) mean – +/- 1 SD (34,1%), 1 SD – 2 SD (13,6%), 2 SD – 3 SD (2,1%), dan &gt; 3 SD (0,1%). Artinya, proporsi terbanyak dari data adalah nilai-nilai yang mendekati mean, dan sebaliknya, semakin jauh dari mean maka proporsinya semakin kecil, terutama untuk nilai-nilai ekstrem (&gt; +/- 3 SD).\nProporsi frekuensi data dengan nilai antara mean hingga 1 SD di bawah mean adalah sebesar 34,1% dari keseluruhan data, begitu juga dengan yang 1 SD di atas mean. Selanjutnya, jika kita ingin mengetahui proporsi frekuensi data antara mean hingga 2 SD di atas mean, maka kita menjumlahkan proporsi (mean – 1 SD) + (1 SD – 2 SD) = 34,1% + 13,6% = 47,7%.\nDengan demikian, untuk menjawab pertanyaan sebelumnya (proporsi mahasiswa yang memperoleh nilai ujian 70 (X1) – 85 (X2) dengan mean = 80, SD = 5, dan N = 250), maka kita menghitungnya dengan mencari besaran SD dari batas bawah dan atas rentang skor:\nX1 - mean = 70 – 80 = -10; karena SD = 5, maka skor 70 = -2SD\nX2 - mean = 85 – 80 = 5; karena SD = 5, maka skor 85 = 1SD\nMaka, proporsi X1 – X2 = (proporsi -2SD – mean) + (proporsi mean – 1SD)\n= (13,6% + 34,1%) + (34,1%)\n= 81,8%\nSehingga, jumlah mahasiswa dengan skor antara 70 – 85 = 81,8% × 250 orang = 204 orang (pembulatan).",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#kurva-normal",
    "href": "3_3_distribusi.html#kurva-normal",
    "title": "9  Bentuk Distribusi Data",
    "section": "",
    "text": "Gambar 9.1: Bentuk kurva normal\n\n\n\n\n\n\n\n\n\n\n\nGambar 9.2: Proporsi sebaran data pada kurva normal",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#skewness",
    "href": "3_3_distribusi.html#skewness",
    "title": "9  Bentuk Distribusi Data",
    "section": "9.2 Skewness",
    "text": "9.2 Skewness\nData pada sampel yang diambil dari populasi penelitian tidak selalu terdistribusi secara normal. Sebaran yang tidak normal ini seringnya terjadi pada sekumpulan data yang memiliki nilai ekstrem (outlier) yang proporsinya cukup jauh melebihi data yang tersebar secara normal. Besarnya outlier ini membuat sebaran data seolah-olah terpusat di bawah nilai tengah, atau sebaliknya terpusat di atas nilai tengah.\nJika data yang tersebar secara normal membentuk kurva berbentuk lonceng yang simetris, maka data yang tidak normal tersebut bisa membentuk kurva yang miring atau juling (skewed). Arah kemiringan (skewness) kurva bergantung pada besaran frekuensi data yang menyimpang dari nilai tengah. Jika frekuensi nilai yang berada di bawah mean jauh lebih kecil daripada frekuensi nilai di atas mean, maka puncak kurva akan condong ke kanan, yang disebut sebagai skew negatif (Gambar 10.1 (a)). Sebaliknya, jika frekuensi nilai yang berada di bawah mean jauh lebih besar daripada frekuensi nilai di atas mean, maka puncak kurva akan condong ke kiri, yang disebut sebagai skew positif (Gambar 10.1 (b)).\n\n\n\n\n\n\n\n\n\n\n\n(a) Skew negatif\n\n\n\n\n\n\n\n\n\n\n\n(b) Skew positif\n\n\n\n\n\n\n\nGambar 9.3: Distribusi skewed\n\n\n\nTerdapat dua cara yang umum digunakan untuk mengetahui arah kemiringan (skewness) dari sebuah distribusi data, yaitu dengan (a) menggunakan rumus Pearson, dan (b) membandingkan nilai-nilai ukuran pemusatan data.\n\nRumus Pearson:\n\\[\n\\text{Skewness} = 3 \\times \\frac{\\text{Mean} - \\text{Median}}{\\text{SD}}\n\\]\nJika hasil penghitungan nilai skewness adalah positif, maka disebut dengan kurva skewed positif. Jika hasil hitungnya negatif, maka disebut dengan kurva skewed negatif. Apabila hasil hitungnya (mendekati) nol, maka disebut dengan kurva normal. Tidak ada angka pasti, seberapa dekat dengan nol dapat disebut sebagai kurva normal, tetapi kesepakatan umum adalah ± 0,5.\nMembandingkan nilai ukuran pemusatan data\nJika mean lebih kecil dari median, maka bentuk distribusinya adalah skewed negatif. Sebaliknya, jika mean lebih lebih besar dari median, maka bentuk distribusinya adalah skewed positif. Namun, jika mean, median, dan modus berada pada satu titik yang relatif sama atau berdekatan, maka bentuk distribusi datanya adalah normal (Gambar 9.4).\n\n\n\n\n\n\n\nGambar 9.4: Skewness data berdasarkan lokasi tendensi sentral",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#kurtosis",
    "href": "3_3_distribusi.html#kurtosis",
    "title": "9  Bentuk Distribusi Data",
    "section": "9.3 Kurtosis",
    "text": "9.3 Kurtosis\nKurtosis adalah seberapa berbeda bentuk kurva dari kurva normal, dilihat dari seberapa tebal-tipis bagian ekor dari kurva tersebut. Selain dilihat dari ekor kurva, kurtosis sebenarnya juga menunjukkan seberapa tajam bentuk puncak dari kurva. Terdapat tiga bentuk kurtosis, yaitu normal, ekor panjang (heavy-tailed) dan ekor pendek (light-tailed) (Gambar 9.5).\n\n\n\n\n\n\nGambar 9.5: Visualisai kurtosis dalam distribusi data\n\n\n\nKurtosis pada distribusi data yang normal adalah ketika ekor kurva tersebar secara proporsional dan puncak kurva tidak terlalu curam maupun terlalu landai. Jika nilai kurtosis &gt; 0, maka kurva akan memiliki ekor yang pendek dan puncak yang curam, menandakan data menumpuk di nilai-nilai sekitar nilai tengah. Sebaliknya, jika nilai kurtosis &lt; 0 maka ekor kurva akan memanjang dan puncaknya melandai, yang artinya hampir seluruh nilai memiliki frekuensi atau jumlah kejadian yang serupa. Kurva yang menunjukkan baik ekor panjang maupun ekor pendek menandakan bahwa data tidak terdistribusi secara normal.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#z-score",
    "href": "3_3_distribusi.html#z-score",
    "title": "9  Bentuk Distribusi Data",
    "section": "9.4 Z-Score",
    "text": "9.4 Z-Score\nz-score, yang dikenal juga dengan nama skor baku, menunjukkan posisi sebuah skor dibandingkan dengan rata-rata dalam satuan standar deviasi. Dengan kata lain, z-score menyatakan posisi relatif suatu nilai (X) dalam distribusi data. z = nol berarti nilai tersebut tepat di mean, z-score negatif menandakan bahwa nilainya lebih rendah dari mean, dan z-score positif berarti nilainya di atas mean. z-score dapat dihitung dengan cara:\n\\[\nz = \\frac{X - \\bar{x}}{\\text{SD}}\n\\]\nTujuan utama penggunaan z-score adalah untuk menstandarkan data, sehingga memungkinkan perbandingan antar nilai dari distribusi yang berbeda. Sebagai analogi, kita tidak bisa menilai mana yang memiliki nilai yang lebih tinggi antara nilai dua mata uang yang berbeda (misalnya, 10 Rupee India dengan 10 Baht Thailand) tanpa mengkonversinya ke dalam satuan mata uang yang sama atau standar.\nDalam hal data, dua nilai dari distribusi yang berbeda (misalnya, nilai 8 pada subtes aritmatika dan nilai 8 pada subtest logika numerikal) bisa jadi memiliki posisi yang berbeda dalam distribusi data masing-masing, sehingga tidak dapat dibandingkan secara langsung. Oleh karena itu, kedua nilai tersebut perlu ditransformasi ke z-score agar memiliki satuan yang sama untuk dapat dibandingkan.\nz-score juga bermanfaat dalam mendeteksi outlier, serta dalam berbagai analisis statistik lanjutan seperti uji hipotesis dan analisis distribusi normal. Karena z-score mengubah data ke skala yang seragam, ia menjadi alat penting dalam interpretasi dan generalisasi hasil penelitian.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Daftar Pustaka",
    "section": "",
    "text": "Buuren, S. van. (2018). Flexible imputation of missing data.\nCRC Press.\n\n\nCoolican, H. (2014). Research methods and statistics in\npsychology (p. 773). Psychology Press, Taylor & Francis Group.\n\n\nCowles, M. (2000). Statistics in psychology: An historical\nperspective. Psychology Press.\n\n\nDancey, C. P., & Reidy, J. (2017). Statistics without maths for\npsychology (7th ed.). Pearson Education Limited.\n\n\nGelfond, J. A. L., Klugman, C. M., Welty, L. J., Heitman, E., Louden,\nC., & Pollock, B. H. (2014). How to tell the\ntruth with statistics: The case for accountable data analyses in\nteam-based science. Journal of Translational Medicine &\nEpidemiology, 2.\n\n\nGravetter, F. J., & Wallnau, L. B. (2017). Statistics for the\nbehavioral sciences. Cengage Learning.\n\n\nSalsburg, D. (2002). The lady tasting tea: How statistics\nrevolutionized science in the twentieth century. Henry Holt;\nCompany.\n\n\nTabachnick, B. G., & Fidell, L. S. (2014). Using multivariate\nstatistics (6th ed.). Pearson Education Limited.",
    "crumbs": [
      "Daftar Pustaka"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik untuk Psikologi dan Ilmu Sosial",
    "section": "",
    "text": "Selamat Datang!\nAlhamdulillah, akhirnya buku Statistik untuk Psikologi dan Ilmu Sosial ini bisa sampai ke tangan Anda. Buku ini lahir dari pengalaman sehari-hari di kelas, saat mendampingi mahasiswa yang sering kali merasa “alergi” begitu mendengar kata statistik. Padahal, kalau dipahami dengan cara yang tepat, statistik bukan sesuatu yang menakutkan. Justru ia adalah alat yang sangat membantu kita untuk membaca, memahami, dan menjelaskan fenomena psikologi secara lebih objektif.\nDalam buku ini, kami mencoba menyajikan konsep-konsep statistik dengan bahasa yang sederhana, runtut, dan dekat dengan dunia psikologi. Setiap bab tidak hanya berisi teori, tetapi juga contoh nyata serta latihan soal yang bisa membantu pembaca melatih pemahaman. Harapannya, buku ini bisa menjadi jembatan agar mahasiswa lebih percaya diri ketika berhadapan dengan data penelitian.\nKami menyadari buku ini masih jauh dari sempurna. Kritik dan saran dari para pembaca tentu sangat kami nantikan, agar pada edisi-edisi berikutnya buku ini bisa semakin baik.\nAkhir kata, semoga buku ini tidak hanya menjadi pegangan dalam belajar, tetapi juga menjadi sahabat yang menemani perjalanan Anda meneliti, menulis, dan memahami psikologi dengan lebih ilmiah.\nJakarta, Agustus 2025\n\nTim Penulis",
    "crumbs": [
      "Selamat Datang!"
    ]
  },
  {
    "objectID": "4_1_parametrik.html",
    "href": "4_1_parametrik.html",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "",
    "text": "10.1 Asumsi Parametrik\nDalam statistik inferensial, metode analisis dapat dibedakan menjadi dua kelompok besar, yaitu statistik parametrik dan statistik non-parametrik. Pemilihan metode ini berpengaruh pada validitas hasil analisis karena masing-masing memiliki asumsi dan prinsip kerja yang berbeda. Meskipun keduanya bertujuan untuk menarik kesimpulan dari data sampel ke populasi, perbedaan pendekatan dapat memengaruhi akurasi dan kekuatan analisis.\nMetode analisis parametrik bekerja dengan optimal jika data memiliki distribusi normal (lihat Bab 9). Karena berbagai prosedur parametrik—seperti estimasi parameter dan pengujian hipotesis—mengandalkan sifat distribusi normal, penyimpangan yang besar dari normalitas dapat membuat hasil analisis menjadi bias atau kurang akurat. Oleh karena itu, sebelum menggunakan metode parametrik, peneliti perlu memeriksa apakah data mendekati distribusi normal melalui uji statistik maupun pemeriksaan visual.\nPemeriksaan melalui metode visual bisa dilihat berdasarkan kurva sebaran data. Salah satu yang paling umum digunakan adalah grafik histogram. Jika histogram tampak seperti lonceng, maka distribusi data tersebut dikatakan normal. Sebaliknya, jika terdapat kemiringan sehingga kurva terlihat jelas tidak simetris, maka data tidak terdistribusi dengan normal (lihat Gambar 10.1).\nMetode pengujian statsitik dapat menjadi cara yang paling akurat untuk menentukan normalitas distribusi data. Terdapat dua uji statistik yang cukup umum digunakan digunakan dalam konteks riset ilmu sosial, yaitu Kolmogorov-Smirnov (KS) dan Shapiro-Wilk (SW). Sejumlah studi mengungkapkan bahwa uji SW lebih andal dibanding KS karena memiliki daya uji (power) yang lebih tinggi dalam mendeteksi berbagai bentuk penyimpangan dari normalitas, baik akibat skewness maupun kurtosis, pada hampir semua ukuran sampel dan jenis distribusi (M. A., 2014; Razali & Wah, 2011; Yap & Sim, 2011). Oleh karena itu, tes SW lebih disarankan untuk digunakan dalam pengujian normalitas distribusi data.\nData yang memenuhi asumsi parametrik dapat dianalisis lebih lanjut dengan statistik parametrik, sedangkan data yang tidak memenuhi asumsi dianalisis dengan menggunakan teknik statistik non-parametrik. Konsekuensi hasil analisisnya adalah pada generalisasi hasil analsis data. Pada statistik parameterik — karena data sampel terdistibusi normal — maka data tersebut dianggap mewakili populasi, sehingga setiap hasil analisis data tersebut dapat digenerasilasikan kepada populasinya. Dengan kata lain, hasil analisis data dianggap mencerminkan populasinya. Sedangkan jika data tidak memenuhi asumsi dan kemudian dianalisis dengan statistik non-parametrik, maka hasilnya tidak dapat disebut mencerminkan populasi, melainkan hanya menggambarkan sekelompok partisipan penelitian tersebut.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_1_parametrik.html#asumsi-parametrik",
    "href": "4_1_parametrik.html#asumsi-parametrik",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "",
    "text": "(a) Distribusi normal\n\n\n\n\n\n\n\n\n\n\n\n(b) Distribusi tidak normal\n\n\n\n\n\n\n\nGambar 10.1: Kurva distribusi data",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_1_parametrik.html#metode-parametrik",
    "href": "4_1_parametrik.html#metode-parametrik",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "10.2 Metode Parametrik",
    "text": "10.2 Metode Parametrik\nMetode parametrik adalah pendekatan analisis statistik yang mendasarkan perhitungannya pada parameter populasi yang diestimasi dari data sampel, seperti mean, varians, dan standar deviasi. Metode ini beroperasi di bawah asumsi bahwa data berasal dari populasi dengan distribusi tertentu, umumnya distribusi normal, sehingga sifat-sifat distribusi tersebut dapat digunakan untuk membangun model matematis yang akurat. Proses analisis dalam metode parametrik biasanya melibatkan penggunaan rumus yang memanfaatkan parameter-parameter ini untuk menghitung ukuran efek, menguji hipotesis, atau membuat estimasi terhadap populasi.\nKelebihan utama metode parametrik adalah presisi dan kekuatan statistik yang tinggi, artinya metode ini lebih mampu mendeteksi perbedaan atau hubungan yang benar-benar ada dalam data, asalkan asumsi normalitas terpenuhi. Hal ini karena informasi yang digunakan berasal dari seluruh nilai data, bukan hanya peringkat atau kategori. Akan tetapi, jika asumsi distribusi dilanggar—misalnya data tidak normal atau mengandung outlier ekstrem—maka metode parametrik bisa menghasilkan estimasi yang bias dan kesimpulan yang menyesatkan. Oleh sebab itu, pengujian asumsi, khususnya normalitas, menjadi langkah krusial sebelum memilih metode ini.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_1_parametrik.html#metode-non-parametrik",
    "href": "4_1_parametrik.html#metode-non-parametrik",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "10.3 Metode Non-Parametrik",
    "text": "10.3 Metode Non-Parametrik\nMetode non-parametrik adalah pendekatan analisis statistik yang tidak bergantung pada asumsi bentuk distribusi tertentu dan tidak secara langsung menggunakan parameter populasi seperti mean atau varians dalam perhitungannya. Metode ini sering digunakan ketika data tidak memenuhi asumsi normalitas atau ketika data yang dimiliki berskala ordinal dan nominal, di mana informasi yang tersedia hanya berupa urutan atau kategori. Dalam praktiknya, metode non-parametrik banyak mengandalkan peringkat (ranking) untuk melakukan perbandingan antar kelompok atau mengukur hubungan antar variabel.\nKelebihan metode non-parametrik terletak pada fleksibilitasnya terhadap bentuk data —metode ini tetap dapat digunakan meskipun data terdistribusi miring, memiliki outlier, atau jumlah sampel relatif kecil. Selain itu, metode ini lebih “aman” digunakan jika peneliti tidak yakin bahwa asumsi parametrik terpenuhi. Namun, konsekuensi dari fleksibilitas ini adalah kekuatan statistik yang umumnya lebih rendah dibandingkan metode parametrik ketika asumsi normalitas sebenarnya terpenuhi. Artinya, metode non-parametrik mungkin kurang sensitif dalam mendeteksi perbedaan atau hubungan yang ada, sehingga hasil yang signifikan memerlukan efek yang lebih besar atau jumlah sampel yang lebih banyak.\nRangkuman perbandingan secara umum antara kedua metode analisis (parametrik vs. non-parametrik) dapat dilihat di Tabel 10.1.\n\n\n\nTabel 10.1: Perbandingan metode statistik parametrik dan non-parametrik\n\n\n\n\n\n\n\n\n\n\nAspek\nStatistik Parametrik\nStatistik Non-parametrik\n\n\n\n\nAsumsi utama\nData berasal dari populasi yang berdistribusi normal.\nTidak memerlukan asumsi distribusi normal\n\n\nJenis data yang cocok\nData berskala interval atau rasio\nData berskala ordinal atau nominal, atau data interval/rasio yang tidak normal\n\n\nKelebihan\nMemiliki daya statistik lebih tinggi jika asumsi normalitas terpenuhi\nLebih fleksibel terhadap pelanggaran asumsi dan dapat digunakan pada data yang tidak normal\n\n\nKekurangan\nData harus memenuhi asumsi-asumsi yang ketat\nUmumnya memiliki kekuatan statistik lebih rendah\n\n\nKonsekuensi praktis\nMemberikan hasil yang lebih presisi pada data yang memenuhi asumsi normalitas\nMemberikan hasil yang kurang sensitif dalam mendeteksi perbedaan atau hubungan yang ada\n\n\n\n\n\n\n\n\n\n\nM. A., H. B. O., Notobroto. (2014). Perbandingan tingkat konsistensi normalitas distribusi metode kolmogorov-smirnov, lilliefors, shapiro-wilk, dan skewness-kurtosis. Jurnal Biometrika dan kependudukan, 3, 127–135.\n\n\nRazali, N., & Wah, Y. (2011). Power comparisons of Shapiro-Wilk , Kolmogorov-Smirnov , Lilliefors and Anderson-Darling test. Journal of Statistical Modeling and Analytics, 2, 21–33.\n\n\nYap, B. W., & Sim, C. H. (2011). Comparisons of various types of normality tests. Journal of Statistical Computation and Simulation, 81, 2141–2155. https://doi.org/10.1080/00949655.2010.520163",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_2_power.html",
    "href": "4_2_power.html",
    "title": "11  Statistical Power",
    "section": "",
    "text": "Statistical power, atau tingkat sensitivitas, adalah kemampuan suatu pengujian statistik untuk mendeteksi adanya efek suatu variabel terhadap variabel lain atau perbedaan antar kelompok jika efek atau perbedaan tersebut memang benar-benar ada. Studi dengan power yang tinggi memiliki peluang besar untuk menemukan efek, bahkan jika efek tersebut kecil, selama efek itu memang nyata. Sebaliknya, studi dengan power yang rendah cenderung gagal mendeteksi perbedaan atau hubungan yang sebenarnya ada, dan hasil signifikansinya lebih rentan dipengaruhi oleh error, baik yang bersifat sistematik maupun acak.\nKonsep ini sangat penting karena berkaitan langsung dengan risiko melakukan kesalahan dalam pengujian hipotesis, khususnya kesalahan tipe II (β). Dalam statistik, terdapat dua jenis kesalahan:\n\nKesalahan tipe I (α): Menolak hipotesis nol padahal sebenarnya tidak ada perbedaan atau hubungan.\nKesalahan tipe II (β): Gagal menolak hipotesis nol padahal sebenarnya ada perbedaan atau hubungan.\n\nPower penelitian dihitung sebagai 1 – β, sehingga semakin kecil β, semakin besar power. Misalnya, power sebesar 80% berarti penelitian memiliki peluang 80% untuk mendeteksi perbedaan atau hubungan yang sebenarnya ada di populasi.\nMenentukan tingkat power biasanya dilakukan sebelum pengambilan data agar peneliti dapat memperkirakan ukuran sampel yang memadai. Tingkat power yang umum digunakan adalah 80%, 90%, atau 95%. Penentuan ini mempertimbangkan beberapa faktor utama: ukuran sampel, besaran efek (effect size), tingkat signifikansi (α), dan variabilitas data. Dengan perencanaan yang baik, peneliti dapat meminimalkan risiko kesalahan tipe II dan meningkatkan peluang memperoleh hasil yang akurat dan dapat diandalkan.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>*Statistical Power*</span>"
    ]
  },
  {
    "objectID": "4_3_hipotesis.html",
    "href": "4_3_hipotesis.html",
    "title": "12  Pengujian Hipotesis",
    "section": "",
    "text": "Secara etimologi, hipotesis berasal dari dua kata, yaitu hipo yang berarti “di bawah” dan thesa yang berarti “kebenaran”. Secara harfiah, hipotesis dapat diartikan “di bawah kebenaran” atau kebenaran sementara yang masih harus diuji kesahihannya. Dalam penelitian, hipotesis adalah jawaban sementara terhadap pertanyaan penelitian yang disusun berdasarkan teori, temuan penelitian sebelumnya, maupun logika dan akal sehat peneliti.\nHipotesis dibuat untuk dikonfirmasikan kepada data lapangan; jika terkonfirmasi, maka hipotesis diterima sebagai kebenaran berdasarkan data penelitian. Dalam analisis statistik, terdapat dua macam hipotesis yang wajib dipahami:\n\nHipotesis nol (H₀), yaitu hipotesis yang menyatakan ketiadaan perbedaan antara dua keadaan atau ketiadaan hubungan antar variabel yang diamati. Sebagai contoh:\n\nTidak ada perbedaan tingkat konsentrasi belajar antara kelas A yang diberi sarapan dan kelas B yang tidak diberi sarapan.\nTidak ada hubungan antara tingkat pemahaman bahaya merokok dengan kecenderungan merokok di kalangan remaja perokok.\n\nHipotesis alternatif (H₁), yaitu hipotesis yang menyatakan adanya perbedaan atau hubungan antar variabel yang diamati. Contohnya:\n\nTerdapat perbedaan gaya parenting berdasarkan tingkat pendidikan orang tua.\nTerdapat hubungan antara tingkat keyakinan pada akhirat dengan ketaatan menjalankan sholat lima waktu.\n\n\nHipotesis juga dapat diklasifikasikan berdasarkan tujuan dan teknik analisis data yang dibutuhkan:\n\nHipotesis deskriptif: digunakan pada penelitian yang hanya melibatkan satu variabel. Misalnya: “Terdapat kesadaran yang tinggi pada remaja usia belasan terhadap merek sabun ‘X’”. Analisisnya meliputi statistik deskriptif, tendensi sentral, dispersi, dan uji normalitas.\nHipotesis komparatif: digunakan untuk membandingkan dua atau lebih keadaan. Misalnya: “Terdapat perbedaan konsentrasi belajar antara kelas A yang diberi sarapan dan kelas B yang tidak”. Analisisnya dapat menggunakan uji-t atau ANOVA untuk data parametrik, dan uji Wilcoxon atau Kruskal-Wallis untuk data non-parametrik.\nHipotesis asosiatif: digunakan untuk menilai keterhubungan antara dua peristiwa atau variabel. Misalnya: “Terdapat hubungan antara tingkat ekspose isu di media sosial dengan literasi masyarakat terhadap isu tersebut”. Analisisnya dapat menggunakan korelasi Pearson untuk data parametrik, dan korelasi Spearman untuk data non-parametrik.\n\nDalam pengujian hipotesis, arah pengujian menentukan di sisi mana peneliti mencari bukti untuk menolak hipotesis nol. Uji satu arah (one-tailed test) digunakan jika hipotesis alternatif memprediksi arah perbedaan atau hubungan yang diharapkan, misalnya rata-rata nilai kelas A lebih tinggi daripada kelas B. Seluruh tingkat signifikansi ditempatkan pada satu sisi distribusi sehingga lebih sensitif untuk mendeteksi perbedaan ke arah tersebut, namun tidak dapat menangkap perbedaan ke arah sebaliknya.\nSebaliknya, uji dua arah (two-tailed test) digunakan jika hipotesis alternatif tidak menentukan arah perbedaan, misalnya hanya ingin mengetahui apakah dua rata-rata berbeda tanpa memprediksi lebih tinggi atau lebih rendah. Dalam uji ini, tingkat signifikansi dibagi pada kedua sisi distribusi sehingga dapat mendeteksi perbedaan di kedua arah. Pemilihan jenis uji sebaiknya ditentukan sejak awal penelitian untuk menjaga validitas hasil.\nProses pengujian hipotesis dilakukan secara sistematis. Langkah pertama adalah merumuskan H₀ dan H₁, kemudian menetapkan tingkat signifikansi (α), umumnya 0,05, untuk membatasi risiko kesalahan tipe I. Selanjutnya, peneliti memilih uji statistik yang sesuai dengan jenis data dan desain penelitian, lalu mengumpulkan dan menganalisis data untuk mendapatkan nilai statistik uji. Nilai ini dibandingkan dengan nilai kritis atau diinterpretasikan menggunakan p-value. Jika p-value ≤ α, maka H₀ ditolak; jika p-value &gt; α, maka H₀ tidak dapat ditolak. Penjelasan lebih lanjut mengenai signifikansi dan p-value akan diuraikan pada Bab 13.\nPenting dipahami bahwa menolak H₀ tidak berarti H₀ salah secara mutlak, melainkan data memberikan bukti cukup untuk mendukung H₁ dalam batas risiko yang ditetapkan. Sebaliknya, gagal menolak H₀ tidak berarti H₀ benar, tetapi menunjukkan bukti yang ada belum cukup untuk mendukung H₁. Dengan pemahaman ini, pengujian hipotesis menjadi alat penting untuk menarik kesimpulan ilmiah yang terukur, transparan, dan dapat dipertanggungjawabkan.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pengujian Hipotesis</span>"
    ]
  },
  {
    "objectID": "4_4_signifikansi.html",
    "href": "4_4_signifikansi.html",
    "title": "13  Signifikansi Statistik & p-value",
    "section": "",
    "text": "13.1 Signifikansi\nSignifikansi statistik dan p-value merupakan dua konsep yang saling terkait dan sangat penting dalam pengujian hipotesis. Keduanya membantu peneliti menentukan apakah hasil penelitian cukup kuat untuk menolak hipotesis nol atau tidak. Pemahaman yang tepat mengenai kedua konsep ini tidak hanya mencegah kesalahan interpretasi, melainkan juga memastikan bahwa keputusan yang diambil mempertimbangkan konteks penelitian, ukuran efek, dan statistical power, sehingga hasil yang diperoleh lebih akurat dan bermakna secara praktis.\nDalam statistik, signifikansi merujuk pada tingkat keyakinan bahwa suatu hasil penelitian bukan semata-mata disebabkan oleh kebetulan. Tingkat signifikansi biasanya dinyatakan dengan simbol α (alpha), yang mewakili probabilitas melakukan kesalahan tipe I — yaitu menolak hipotesis nol (H₀) padahal H₀ benar. Nilai α yang umum digunakan adalah 0,05 (5%) atau 0,01 (1%). Pemilihan nilai ini merupakan batas yang ditetapkan peneliti sebelum analisis, untuk mengontrol risiko salah menolak H₀.\nTingkat signifikansi berfungsi sebagai ambang batas untuk memutuskan apakah bukti yang diperoleh dari data cukup kuat untuk menolak H₀. Semakin kecil nilai α, semakin ketat kriteria yang digunakan, sehingga peluang membuat kesalahan tipe I menjadi lebih kecil, tetapi sekaligus meningkatkan risiko kesalahan tipe II (gagal menolak H₀ padahal H₀ salah). Oleh karena itu, penentuan nilai α harus mempertimbangkan keseimbangan antara ketelitian statistik dan kebutuhan praktis penelitian, termasuk konteks bidang ilmu, risiko kesalahan yang dapat ditoleransi, dan implikasi keputusan yang akan diambil berdasarkan hasil analisis (Moore dkk., 2018) .\nIlmu sosial umumnya menggunakan tingkat signifikansi 0,05 karena fenomena yang diteliti sering kali melibatkan variabilitas tinggi dan faktor-faktor yang sulit dikendalikan sepenuhnya, seperti perilaku, persepsi, atau interaksi sosial (Gravetter & Wallnau, 2017). Variabilitas ini membuat data cenderung mengandung banyak noise, sehingga menetapkan ambang yang terlalu ketat (misalnya 0,01) dapat meningkatkan risiko kesalahan tipe II — gagal mendeteksi efek yang sebenarnya ada. Dengan α = 0,05, peneliti di ilmu sosial masih memiliki keseimbangan yang cukup baik antara menghindari kesalahan tipe I dan tetap sensitif terhadap efek yang relevan.\nSebaliknya, di ilmu eksak seperti fisika, kimia, atau teknik, eksperimen biasanya dilakukan dalam kondisi yang lebih terkontrol, dengan variabel-variabel yang dapat diukur secara presisi dan replikasi yang konsisten. Karena kontrol yang ketat ini, tingkat kesalahan acak (random) lebih rendah, sehingga dimungkinkan untuk menetapkan α lebih kecil (misalnya 0,01 atau 0,001) tanpa mengorbankan terlalu banyak sensitivitas. Di bidang ini, kesalahan tipe I sering kali memiliki konsekuensi besar — misalnya, klaim penemuan efektivitas obat baru — sehingga diperlukan standar bukti yang lebih kuat sebelum menolak H₀.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Signifikansi Statistik & *p-value*</span>"
    ]
  },
  {
    "objectID": "4_4_signifikansi.html#p-value",
    "href": "4_4_signifikansi.html#p-value",
    "title": "13  Signifikansi Statistik & p-value",
    "section": "13.2 p-value",
    "text": "13.2 p-value\np-value atau probability value adalah probabilitas mendapatkan hasil pengamatan, atau hasil yang lebih ekstrem, jika H₀ benar. Nilai ini digunakan untuk menilai apakah hasil yang diperoleh cukup kuat untuk menolak H₀ berdasarkan tingkat signifikansi yang ditetapkan.\nAturan pengambilan keputusan:\n\np-value ≤ α → Hasil signifikan secara statistik, H₀ ditolak, artinya data memberikan bukti yang cukup untuk mendukung H₁.\np-value &gt; α → Hasil tidak signifikan secara statistik, H₀ tidak ditolak, artinya data tidak memberikan bukti yang cukup untuk menolak H₀.\n\nMari kita gunakan ilustrasi sederhana untuk dapat lebih memahami mengenai konsep p-value ini. Bayangkan Anda sedang bermain permainan melempar koin yang menurut klaim teman Anda adalah koin normal (punya peluang 50% muncul gambar dan 50% muncul angka). Jika diterjemahkan ke dalam istilah hipotesis, maka:\n\nHipotesis nol (H₀): Koin itu seimbang (tidak curang)\nHipotesis alternatif (H₁): Koin itu tidak seimbang (curang)\n\nLalu Anda melempar koin 10 kali dan hasilnya 9 kali gambar, 1 kali angka. Sekarang Anda bertanya: “Kalau koin ini benar-benar seimbang (H₀ benar), seberapa besar kemungkinan saya mendapatkan hasil yang ekstrem seperti ini atau lebih ekstrem?”\nDi sinilah p-value berperan, yaitu menghitung peluang mendapatkan hasil se-ekstrem ini jika H₀ benar:\n\nJika peluangnya sangat kecil (misalnya &lt; 5%), maka hasil yang Anda dapatkan tidak cocok dengan asumsi bahwa koin seimbang, sehingga Anda punya alasan kuat untuk menolak H₀ dan curiga koinnya curang.\nJika peluangnya masih cukup besar (misalnya 30%), maka hasil yang Anda dapatkan masih wajar untuk koin seimbang, sehingga Anda tidak punya cukup alasan untuk menolak H₀.\n\nJadi, p-value bukanlah peluang koin curang atau tidak curang, melainkan peluang mendapatkan data yang Anda lihat jika koin benar-benar seimbang.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Signifikansi Statistik & *p-value*</span>"
    ]
  },
  {
    "objectID": "4_4_signifikansi.html#interpretasi-signifikansi-p-value",
    "href": "4_4_signifikansi.html#interpretasi-signifikansi-p-value",
    "title": "13  Signifikansi Statistik & p-value",
    "section": "13.3 Interpretasi Signifikansi & p-value",
    "text": "13.3 Interpretasi Signifikansi & p-value\nTerdapat dua hal penting yang perlu diingat diingat dalam menginterpretasi signifikansi statistik dan p-value. Pertama, signifikan secara statistik tidak selalu berarti signifikan secara praktis; ukuran efek (effect size) perlu dipertimbangkan (lihat Bab 15). Misalnya, ditemukan perbedaan skor ujian antara kelas yang menggunakan metode pembelajaran daring (Mean = 78,2) dan metode pembelajaran hibrid (Mean = 79,2). Meskipun secara statistik perbedaan kedua skor tersebut ditemukan signifikan (kemungkinan karena jumlah sampel yang besar), belum tentu memiliki nilai praktis yang bermakna. Dalam hal ini, perbedaan nilai 1 poin nampaknya terlalu “mahal” untuk dibayar dengan kerumitan dalam pelaksanaan dan pengelolaan metode belajar hibrid.\nKedua, p-value tidak menunjukkan peluang hipotesis benar atau salah, dan tidak membuktikan H₀ atau H₁ secara mutlak. p-value kecil menunjukkan bahwa jika H₀ benar, peluang memperoleh data seperti yang diamati sangat kecil; p-value besar menunjukkan data konsisten dengan H₀, tetapi bukan bukti bahwa H₀ benar.\nDengan memahami hubungan antara signifikansi dan p-value, peneliti dapat membuat keputusan yang lebih tepat dalam pengujian hipotesis, sekaligus menghindari kesalahan interpretasi yang umum terjadi.\n\n\n\n\nMoore, D. S., Notz, W., & Flinger, A. (2018). The basic practice of statistics (7th ed.). W.H. Freeman.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Signifikansi Statistik & *p-value*</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html",
    "href": "4_5_confidence.html",
    "title": "14  Confidence Interval",
    "section": "",
    "text": "14.1 Prinsip Dasar Confidence Interval\nSebelum memahami konsep Confidence Interval (CI), kita perlu mengingat kembali prinsip dasar statistik, yaitu bahwa statistik adalah estimasi parameter-parameter populasi (misalnya, nilai rata-rata, standar deviasi) berdasarkan data yang diambil dari sampel. Dengan kata lain, nilai yang kita peroleh dalam statistik kemungkinan besar (atau bahkan hampir pasti) tidak sama dengan nilai yang sesungguhnya pada populasi. Akan selalu ada selisih (eror) antara nilai pada sampel dan pada populasi.\nConfidence interval adalah rentang nilai yang digunakan untuk memperkirakan posisi parameter populasi berdasarkan data sampel. Interval ini dibentuk dari estimasi titik, seperti mean atau proporsi, kemudian ditambahkan batas bawah dan batas atas yang dihitung dari data.\nPrinsip dasarnya adalah memberikan gambaran bahwa parameter populasi tidak dinyatakan sebagai satu angka pasti, tetapi berada dalam suatu rentang yang masuk akal menurut data yang dikumpulkan. Dengan menggunakan CI, peneliti dapat menyampaikan hasil estimasi secara lebih informatif dan transparan, karena selain nilai estimasi, juga disertakan rentang ketidakpastian yang menyertainya.\nTingkat kesahihan dan keterpercayaan sebuah hasil riset bergantung pada seberapa representatif data yang diperoleh dari sampel dan seberapa yakin bahwa hasil analisis data yang dilakukan menggambarkan kondisi populasi yang sebenarnya. Oleh karena itu, pembahasan mengenai CI tidak dapat dilepaskan dari dua konsep yang terkait, yaitu Margin of Error (MoE) dan derajat keyakinan (Level of Confidence).",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Confidence Interval</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html#margin-of-error",
    "href": "4_5_confidence.html#margin-of-error",
    "title": "14  Confidence Interval",
    "section": "14.2 Margin of Error",
    "text": "14.2 Margin of Error\nMargin of error adalah batas toleransi kesalahan yang menunjukkan seberapa jauh nilai estimasi sampel dapat berbeda dari nilai sebenarnya di populasi. Dalam konteks CI, MoE menentukan jarak antara estimasi titik (misalnya mean sampel) dan batas atas atau batas bawah interval kepercayaan. Semakin kecil MoE, semakin sempit intervalnya, yang berarti estimasi lebih presisi.\nBesarnya MoE dipengaruhi oleh level of confidence (LoC) yang dipilih (misalnya 95%), ukuran sampel, dan variasi data. Pada LoC yang sama, ukuran sampel yang lebih besar atau variasi data yang lebih kecil akan menghasilkan MoE yang lebih kecil, sehingga interval kepercayaan menjadi lebih akurat.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Confidence Interval</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html#level-of-confidence",
    "href": "4_5_confidence.html#level-of-confidence",
    "title": "14  Confidence Interval",
    "section": "14.3 Level of Confidence",
    "text": "14.3 Level of Confidence\nLoC adalah tingkat keyakinan yang digunakan untuk menyatakan seberapa besar kemungkinan CI mencakup nilai parameter sebenarnya di populasi. Misalnya, LoC 95% berarti jika penelitian yang sama diulang berkali-kali dengan metode yang sama, sekitar 95% dari CI yang dihasilkan akan mengandung nilai parameter populasi. Semakin tinggi LoC, semakin besar jaminan bahwa interval mencakup parameter yang benar, namun konsekuensinya interval akan menjadi lebih lebar. Sebaliknya, level yang lebih rendah menghasilkan interval yang lebih sempit tetapi meningkatkan risiko parameter sebenarnya berada di luar interval tersebut.\nMari kita gunakan analogi untuk dapat lebih mudah memahaminya. Misalnya, Anda diminta untuk mengestimasi jarak antara Jakarta (dihitung dari lokasi Monumen Nasional) dan Yogyakarta (dihitung dari lokasi Monumen Yogya Kembali). Jika Anda bukan orang yang terbiasa bepergian Jakarta-Yogyakarta, Anda bisa menjawab bahwa jarak keduanya antara 550-600 KM (rentang sempit) dengan derajat keyakinan 45% (level rendah) karena Anda tidak terlalu yakin bahwa jarak sebenarnya ada di antara rentang tersebut.\nAtau, Anda bisa menjawab dengan tingkat keyakinan yang jauh lebih tinggi (misalnya 99%) bahwa jaraknya antara 100-800KM (rentang sangat lebar). Memang, hampir pasti jawabannya ada di dalam rentang tersebut, tetapi kemampuan estimasi Anda menjadi sangat diragukan karena rentangnya sangat lebar (700 KM), sehingga sulit untuk memperkirakan berapa jarak sebenarnya (menurut perhitungan Google Maps dengan mode kendaraan roda 4, jaraknya adalah 578 KM).",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Confidence Interval</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html#menginterpretasi-ci-moe-loc",
    "href": "4_5_confidence.html#menginterpretasi-ci-moe-loc",
    "title": "14  Confidence Interval",
    "section": "14.4 Menginterpretasi CI, MoE, & LoC",
    "text": "14.4 Menginterpretasi CI, MoE, & LoC\nRentang keyakinan atau CI diperoleh dengan cara sebagai berikut:\n\\[\\text{CI} = \\bar{x} \\;\\pm\\; \\text{MoE}\n\\]\n\\[\n\\text{di mana MoE} = z \\times \\frac{s}{\\sqrt{n}}\n\\]\nKet.: \\(\\bar{x}\\) = rata-rata (mean) sampel; \\(z\\) = nilai z-score yang sesuai dengan tingkat kepercayaan yang dipilih (misalnya, 1,96 untuk LoC 95% dan 2,58 untuk LoC 99%); \\(s\\) = standar deviasi sampel; \\(n\\) = ukuran sampel\nJika mean dari data adalah 25 dan MoE (LoC 95%) = 4, maka CI = 25 ± 4 = 21–29, yang artinya bahwa nilai populasi diestimasi berada pada kisaran 21 hingga 29. Dengan menggunakan LoC yang lebih tinggi (99%), maka MoE = 5,25, sehingga CI = 25 ± 5,25 = 19,75–30,25. Dengan kata lain, dengan tingkat keyakinan 99%, nilai mean populasi berada di antara 19,75 hingga 30,25. Kita dapat melihat bahwa semakin tinggi LoC maka semakin lebar rentang keyakinannya, begitu pula sebaliknya.\nPemahaman mengenai CI dan MoE ini sangat penting bagi peneliti untuk mengambil kesimpulan dan keputusan dari data yang telah dianalisis. Kesalahan atau kurangnya pemahaman dapat membawa peneliti pada penyimpulan yang keliru. Sebagai ilustrasi, di masa Pemilu sebuah lembaga survei politik melakukan riset tingkat keterpilihan (elektabilitas) para pasangan kandidat presiden dan wakil presiden. Dari dua pasang kandidat, berdasarkan risetnya lembaga survei tersebut menemukan bahwa elektabilitas pasangan A mencapai 48% dan pasangan B 52% dengan MoE 3% pada LoC 95%.\nJika tidak memahami bagaimana hasil ini seharusnya diinterpretasikan, maka mereka dapat berkesimpulan bahwa pasangan B unggul dan akan memenangi persaingan dengan pasangan A. Padahal, jika memperhitungkan MoE dalam memahami hasil tersebut, kita akan menemukan bahwa pada kondisi aktualnya, elektabilitas A berada di antara 45–51%, sedangkan B 49–55%. Artinya, masih ada kemungkinan bahwa pasangan A meraih skor lebih tinggi (misalnya 51%) dibandingkan B (misalnya 49%). Oleh karena itu, kemenangan di antara kedua pasangan tersebut masih belum dapat diestimasi secara meyakinkan karena ada area skor elektabilitas yang beririsan. Terlebih lagi jika penghitungannya menggunakan LoC 99%, maka irisan skornya akan makin besar, sehingga makin sulit menentukan siapa di antara mereka yang secara aktual lebih unggul.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Confidence Interval</span>"
    ]
  },
  {
    "objectID": "4_6_effect_size.html",
    "href": "4_6_effect_size.html",
    "title": "15  Effect Size",
    "section": "",
    "text": "15.1 Prinsip Dasar\nEffect size adalah ukuran yang menunjukkan seberapa besar perbedaan atau hubungan yang benar-benar berarti dalam penelitian, melampaui sekadar signifikansi statistik. Jika nilai p hanya memberi tahu apakah suatu efek ada, maka effect size menjelaskan seberapa kuat atau penting efek tersebut secara praktis. Dengan demikian, memahami effect size menjadi penting agar peneliti tidak hanya tahu “ada atau tidaknya perbedaan”, tetapi juga “seberapa besar perbedaan itu” dalam konteks nyata. Dari titik inilah pembahasan dapat diarahkan pada prinsip dasar effect size yang menjelaskan konsep, jenis, hingga cara menghitungnya.\nEffect size berangkat dari gagasan bahwa signifikansi statistik saja tidak cukup untuk menjawab apakah suatu temuan penelitian benar-benar penting secara praktis. Sebuah hasil bisa saja signifikan karena ukuran sampelnya besar, padahal perbedaan yang ditemukan sebenarnya sangat kecil dan tidak relevan dalam praktik. Di sinilah effect size berperan, karena ia memberi informasi mengenai kekuatan hubungan antar variabel atau besarnya perbedaan antar kelompok dengan satuan yang lebih mudah dipahami secara kuantitatif.\nSecara prinsip, effect size mengukur seberapa besar “efek nyata” yang terjadi dalam sebuah studi. Efek ini bisa berupa perbedaan rata-rata antar kelompok, kekuatan korelasi antara dua variabel, atau besarnya varians yang dapat dijelaskan oleh suatu model. Dengan demikian, effect size menjadi jembatan penting yang menghubungkan antara hasil analisis statistik dan implikasi praktis dari penelitian. Ia membantu peneliti untuk tidak hanya menjawab “apakah ada efek?” tetapi juga “seberapa besar efek itu?”.\nPelaporan effect size penting karena melengkapi informasi yang tidak diberikan oleh p-value. Nilai signifikansi hanya menunjukkan apakah hasil mungkin terjadi karena kebetulan atau tidak, tetapi tidak menjelaskan seberapa besar pengaruh yang sebenarnya. Dengan menyertakan effect size, peneliti dapat menilai apakah temuan yang signifikan juga memiliki arti praktis, serta memungkinkan perbandingan lintas penelitian secara lebih adil, misalnya dalam meta-analisis. Hal ini mencegah kesalahpahaman bahwa hasil signifikan selalu berarti penting, padahal efeknya bisa saja sangat kecil dan kurang relevan secara praktis.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Effect Size*</span>"
    ]
  },
  {
    "objectID": "4_6_effect_size.html#klasifikasi-effect-size",
    "href": "4_6_effect_size.html#klasifikasi-effect-size",
    "title": "15  Effect Size",
    "section": "15.2 Klasifikasi Effect Size",
    "text": "15.2 Klasifikasi Effect Size\nEffect size dapat dinyatakan dalam beberapa bentuk tergantung pada teknik analisis statistik yang digunakan. Secara umum, ada dua kategori utama:\n\nPerbedaan mean yang distandarisasi\nUkuran ini digunakan untuk membandingkan rata-rata dua kelompok atau lebih. Rumus yang paling populer adalah Cohen’s d:\n\\[\nd = \\frac{M_{1} - M_{2}}{SD_{\\text{pooled}}}\n\\]\ndengan\n\\[\nSD_{\\text{pooled}} =\n\\sqrt{ \\frac{(n_{1}-1)SD_{1}^{2} + (n_{2}-1)SD_{2}^{2}}{\\,n_{1} + n_{2} - 2} }\n\\]\n\nProporsi varians yang dapat dijelaskan\nUkuran ini menjawab pertanyaan: seberapa besar varians pada suatu variabel dapat dijelaskan oleh varians variabel lain. Bentuk yang sering digunakan antara lain:\n\nr² untuk uji beda mean\nDari uji t, effect size dapat dihitung dengan:\n\n\\[\nr^{2} = \\frac{t^{2}}{t^{2} + \\text{df}}\n\\]\n\nr² untuk korelasi\nJika analisis berupa korelasi, effect size dihitung dengan menguadratkan koefisien korelasi:\n\n\\[\nr^{2} = \\left(r_{xy}\\right)^{2}\n\\]\nSemakin besar nilai r², semakin banyak varians satu variabel yang dapat dijelaskan oleh variabel lain.\n\nR² dalam regresi\nDalam analisis regresi, effect size dinyatakan dengan proporsi varians total yang dijelaskan oleh model:\n\\[\nR^{2} = \\frac{JK_{\\text{reg}}}{JK_{\\text{tot}}}\n\\]Nilai R² berkisar antara 0–1, dengan interpretasi bahwa semakin tinggi R², semakin baik model regresi menjelaskan varians variabel dependen.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Effect Size*</span>"
    ]
  },
  {
    "objectID": "4_6_effect_size.html#ukuran-effect-size-lainnya",
    "href": "4_6_effect_size.html#ukuran-effect-size-lainnya",
    "title": "15  Effect Size",
    "section": "15.3 Ukuran Effect Size Lainnya",
    "text": "15.3 Ukuran Effect Size Lainnya\nSelain Cohen’s d dan korelasi (r), terdapat ukuran effect size lain yang digunakan sesuai jenis analisis. Setiap ukuran ini membantu peneliti membaca makna praktis hasil penelitian dalam konteks yang lebih spesifik (lihat ?tbl-effect).\n\nCramer’s V/Phi coefficient\nDigunakan pada uji chi-square atau tabel kontingensi untuk melihat kekuatan hubungan antar variabel kategorikal. Nilainya mirip dengan korelasi, semakin mendekati 1 berarti hubungan semakin kuat.\nEta squared (η²)/Partial eta squared (ηp²)\nSering digunakan pada ANOVA. Menunjukkan proporsi varians yang dijelaskan oleh faktor independen. Partial eta squared lebih umum dipakai dalam penelitian psikologi karena memperhitungkan pengaruh faktor lain.\nOdds ratio\nDigunakan dalam penelitian dengan data kategorikal (terutama di ilmu kesehatan). Menggambarkan seberapa besar peluang suatu kejadian terjadi pada satu kelompok dibandingkan kelompok lain.\n\n\n\nTabel interpretasi effect size (Cumming, 2011)\n\n\n\n\n\n\n\n\nUkuran\nKecil\nSedang\nBesar\n\n\n\n\nCohen’s d\n0.2\n0.5\n0.8\n\n\nr/r²\nr = 0.1 (r² ≈ 0.01)\nr = 0.3 (r² ≈ 0.09)\nr = 0.5 (r² ≈ 0.25)\n\n\nCramer’s V/Phi\n0.1\n0.3\n0.5\n\n\nEta squared (η²)\n0.01\n0.06\n0.14\n\n\nPartial eta squared (ηp²)\n0.01\n0.06\n0.14\n\n\nOdds ratio (OR)\n~1.2\n~1.5\n≥2.0\n\n\n\n\n\n\n\n\nCumming, G. (2011). Understanding the New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis. Routledge.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Effect Size*</span>"
    ]
  }
]
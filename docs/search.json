[
  {
    "objectID": "5_3_independent_ttest.html",
    "href": "5_3_independent_ttest.html",
    "title": "18  Asumsi, Interpretasi, dan Pelaporan Analisis Independent Samples t-test: Parametrik dan Non-Parametrik",
    "section": "",
    "text": "Asumsi dasar yang perlu dipenuhi untuk melakukan uji beda menggunakan independent t-test adalah:\n\nDependent Variable (DV – variabel yang menjadi fokus penelitian) berupa data kontinum (data interval atau rasio), misalnya skor tes, waktu respon.\nIndependent Variable (IV – kelompok yang diuji) merupakan dua kelompok yang berbeda, misalnya perbedaan kemampuan bahasa antara kelompok laki-laki dan perempuan.\nData yang diobservasi harus independen, tidak berasal dari kelompok yang sama.\nData harus terdistribusi normal. Gunakan uji beda non-parametrik jika data tidak terdistribusi dengan normal.\nTidak ada outliers (data yang sangat berbeda dari rata-rata).\nData harus memiliki varians yang homogen (homogeneity). Asumsi ini dapat dilihat dengan menggunakan Levene’s test for homogeneity of variance.\n\nInterpretasi dari hasil uji beda menggunakan independent t-test perlu dilakukan secara bertahap. Misalnya, peneliti ingin mengetahui perbedaan self-efficacy berdasarkan  jenis kelamin (laki-laki dan perempuan). Tahapan interpretasi hasil uji independent t-test dapat dipahami dengan mempelajari contoh output penghitungan independent t-test menggunakan software JASP berikut:\n\nUji asumsi\nHal pertama yang perlu dilihat adalah uji asumsi terkait distribusi dan homogenitas data; data harus terdistribusi secara normal dan homogen. Pada contoh tabel hasil uji hipotesis yang diperlihatkan pada Tabel 18.1, diketahui bahwa self-efficacy pada kedua kelompok terdistribusi normal (kelompok laki-laki p = .16; perempuan p = .07; p &gt; .05). Artinya, sebaran data self-efficacy partisipan pada kedua kelompok tidak berbeda secara signifikan dibandingkan sebaran data kurva normal.\n\n\n\nTabel 18.1: Contoh hasil uji normalitas (Shapiro-Wilk)\n\n\n\n\n\nVariabel\nKelompok\nW\np\n\n\n\n\nSelf-efficacy\nLaki-laki\n0.961\n0.155\n\n\n\nPerempuan\n0.961\n0.066\n\n\n\n\n\n\nUji homogenitas berdasarkan skor Levene’s test juga tidak signifikan (F = 1.53, p = .22 &gt; .05), menunjukkan bahwa kedua kelompok tidak menunjukkan varians yang berbeda, atau data bersifat homogen (Tabel 18.2). Dengan demikian, data penelitian memenuhi kedua uji asumsi sehingga dapat dilanjutkan untuk dianalisis dengan menggunakan independent samples t-test. Jika data tidak memenuhi uji asumsi tersebut, maka uji parametrik tidak dapat dilanjutkan, perlu dilakukan uji non-parametrik (Mann-Withney test).\n\n\n\nTabel 18.2: Contoh hasil uji homogenitas Levene\n\n\n\n\n\nVariabel\nF\ndf1\ndf2\np\n\n\n\n\nSelf-efficacy\n1.527\n1\n98\n.220\n\n\n\n\n\n\nUji Hipotesis\nSelanjutnya, hal yang perlu dilihat adalah nilai p pada tabel independent samples t-test. Nilai p = .006 (p &lt; .05) menunjukkan terdapat perbedaan signifikan tingkat self-efficacy yang dilaporkan oleh partisipan laki-laki dan perempuan. Pada tabel output uji independent t-test (lihat Tabel 18.3) juga dapat dilihat nilai Cohen’s d yang menunjukkan seberapa besar efek dari perbedaan jenis kelamin terhadap perbedaan self-efficacy pada kedua kelompok (effect size). Nilai t, df, p dan Cohen’s d diperlukan dalam penulisan interpretasi hasil uji beda antar kelompok, yang dapat dilihat pada contoh interpretasi hasil independent samples t-test.\n\n\n\nTabel 18.3: Contoh hasil analisis independent samples t-test\n\n\n\n\n\nVariabel\nt\ndf\np\nCohen’s D\nSE Cohen’s D\n\n\n\n\nSelf-efficacy\n2.280\n98\n.006\n0.570\n0211\n\n\n\n\n\n\nData Deskriptif Kelompok\nTerakhir, informasi mengenai mean dan SD diperlukan untuk mengetahui kelompok mana yang menunjukkan rata-rata skor paling tinggi (lihat Tabel 18.4). Contoh tabel menunjukkan laki-laki memiliki rata-rata self-efficacy yang lebih tinggi dibandingkan perempuan.\n\n\n\n\nTabel 18.4: Contoh statistik deskriptif independent samples t-test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabel\nKelompok\nN\nMean\nSD\nSE\nCoefficient of variation\n\n\n\n\nSelf-efficacy\nLaki-laki\n43\n8.209\n1.922\n0.293\n0.234\n\n\n\nPerempuan\n57\n7.193\n1.674\n0.222\n0.233\n\n\n\n\n\n\nPelaporan hasil uji beda independent samples t-test dengan mengikuti format penulisan APA, adalah: Hasil independent samples t-test menunjukkan terdapat perbedaan tingkat self-efficacy yang signifikan (t (98) = 2.82, p = .006, d = .57) antara kelompok partisipan laki-laki (M = 8.21, SD = 1.92) dan partisipan perempuan (M = 7.19, SD = 1.67). Atau, partisipan laki-laki (M = 8.21, SD = 1.92) memiliki self-efficacy yang lebih tinggi (t (98) = 2.82, p = .006, d = .57) dibandingkan partisipan perempuan (M = 7.19, SD = 1.67).\nPrinsip yang sama juga dapat diterapkan untuk interpretasi dan melaporkan hasil uji beda non-parametrik (lihat Tabel 18.5), dengan melihat hasil uji Mann-Whitney test (U), dan mean rank sebagai pengganti mean. Berikut adalah contoh output Mann-Whitney:\n\n\n\nTabel 18.5: Contoh hasil analisis Mann-Whitney\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabel\nU\ndf\np\nRank-Biserial Correlation\nSE Rank-Biserial Correlation\n\n\n\n\nSelf-efficacy\n1576.000\n\n0.013\n0.286\n0.117\n\n\n\n\n\n\nHasil Mann-Whitney test menunjukkan bahwa terdapat perbedaan tingkat self-efficacy yang signifikan (U = 1576, p = .013) antara kelompok partisipan laki-laki (Mdn = 58.65) dan partisipan perempuan (Mdn = 44.35). Atau, partisipan laki-laki (Mdn = 58.65) memiliki self-efficacy yang lebih tinggi (U = 1576, p = .013) dibandingkan partisipan perempuan (Mdn = 44.35) (lihat Tabel 18.6).\n\n\n\nTabel 18.6: Contoh statistik deskriptif Mann-Whitney\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVariabel\nKelompok\nN\nMean\nSD\nSE\nCoefficent of Variation\nMean Rank\nSum Rank\n\n\n\n\nSelf-efficacy\nLaki-laki\n43\n8.209\n1.922\n0.293\n0.234\n58.651\n2522\n\n\n\nPerempuan\n57\n7.193\n1.674\n0.222\n0.233\n44.351\n2528",
    "crumbs": [
      "PERBEDAAN RATA-RATA DUA KELOMPOK",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Asumsi, Interpretasi, dan Pelaporan Analisis *Independent Samples t-test*: Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Tentang Penulis",
    "section": "",
    "text": "Dr. Sunu Bagaskara  \nadalah akademisi dan peneliti di bidang Psikologi dengan latar belakang pendidikan S1 hingga S3 di Fakultas Psikologi Universitas Indonesia. Ia berpengalaman mengajar Psikologi Sosial, Metode Penelitian Kuantitatif dan Statistik, serta Konstruksi Alat Ukur Psikologi. Minat penelitiannya mencakup kognisi sosial, psikologi lalu lintas, dan penerapan statistik dalam psikologi, dengan berbagai publikasi di jurnal ilmiah nasional dan internasional yang mencerminkan dedikasinya pada pengembangan ilmu psikologi dan keselamatan masyarakat.\n\n\nDr. Entin Nurhayati  \nberpengalaman mengajar kurang lebih selama 20 tahun. Pernah mengajar berbagai mata kuliah, seperti Faal, Psi Perkembangan, Psikodiagnosis (TAT/CAT, Rorschach) hingga beberapa tahun terakhir fokus di rumpun penelitian, khususnya mata kuliah metodologi penelitian dan statistik. Berdasar pengalaman mengajar ini serta membimbing penelitian mahasiswa, penulis memahami berbagai kesulitan yang dihadapi mahasiswa dalam memahami metopen dan statistik. Bersama sejawat, penulis berusaha melahirkan rangkaian buku praktis, agar mahasiswa dapat dengan mudah dan cepat memahami ilmu alat mengembangkan pengetahuan ini. Buku ini merupakan buku pertama yang dirancang untuk keperluan tersebut.\n\n\nSari Zakiah Akmal, Ph.D., Psikolog  \nadalah akademisi dan peneliti di bidang Psikologi Pendidikan. Ia lulusan dari program Sarjana dan Magister Profesi Psikologi Pendidikan, Fakultas Psikologi Universitas Indonesia dan program doktoral dari School of Applied Psychology, Griffith University, Australia. Sebagai dosen psikologi, ia pernah mengampu matakuliah terkait Metode Penelitian Kuantitatif, Statistik, Logika – Penulisan Ilmiah, Konstruksi Alat Ukur Psikologi, Asesmen Inteligensi, dan Pengembangan Diri dan Karier. Ia juga aktif dalam melakukan penelitian dan pengabdian masyarakat dengan fokus utama pada pengambilan keputusan karier, adaptabilitas karier, ketahanan akademik di kalangan mahasiswa, dan berbagai permasalahan terkait pendidikan siswa SMA/SMK dan mahasiswa di perguruan tinggi. Karya-karyanya telah dipublikasikan dalam berbagai jurnal akademik dan konferensi, mencerminkan komitmennya dalam mengembangkan penelitian dan pendidikan psikologi.\n\n\nTiti Sahidah, M.Psi, M.Sc., Ph.D., Psikolog  \nadalah pengajar di Fakultas Psikologi Universitas YARSI, Jakarta. Sejak memulai karier akademiknya pada tahun 2012, ia secara konsisten mengampu mata kuliah Psikometri dan Konstruksi Alat Ukur, yang menjadi bidang minat dan keahliannya. Ia melanjutkan studi doktoralnya di bidang Psikologi Medis di Erasmus MC, Rotterdam, Belanda. Di bawah bimbingan ahli dalam bidang psikometri, Titi menulis disertasi mengenai validitas, reliabilitas dan norma alat ukur EQ-5D-Y di Indonesia. Karya-karya publikasinya, khususnya dalam pengembangan alat ukur psikologi kesehatan yang dipresentasikan di berbagai konferensi dan diterbitkan di jurnal internasional, menjadikannya salah satu pakar dalam bidang pengukuran psikologi kesehatan di Indonesia.\n\n\nAswin Januarsjaf, S.Psi., M.M \nadalah akademisi dan praktisi di bidang Psikologi serta Manajemen Sumber Daya Manusia. Lulusan Psikologi Universitas Padjadjaran dan Magister Manajemen PPM School of Management ini memiliki pengalaman lebih dari dua dekade di berbagai industri, khususnya dalam bidang rekrutmen, asesmen, dan pengembangan SDM. Ia mendirikan Talentlytica, sebuah platform asesmen berbasis data, serta aktif mengajar statistik psikologi dan melatih topik manajemen SDM di berbagai institusi. Karya-karya dan inovasi perangkat asesmennya mencerminkan komitmennya untuk menghubungkan ilmu psikologi dengan praktik manajemen modern di Indonesia.",
    "crumbs": [
      "Tentang Penulis"
    ]
  },
  {
    "objectID": "1_pengantar.html",
    "href": "1_pengantar.html",
    "title": "PENGANTAR STATISTIK",
    "section": "",
    "text": "Statistik memainkan peran yang sangat penting dalam dunia psikologi, khususnya dalam konteks penelitian dan pengambilan keputusan berbasis data. Bab-bab awal buku ini bertujuan memberikan pemahaman dasar tentang konsep-konsep statistik yang relevan bagi mahasiswa psikologi. Mulai dari sejarah dan definisi statistik, pembahasan ini menjelaskan bagaimana perkembangan ilmu ini dipengaruhi oleh berbagai tokoh dan kebutuhan untuk memahami variasi dalam kehidupan manusia. Selain itu, bab-bab ini juga menguraikan prinsip-prinsip dasar seperti hubungan antara sampel dan populasi, serta peran parameter dan statistik dalam menginterpretasikan data penelitian.\nLebih jauh, buku ini membahas pentingnya statistik dalam penelitian psikologi, terutama untuk mengakomodasi kompleksitas perilaku manusia. Dengan menggunakan pendekatan deskriptif dan inferensial, statistik membantu peneliti menggambarkan data secara efektif sekaligus membuat generalisasi yang valid dari sampel ke populasi. Bab-bab ini dirancang untuk menjadi landasan kokoh bagi mahasiswa dalam memahami bagaimana statistik dapat digunakan untuk menjawab berbagai pertanyaan penelitian, mengatasi tantangan analisis data, dan mendukung validitas ilmiah psikologi sebagai disiplin ilmu.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 1. Pengertian & Sejarah Ringkas Statistik:\n\nMemahami definisi statistik dan konsep dasar yang meliputi parameter dan statistik.\nMengidentifikasi hubungan antara sampel dan populasi dalam konteks penelitian.\nMemahami peran statistik sebagai alat untuk mengorganisasi, merangkum, dan menginterpretasi informasi.\n\nBab 2. Statistik dalam Penelitian Psikologi:\n\nMenjelaskan peran statistik dalam mendukung psikologi sebagai ilmu ilmiah.\nMengevaluasi signifikansi statistik dalam memahami variasi perilaku dan membuat inferensi dari data penelitian.\n\nBab 3. Jenis-jenis Statistik: Deskriptif & Inferensial:\n\nMengidentifikasi perbedaan utama antara statistik deskriptif dan statistik inferensial, termasuk ruang lingkup dan tujuan keduanya.\nMemahami bagaimana kombinasi statistik deskriptif dan inferensial mendukung analisis data yang kuat, khususnya dalam ilmu perilaku dan sosial.",
    "crumbs": [
      "PENGANTAR STATISTIK"
    ]
  },
  {
    "objectID": "1_1_sejarah.html",
    "href": "1_1_sejarah.html",
    "title": "1  Pengertian & Sejarah Ringkas Statistik",
    "section": "",
    "text": "1.1 Definisi Statistik\nSejarah statistik bermula dari kebutuhan memahami variasi dalam ilmu hayati dan sosial (Gravetter & Wallnau, 2017). Variasi ini menjadi pusat perhatian dengan diperkenalkannya teori evolusi oleh Charles Darwin pada abad ke-19. Pionir seperti Francis Galton, sepupu Darwin, berusaha menguantifikasi pewarisan sifat biologis dan memunculkan konsep regresi terhadap rata-rata. Galton juga mengembangkan metode korelasi, yang menjadi dasar statistik modern. Selanjutnya, Karl Pearson memperkukuh landasan matematis statistik dengan memperkenalkan koefisien korelasi dan uji chi-kuadrat. Perkembangan ini melibatkan kajian biometrika dan genetik, dengan fokus pada pewarisan sifat yang dipengaruhi oleh gerakan eugenika.\nPada abad ke-20, Ronald Fisher memperkenalkan analisis varians dan metode eksperimental untuk memperluas penerapan statistik, terutama dalam ilmu perilaku (Cowles, 2000). Fisher, bersama Pearson, menekankan pentingnya inferensi statistik untuk mengatasi variasi alami. Pada saat yang sama, probabilitas berkembang sebagai dasar teoretis statistik, berakar dari upaya menjawab masalah dunia nyata seperti perjudian dan prediksi aktuarial. Normalisasi distribusi data, yang diperkenalkan oleh Lambert Quetelet, menjadi inti statistik inferensial. Hingga kini, statistik terus berkembang dengan mengintegrasikan metode baru untuk menjawab tantangan dalam berbagai disiplin ilmu.\nStatistik adalah kumpulan prosedur matematis yang digunakan untuk mengorganisasi, merangkum, dan menginterpretasi informasi (Gravetter & Wallnau, 2017). Dalam konteks penelitian, statistik membantu para peneliti untuk memahami hasil studi dan menyampaikan informasi tersebut secara akurat dan informatif. Statistik juga menyediakan teknik-teknik standar yang diakui dalam komunitas ilmiah sehingga hasil analisis dapat diinterpretasikan dengan konsistensi yang tinggi oleh peneliti lainnya.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pengertian & Sejarah Ringkas Statistik</span>"
    ]
  },
  {
    "objectID": "1_1_sejarah.html#sampel-dan-populasi",
    "href": "1_1_sejarah.html#sampel-dan-populasi",
    "title": "1  Pengertian & Sejarah Ringkas Statistik",
    "section": "1.2 Sampel dan Populasi",
    "text": "1.2 Sampel dan Populasi\nPopulasi adalah keseluruhan individu atau elemen yang menjadi fokus penelitian. Karena populasi biasanya terlalu besar untuk dianalisis secara langsung, peneliti memilih sampel, yaitu sekelompok individu yang mewakili populasi. Sampel bertujuan untuk menyederhanakan penelitian sambil tetap memungkinkan penarikan kesimpulan yang dapat digeneralisasi ke populasi. Hubungan antara sampel dan populasi bersifat dua arah: sampel diambil dari populasi, dan hasil penelitian pada sampel digeneralisasikan kembali ke populasi.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pengertian & Sejarah Ringkas Statistik</span>"
    ]
  },
  {
    "objectID": "1_1_sejarah.html#parameter-dan-statistik",
    "href": "1_1_sejarah.html#parameter-dan-statistik",
    "title": "1  Pengertian & Sejarah Ringkas Statistik",
    "section": "1.3 Parameter dan Statistik",
    "text": "1.3 Parameter dan Statistik\nParameter adalah nilai yang menggambarkan suatu karakteristik dari populasi, seperti rata-rata populasi, sedangkan statistik adalah nilai yang menggambarkan karakteristik dari sampel, seperti rata-rata sampel. Dalam penelitian, data yang diperoleh berasal dari sampel, sehingga statistik digunakan untuk memperkirakan parameter populasi. Proses ini menciptakan hubungan erat antara statistik sampel dan parameter populasi, yang menjadi dasar dari banyak prosedur statistik.\n\n\n\n\nCowles, M. (2000). Statistics in Psychology: An Historical Perspective. Psychology Press.\n\n\nGravetter, F. J., & Wallnau, L. B. (2017). Statistics for the Behavioral Sciences. Cengage Learning.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pengertian & Sejarah Ringkas Statistik</span>"
    ]
  },
  {
    "objectID": "1_2_stat_psiko.html",
    "href": "1_2_stat_psiko.html",
    "title": "2  Statistik dalam Penelitian Psikologi",
    "section": "",
    "text": "Statistik memegang peran penting dalam perkembangan ilmu psikologi, khususnya dalam upaya menjadikannya ilmu yang lebih ilmiah (Dancey & Reidy, 2017). Dimulai dengan prinsip determinisme yang mengasumsikan adanya keteraturan dalam alam, psikologi mencoba meniru pendekatan ilmu alam untuk memprediksi dan mengontrol perilaku. Hal ini dipopulerkan oleh tokoh seperti John B. Watson melalui behaviorisme yang mengedepankan studi eksperimental untuk mengendalikan variabel-variabel perilaku. Namun, pendekatan deterministik ini dipadukan dengan model probabilistik untuk mengakomodasi kompleksitas dan variasi yang melekat pada manusia.\nStatistik memungkinkan psikologi menangani variasi data dan membuat inferensi dari sampel ke populasi. Misalnya, Ronald Fisher mengembangkan desain eksperimen dan analisis varians (ANOVA) untuk membantu peneliti memahami hubungan sebab-akibat meskipun terdapat variabilitas. Selain itu, pengembangan metode korelasi oleh Francis Galton dan Karl Pearson membantu mengukur hubungan antar variabel, sementara analisis faktor yang diperkenalkan Charles Spearman mengidentifikasi faktor-faktor dalam kecerdasan (Coolican, 2014).\nDalam sejarahnya, statistik tidak hanya digunakan untuk menganalisis data, tetapi juga sebagai alat eksplorasi. Contohnya, metode analisis faktor sering digunakan untuk memetakan domain baru dalam psikologi sebelum eksperimen langsung dilakukan. Statistik juga membantu memperjelas perbedaan antara pendekatan eksperimental yang berfokus pada manipulasi variabel independen dan pendekatan korelasional yang mempelajari hubungan antar variabel dalam kondisi alami.\nSignifikansi statistik dalam psikologi tidak lepas dari pengaruh pionir seperti Gustav Fechner, yang memulai pendekatan kuantitatif untuk mengukur hubungan antara stimulus dan sensasi. Meskipun beberapa konsep awal seperti hukum psikofisik Fechner kini telah direvisi, kontribusinya mendasari metode eksperimental modern. Statistik memungkinkan peneliti psikologi untuk mengatasi tantangan dalam memahami kondisi manusia yang penuh variasi, sekaligus menyediakan dasar untuk menguji hipotesis secara objektif (Salsburg, 2002).\nStatistik juga memperkuat nilai-nilai keilmiahan psikologi, seperti keterbukaan terhadap koreksi, validasi empiris, dan kemampuan untuk memprediksi. Dengan demikian, statistik tidak hanya menjadi alat teknis tetapi juga kerangka filosofis yang mendukung psikologi sebagai ilmu yang dapat menjembatani antara determinisme dan kebebasan manusia, serta antara pandangan positivistik dan humanisme.\n\n\n\n\nCoolican, H. (2014). Research methods and statistics in psychology (hlm. 773). Psychology Press, Taylor & Francis Group.\n\n\nDancey, C. P., & Reidy, J. (2017). Statistics without maths for psychology (7th ed.). Pearson Education Limited.\n\n\nSalsburg, D. (2002). The lady tasting tea: how statistics revolutionized science in the twentieth century. Henry Holt; Company.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Statistik dalam Penelitian Psikologi</span>"
    ]
  },
  {
    "objectID": "1_3_jenis_stat.html",
    "href": "1_3_jenis_stat.html",
    "title": "3  Jenis-jenis Statistik: Deskriptif & Inferensial",
    "section": "",
    "text": "Statistik dapat dibagi menjadi dua kategori utama, yaitu statistik deskriptif dan statistik inferensial, yang masing-masing memiliki peran penting dalam analisis data. Statistik deskriptif (Bagian 3) digunakan untuk merangkum, mengorganisasi, dan menyederhanakan data mentah menjadi informasi yang lebih mudah dipahami. Teknik-teknik ini termasuk distribusi frekuensi, tabel, grafik, rata-rata (mean), median, mode, serta ukuran dispersi seperti variansi dan standar deviasi. Statistik deskriptif membantu memberikan gambaran umum tentang data tanpa membuat kesimpulan lebih luas.\nSebaliknya, statistik inferensial (Bagian 4) digunakan untuk membuat generalisasi tentang populasi berdasarkan data sampel. Teknik ini melibatkan analisis data dari sampel untuk menjawab pertanyaan penelitian dan menyimpulkan parameter populasi. Statistik inferensial sering menggunakan konsep probabilitas untuk memperkirakan sejauh mana kesimpulan dari sampel dapat mewakili populasi secara keseluruhan. Contoh aplikasinya termasuk uji hipotesis, analisis varians (ANOVA), dan regresi.\nPerbedaan utama antara keduanya terletak pada tujuan dan ruang lingkupnya. Statistik deskriptif fokus pada penggambaran data yang ada, sedangkan statistik inferensial fokus pada pengambilan keputusan atau prediksi berdasarkan data tersebut. Misalnya, statistik deskriptif digunakan untuk menghitung rata-rata usia partisipan dalam sebuah survei, sementara statistik inferensial menggunakan data tersebut untuk memprediksi rata-rata usia seluruh populasi.\nDalam praktiknya, kedua jenis statistik ini saling melengkapi. Statistik deskriptif menyediakan dasar untuk memahami data, sedangkan statistik inferensial memberikan kerangka untuk mengambil keputusan yang lebih luas. Sebagai contoh, analisis distribusi frekuensi dalam statistik deskriptif dapat menjadi langkah awal sebelum melakukan uji-t atau ANOVA dalam statistik inferensial.\nKombinasi kedua pendekatan ini mendukung analisis data yang kuat, terutama dalam ilmu perilaku dan sosial. Statistik deskriptif membantu menggambarkan data dengan jelas, sementara statistik inferensial memberikan justifikasi yang didukung oleh probabilitas untuk menjawab pertanyaan-pertanyaan penelitian yang kompleks. Hal ini menjadikan statistik alat yang tak tergantikan dalam proses penelitian ilmiah.",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Jenis-jenis Statistik: Deskriptif & Inferensial</span>"
    ]
  },
  {
    "objectID": "1_latihan.html",
    "href": "1_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bagian 1 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "PENGANTAR STATISTIK",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "2_persiapan.html",
    "href": "2_persiapan.html",
    "title": "PERSIAPAN DATA",
    "section": "",
    "text": "Bab ini akan membahas mengenai mengenali dan mempersiapkan data penelitian agar dapat diolah lebih lanjut secara statistik. Untuk menghasilkan analisis yang valid dan bermakna, peneliti perlu memahami jenis data yang dimiliki, melakukan proses pembersihan data secara sistematis, serta menjaga akuntabilitas dalam setiap tahap pengelolaan data. Tahapan ini bukan sekadar teknis, melainkan fondasi penting untuk memastikan bahwa hasil analisis benar-benar mencerminkan realitas yang diteliti.\nBab ini diawali dengan penjelasan tentang jenis data, termasuk cara mengidentifikasi tipe data serta prinsip dalam penamaan dan pengkodean variabel agar konsisten dan mudah diinterpretasikan. Selanjutnya, pembahasan berlanjut pada proses pembersihan data, yang mencakup analisis deskriptif awal, penanganan missing value, serta deteksi pencilan (outlier) yang dapat memengaruhi hasil analisis. Terakhir, bab ini menekankan pentingnya akuntabilitas data, yaitu tanggung jawab peneliti untuk mendokumentasikan, menyimpan, dan mengelola data secara transparan agar dapat dipertanggungjawabkan secara ilmiah. Dengan memahami dan menerapkan ketiga aspek ini, mahasiswa akan memiliki dasar yang kuat dalam mempersiapkan data untuk analisis statistik yang sahih dan terpercaya.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 4. Jenis Data:\n\nMengidentifikasi berbagai jenis data dalam konteks penelitian psikologi (nominal, ordinal, interval, rasio).\nMenerapkan prinsip penamaan dan pengkodean variabel secara konsisten dan sistematis.\nMemahami pentingnya kesesuaian antara jenis data dan teknik analisis statistik yang akan digunakan.\n\nBab 5. Pembersihan Data:\n\nMelakukan analisis deskriptif awal untuk mengevaluasi distribusi dan karakteristik dasar data.\nMengidentifikasi dan menangani data hilang (missing value) serta outlier secara tepat untuk memastikan keakuratan analisis lanjutan.\n\nBab 6. Akuntabilitas Data:\n\nMenjelaskan pentingnya pencatatan proses analisis statistik sebagai bentuk akuntabilitas ilmiah.\nMemahami pentingnya transparansi dalam meningkatkan kualitas dan integritas penelitian psikologi.",
    "crumbs": [
      "PERSIAPAN DATA"
    ]
  },
  {
    "objectID": "2_1_jenis_data.html",
    "href": "2_1_jenis_data.html",
    "title": "4  Jenis Data",
    "section": "",
    "text": "4.1 Mengidentifikasi Jenis Data\nSebelum data dianalisis, peneliti perlu memahami terlebih dahulu jenis data yang dimiliki. Pengklasifikasian data menjadi nominal, ordinal, interval, atau rasio akan menentukan teknik statistik apa yang tepat untuk digunakan. Selain itu, proses penamaan dan pengkodean variabel juga merupakan bagian penting dalam pengelolaan data yang baik. Pengkodean yang konsisten akan memudahkan dalam proses input data, analisis, maupun interpretasi hasil. Oleh karena itu, pengenalan jenis data dan cara mengelola variabel adalah fondasi penting sebelum melangkah ke tahap analisis statistik.\nData adalah kumpulan informasi berupa angka. Informasi ini biasanya dicatat sesuai dengan definisi yang diinginkan oleh peneliti. Sebagai contoh, data tinggi badan dicatat dalam centimeter per individu untuk anak-anak usia 0-10 tahun di Indonesia. Pada data tersebut terdapat data tinggi badan anak yang dapat diolah per individu. Di saat yang sama, terdapat pula kelompok data yang lebih besar, misalnya data tinggi badan untuk wilayah DKI Jakarta, Jawa Barat, dan wilayah lainnya yang kemudian dapat diolah dan dibandingkan per wilayah.\nData disebut dengan raw score (data mentah) apabila data tersebut adalah data langsung dari partisipan, tidak dimodifikasi, dan tidak dikonversi ke dalam nilai tertentu. Contoh data mentah:\nData dapat memberikan berbagai jenis informasi yang berbeda. Misalnya, informasi dasar seperti jenis kelamin, atau informasi lainnya yang lebih rumit seperti sikap atau perasaan seseorang. Terdapat berbagai jenis data di dalam penelitian psikologi, yaitu:",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Jenis Data</span>"
    ]
  },
  {
    "objectID": "2_1_jenis_data.html#mengidentifikasi-jenis-data",
    "href": "2_1_jenis_data.html#mengidentifikasi-jenis-data",
    "title": "4  Jenis Data",
    "section": "",
    "text": "ID Partisipan\nSkor Mentah Matematika (jumlah menjawab benar dari 50 soal)\nSkor Konversi dalam rentang 0-100 (raw/50 x 100)\n\n\n\n\n1\n25\n50\n\n\n2\n35\n70\n\n\n3\n45\n90\n\n\n4\n15\n30\n\n\n5\n37\n74\n\n\n\n\n\nData kategorikal atau nominal\nData kategorikal atau nominal adalah penunjuk karakteristik, label, atau golongan pada subjek. Sebagai contoh: jenis kelamin (laki-laki dan perempuan), daerah tempat tinggal (Jakarta, Bekasi, Bogor) dan lain sebagainya. Pemberian kode pada data-data ini hanya bersifat dummy dan tidak memiliki makna apa-apa secara statistik.\nData ordinal\nSebagai contoh, pada sebuah data penelitian, laki-laki diberikan kode 0 dan perempuan kode 1. Hal ini tidak berarti perempuan memiliki nilai yang lebih tinggi daripada laki-laki, begitu pula sebaliknya. Pemberian kode ini hanya untuk kemudahan pengolahan data dan tidak berarti secara statistik. Misalnya pada jenis kelamin, nilai rata-rata (mean) tidak dapat dihitung meski laki-laki disematkan angka 0 dan perempuan disematkan angka 1.\nData interval\nData interval adalah data yang memiliki makna, terdapat informasi mengenai jarak antara satu skor dengan skor lainnya namun tidak ada informasi mengenai seberapa mutlak nilai tersebut karena titik 0 tidak definitif. Misalnya suhu udara 0o Celsius tidak berarti ‘tidak ada temperatur’. Titik tersebut adalah definisi dari kondisi di mana air membeku. Perbedaan suhu antara 30oC dan 20o C adalah 10oC. Namun, tidak dapat dikatakan bahwa 20oC adalah dua kali lebih panas daripada 10oC karena suhu tidak memiliki titik 0oC yang definitif.\nData rasio\nData rasio adalah data yang memiliki titik 0 yang mutlak sehingga jarak antara satu skor dengan skor lainnya dapat dilakukan secara definit. Sebagai contoh, berat badan 100 kilogram dapat dikatakan lebih berat dua kali lipat dibandingkan seseorang dengan berat badan 50 kg.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Jenis Data</span>"
    ]
  },
  {
    "objectID": "2_1_jenis_data.html#penamaan-dan-pengkodean-datavariabel",
    "href": "2_1_jenis_data.html#penamaan-dan-pengkodean-datavariabel",
    "title": "4  Jenis Data",
    "section": "4.2 Penamaan dan Pengkodean Data/Variabel",
    "text": "4.2 Penamaan dan Pengkodean Data/Variabel\nLangkah awal yang penting dalam mempersiapkan data adalah memberikan nama atau kode variabel dengan jelas, mudah dipahami, dan mengikuti pola penamaan yang konsisten. Penamaan variabel yang baik tidak hanya memudahkan peneliti dalam mengolah data, tetapi juga memastikan bahwa data dapat dipahami dan digunakan kembali oleh peneliti lain, terutama ketika bekerja dengan data set yang besar atau di dalam tim.\nSebagai contoh, dalam sebuah penelitian yang melibatkan tiga kali pengambilan data menggunakan dua kuesioner – EQ-5D dan PedsQL – penamaan variabel dapat menggunakan kode yang menggambarkan waktu pengambilan data dan jenis instrumen secara ringkas dan jelas. Misalnya:\n\nData pengambilan pertama diberi kode B (Baseline)\nPengambilan kedua diberi kode R (Retest),\nDan pengambilan ketiga diberi kode F (Follow-up).\n\nSelanjutnya, nama variabel dibentuk dengan menggabungkan kode waktu dan nama instrumen. Dengan demikian:\n\nUntuk pengambilan pertama dengan EQ-5D, variabel dinamai BEQ5D, dan untuk PedsQL dinamai BPedsQL.\nUntuk pengambilan kedua: REQ5D dan RPedsQL.\nDan seterusnya untuk pengambilan ketiga.\n\nPola penamaan yang konsisten seperti ini akan mempermudah proses analisis, mengurangi risiko kesalahan, serta meningkatkan transparansi dan akuntabilitas, khususnya jika pengolahan data dilakukan oleh pihak lain atau pada proyek penelitian berskala besar.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Jenis Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html",
    "href": "2_2_cleaning.html",
    "title": "5  Pembersihan Data",
    "section": "",
    "text": "5.1 Melakukan Analisis Deskriptif\nSetelah data dikumpulkan dan diklasifikasikan, langkah selanjutnya adalah memastikan data tersebut layak untuk dianalisis. Proses ini dikenal sebagai data cleaning atau pembersihan data. Dalam tahap ini, peneliti melakukan analisis deskriptif awal untuk mendapatkan gambaran umum data, serta mengecek kemungkinan adanya missing valueatau outlier yang dapat memengaruhi hasil analisis. Pembersihan data bukan hanya soal menghapus skor-skor yang tidak wajar, tetapi juga tentang membuat keputusan yang tepat berdasarkan konteks penelitian. Dengan data yang bersih, hasil analisis akan menjadi lebih akurat dan dapat dipercaya.\nSetelah peneliti memberi nama variabel dan mengidentifikasi jenis data sesuai dengan sifat masing-masing variabel, langkah berikutnya adalah melakukan analisis deskriptif awal terhadap data. Analisis deskriptif ini bertujuan untuk memastikan kualitas data sebelum masuk ke tahap analisis lebih lanjut.\nBeberapa hal penting yang perlu diperhatikan dalam tahap ini antara lain:\nDengan melakukan analisis deskriptif ini secara teliti, peneliti dapat memastikan bahwa data yang akan dianalisis lebih lanjut sudah bersih, valid, dan siap untuk digunakan, sehingga hasil penelitian menjadi lebih akurat dan dapat dipertanggungjawabkan.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html#melakukan-analisis-deskriptif",
    "href": "2_2_cleaning.html#melakukan-analisis-deskriptif",
    "title": "5  Pembersihan Data",
    "section": "",
    "text": "Memeriksa sebaran skor\nPeneliti perlu melihat apakah nilai total skor, minimum, maksimum, rata-rata (mean), dan simpangan baku (standar deviasi) dari setiap variabel berada dalam rentang yang sesuai dengan instrumen alat ukur dan sampel yang diteliti. Hal ini membantu mendeteksi adanya kesalahan input data atau anomali yang tidak sesuai dengan ekspektasi.\nMemeriksa data hilang (missing values)\nIdentifikasi jumlah dan pola missing values pada setiap variabel sangat penting, karena dapat mempengaruhi validitas hasil analisis.\nMendeteksi nilai pencilan (outliers)\nNilai-nilai pencilan dapat mengindikasikan kesalahan pencatatan data atau variasi yang ekstrem di dalam sampel. Oleh karena itu, penting untuk mengidentifikasi outlier pada tahap awal, kemudian menentukan apakah nilai tersebut merupakan bagian dari variasi alami atau justru kesalahan yang perlu diperbaiki atau dikeluarkan dari analisis.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html#data-hilang",
    "href": "2_2_cleaning.html#data-hilang",
    "title": "5  Pembersihan Data",
    "section": "5.2 Data Hilang",
    "text": "5.2 Data Hilang\nTerdapat sejumlah hal yang perlu Anda lakukan sebelum memulai analisis utama terhadap data Anda. Hal pertama adalah memeriksa apakah terdapat missing data (data hilang). Data hilang terjadi ketika terdapat pernyataan yang tidak diisi oleh seseorang yang menjawab survei atau kuesioner Anda. Partisipan mungkin tidak menjawab salah satu item pada survei karena berbagai alasan. Mereka mungkin melewatkan sebuah pertanyaan, enggan menjawab pertanyaan tertentu, atau merasa bosan dan berhenti mengisi survei. Ketidaklengkapan jawaban pada satu atau beberapa item ini menimbulkan masalah dalam analisis.\nData hilang dapat dikategorikan menjadi (1) missing completely at random (MCAR), (2) missing at random (MAR), atau (3) missing not at random (MNAR) (Buuren, 2018).\n\nMissing completely at random (MCAR) berarti probabilitas sebuah data hilang sama besar untuk semua responden. Misalnya, seseorang secara acak melewatkan satu pertanyaan di survei Anda, sehingga data hilang itu benar-benar acak.\nJika probabilitas sebuah nilai hilang hanya sama dalam kelompok-kelompok tertentu yang didefinisikan oleh data yang teramati, maka data tersebut disebut missing at random (MAR). Karena itu, MCAR dan MAR adalah konsep yang saling terkait. Sebagai contoh, ditemukan bahwa responden yang tingkat stresnya tinggi cenderung melewatkan pertanyaan tentang tidur, mungkin karena merasa pertanyaan tersebut terlalu sensitif atau tidak relevan bagi mereka dalam kondisi stres.\nJika data hilang tidak memenuhi asumsi MCAR maupun MAR, maka disebut missing not at random (MNAR). Sebagai contoh, jika sejumlah besar peserta sengaja melewati satu pertanyaan tertentu pada survei, maka hal itu tidak terjadi secara acak. Kemungkinan ada alasan tertentu mengapa pertanyaan itu dilewati, misalnya karena pertanyaan kurang jelas, terlalu pribadi, atau tersembunyi di bagian bawah halaman.\n\nTerdapat sebuah uji untuk mengetahui apakah data hilang secara acak atau tidak, yaitu Little’s MCAR test. Secara sederhana, jika hasil uji tidak signifikan, maka data hilang kemungkinan terjadi secara acak. Sebaliknya, jika hasil uji signifikan, ada kemungkinan data hilang karena alasan sistematis atau tidak acak.\nLalu, apa yang bisa dilakukan peneliti untuk menangani data hilang? Secara umum, terdapat dua cara utama untuk menangani data hilang, yaitu:\n\nPenggantian dengan rata-rata (mean replacement). Dalam prosedur ini, Anda mengganti titik data yang hilang dengan nilai rata-rata variabel tersebut. Namun, teknik ini hanya disarankan jika data hilang secara acak (at random) dan proporsinya kurang dari 5% pada variabel yang bersangkutan.\nImputasi majemuk (multiple imputation). Teknik ini dilakukan dengan bantuan program statistik yang Anda gunakan, yang menganalisis pola data dan menetapkan nilai untuk variabel yang hilang pada kasus tertentu. Nilai ini didasarkan pada jawaban sebelumnya pada variabel terkait, serta jawaban tidak hilang pada variabel tersebut di kasus lain. Disarankan menggunakan metode ini jika data hilang secara acak dengan proporsi antara 5–10% dari total respons pada variabel tersebut.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_2_cleaning.html#data-pencilan",
    "href": "2_2_cleaning.html#data-pencilan",
    "title": "5  Pembersihan Data",
    "section": "5.3 Data Pencilan",
    "text": "5.3 Data Pencilan\nSalah satu hal yang perlu diperhatikan saat menganalisis data adalah pengaruhoutlier — yaitu data yang nilainya sangat tinggi atau sangat rendah dibandingkan data lainnya — terhadap hasil keseluruhan. Contohnya, jika Anda bertanya kepada orang-orang tentang berapa cangkir kopi yang mereka minum dalam sehari, sebagian besar jawabannya mungkin berkisar antara nol hingga empat cangkir. Sebaran ini disebut dengan sebaran jawaban yang normal. Namun, jika ada satu orang yang menjawab bahwa ia minum 17 cangkir kopi sehari, maka jawaban ini bisa dianggap sebagai outlier bila dibandingkan dengan partisipan lainnya.\nKita bisa mengasumsikan bahwa orang tersebut memang memiliki masalah dengan kafein atau mungkin salah memasukkan jawaban. Apa pun alasannya, jawaban ini bisa meningkatkan rata-rata (mean) konsumsi kopi dalam sampel, padahal sebetulnya jawaban ini tidak mewakili kebiasaan rata-rata peminum kopi.\nAda beberapa cara secara statistik untuk mengidentifikasi outlier dalam kumpulan data Anda (Tabachnick & Fidell, 2014):\n\nMengubah jawaban peserta untuk setiap variabel menjadi skor-z (z-score).\nSkor-z adalah transformasi dasar untuk membandingkan jawaban peserta dengan distribusi standar yang memiliki rata-rata 0 dan standar deviasi 1.\nJika suatu jawaban memiliki skor-z lebih besar dari +3.3 atau kurang dari -3.3, maka jawaban ini dianggap sebagai outlier.\nMemvisualisasikan data menggunakan box plot atau bar graph, lalu melihat secara langsung apakah ada data yang tampak menyimpang jauh. Lihat Gambar 5.1 untuk visualisasi dari outlier menggunakan box plot.\n\n\n\n\n\n\n\nGambar 5.1: Outlier dalam boxplot\n\n\n\nSetelah menemukan outlier, Anda punya dua pilihan (Dancey & Reidy, 2017):\n\nTetap menyertakan dalam analisis jika Anda menganggap outlier ini bukan kebetulan.\nMenghapus dari analisis jika outlier ini muncul karena alasan yang tidak valid, misalnya kesalahan input atau jawaban yang tidak realistis.\n\nJika jawaban outlier tersebut tidak masuk akal dalam konteks pertanyaan, atau terlalu ekstrem tanpa alasan yang jelas, maka sebaiknya dianggap sebagai jawaban tidak valid (spurious response) dan dihapus dari analisis. Namun, jika jawaban tersebut masih masuk akal atau hanya sedikit melampaui batas skor-z (± 3.3), Anda bisa mempertimbangkannya sebagai outlier yang valid dan tetap menyertakannya dalam analisis.\n\n\n\n\nBuuren, S. van. (2018). Flexible Imputation of Missing Data. CRC Press.\n\n\nDancey, C. P., & Reidy, J. (2017). Statistics without maths for psychology (7th ed.). Pearson Education Limited.\n\n\nTabachnick, B. G., & Fidell, L. S. (2014). Using Multivariate Statistics (6th ed.). Pearson Education Limited.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Pembersihan Data</span>"
    ]
  },
  {
    "objectID": "2_3_akuntabilitas.html",
    "href": "2_3_akuntabilitas.html",
    "title": "6  Akuntabilitas Data",
    "section": "",
    "text": "Salah satu langkah penting yang sering kali terabaikan dalam pengolahan data statistik adalah mencatat secara sistematis setiap proses analisis yang dilakukan. Pencatatan ini merupakan inti dari prinsip akuntabilitas, yaitu kemampuan untuk mempertanggungjawabkan seluruh proses analisis kepada diri sendiri maupun komunitas ilmiah (Gelfond dkk., 2014). Dengan memiliki catatan lengkap, peneliti lain dapat menelusuri, memverifikasi, atau mereplikasi prosedur yang telah dilakukan, sehingga penelitian menjadi lebih transparan dan dapat dipercaya.\nPentingnya akuntabilitas semakin terasa ketika terjadi hasil yang tidak sesuai harapan atau tampak tidak wajar. Dalam situasi ini, dokumentasi proses analisis akan sangat membantu peneliti untuk menelusuri kembali langkah-langkah yang telah diambil, mengidentifikasi potensi kesalahan (seperti pengkodean yang keliru, pemilihan teknik analisis yang tidak tepat, atau salah input data), dan memperbaikinya tanpa harus mengulang seluruh proses dari awal.\nPencatatan proses analisis dapat dilakukan melalui script atau syntax di perangkat lunak statistik. Tools ini memungkinkan setiap langkah (misalnya transformasi variabel dan filtering data) untuk terekam secara otomatis dan dapat dijalankan ulang. Penggunaan syntax bukan hanya efisien, tetapi juga menciptakan audit trail yang sangat berguna dalam kerja tim atau revisi laporan.\nJika perangkat lunak yang digunakan tidak menyimpan jejak analisis secara otomatis, maka pencatatan manual menjadi penting. Hal ini bisa dilakukan dengan menuliskan setiap prosedur analisis dalam dokumen pendamping, seperti di Microsoft Word, Google Docs, atau aplikasi pencatat lain. Format catatan sebaiknya mencakup: nama file data, langkah-langkah analisis yang dilakukan, alasan memilih teknik tertentu, serta ringkasan hasil yang diperoleh.\nMenjaga akuntabilitas bukan hanya menunjukkan profesionalisme peneliti, tetapi juga mendukung prinsip replikasi, transparansi, dan validitas ilmiah. Dokumentasi proses analisis dianggap sebagai bagian dari etika penelitian, terutama di era open science. Oleh karena itu, mahasiswa perlu membiasakan diri untuk tidak hanya fokus pada hasil akhir, tetapi juga menaruh perhatian serius pada proses yang ditempuh untuk sampai ke hasil tersebut.\n\n\n\n\nGelfond, J. A. L., Klugman, C. M., Welty, L. J., Heitman, E., Louden, C., & Pollock, B. H. (2014). How to Tell the Truth with Statistics: The Case for Accountable Data Analyses in Team-based Science. Journal of translational medicine & epidemiology, 2.",
    "crumbs": [
      "PERSIAPAN DATA",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Akuntabilitas Data</span>"
    ]
  },
  {
    "objectID": "2_latihan.html",
    "href": "2_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bagian 2 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "PERSIAPAN DATA",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "3_deskriptif.html",
    "href": "3_deskriptif.html",
    "title": "STATISTIK DESKRIPTIF",
    "section": "",
    "text": "Setelah data dikumpulkan dan dipersiapkan, langkah selanjutnya dalam proses analisis adalah memahami karakteristik umum dari data tersebut. Bab ini membahas tentang statistik deskriptif, yaitu serangkaian teknik yang digunakan untuk merangkum, menyederhanakan, dan menyajikan data mentah menjadi informasi yang lebih mudah dipahami. Statistik deskriptif tidak berfokus pada pengambilan keputusan atau generalisasi, melainkan pada penggambaran pola, kecenderungan, dan sebaran data yang ada.\nBab ini terdiri dari tiga bagian utama. Pertama, pembahasan mengenai ukuran pemusatan data (central tendency), mencakup mean (rata-rata), median, dan modus yang menggambarkan nilai pusat dari sekumpulan data. Kedua, penjelasan tentang sebaran data (dispersi) yang mencakup rentang, varians, dan standar deviasi untuk memahami seberapa jauh data menyebar dari pusatnya. Terakhir, akan dibahas mengenai bentuk distribusi data, termasuk konsep simetri, skewness, dan kurtosis, yang penting untuk mengetahui apakah data berdistribusi normal atau memiliki penyimpangan tertentu.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 7. Ukuran Pemusatan Data:\n\nMenjelaskan konsep ukuran pemusatan data dan peranannya dalam menggambarkan nilai pusat data.\nMenghitung dan menginterpretasikan mean, median, dan modus dari data.\nMemilih ukuran pemusatan data yang paling tepat berdasarkan karakteristik distribusi data.\n\nBab 8. Pembersihan Data:\n\nMelakukan analisis deskriptif awal untuk mengevaluasi distribusi dan karakteristik dasar data.\nMengidentifikasi dan menangani data hilang (missing value) serta outlier secara tepat untuk memastikan keakuratan analisis lanjutan.\n\nBab 6. Akuntabilitas Data:\n\nMenjelaskan pentingnya pencatatan proses analisis statistik sebagai bentuk akuntabilitas ilmiah.\nMemahami pentingnya transparansi dalam meningkatkan kualitas dan integritas penelitian psikologi.",
    "crumbs": [
      "STATISTIK DESKRIPTIF"
    ]
  },
  {
    "objectID": "3_1_sentral.html",
    "href": "3_1_sentral.html",
    "title": "7  Ukuran Pemusatan Data",
    "section": "",
    "text": "7.1 Mean\nBayangkan, Anda sedang melakukan pengamatan terhadap hasil belajar di satu sekolah, misalnya pelajaran matematika dari 150 anak kelas X. Dari daftar nilai itu, Anda mempunyai informasi mengenai nilai dari setiap anak. Namun, bagaimana Anda akan mengatakan kepada khalayak, mengenai capaian nilai matematika dari ke-150 anak ini? Seberapa baik capaian tersebut? Untuk menjawabnya, Anda memerlukan satu perwakilan angka yang dapat dinilai sebagai baik, cukup atau buruk. Inilah yang disebut dengan konsep central tendency atau ukuran pemusatan data, yaitu satu angka yang menjadi ukuran sentral dari semua kumpulan angka yang diwakilinya. Terdapat tiga macam ukuran sentral, yaitu mean, median dan modus.\nMean (rerata) merupakan ukuran tendensi sentral yang paling umum digunakan karena mempertimbangkan semua nilai dalam distribusi. Mean diperoleh dengan cara menjumlahkan seluruh nilai data dibagi dengan banyaknya data. Mean sangat sensitif terhadap nilai ekstrem (outlier) yang dapat memengaruhi hasilnya secara signifikan.\nMisalnya kita memperoleh data dari 10 orang seperti di bawah ini:\nSetiap angka menggambarkan skor dari setiap orang. Berikut adalah cara menghitung mean dari data tersebut:\n\\[\n\\text{Mean} \\;=\\; \\frac{\\sum x}{n} \\;=\\; \\frac{4+4+6+6+7+4+7+3+5+4}{10} \\;=\\; \\frac{50}{10} \\;=\\; 5\n\\]",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "3_1_sentral.html#mean",
    "href": "3_1_sentral.html#mean",
    "title": "7  Ukuran Pemusatan Data",
    "section": "",
    "text": "4\n4\n6\n6\n7\n4\n7\n3\n5\n4",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "3_1_sentral.html#median",
    "href": "3_1_sentral.html#median",
    "title": "7  Ukuran Pemusatan Data",
    "section": "7.2 Median",
    "text": "7.2 Median\nMedian adalah nilai tengah dari data yang telah diurutkan dari yang terkecil ke terbesar. Jika jumlah data ganjil, median adalah nilai di posisi tengah; jika genap, median adalah rata-rata dari dua nilai tengah. Median berguna ketika data mengandung pencilan atau distribusinya tidak simetris, karena tidak terpengaruh oleh nilai-nilai ekstrem.\nMenggunakan data yang sama dengan yang di atas, maka untuk memperoleh nilai median kita perlu mengurutkan data dari yang paling kecil hingga yang paling besar. Nilai median merupakan nilai yang ada di tengah dari urutan data tersebut. Sehingga, dari data tersebut, dapat ditentukan bahwa nilai median adalah sebagai berikut:\n\n\n\n3\n4\n4\n4\n4\n5\n6\n6\n7\n7\n\n\n\nMengingat jumlah data yang diperoleh genap (10), maka nilai median dihitung dengan menghitung rata-rata dari dua nilai yang berada di tengah. Dalam hal ini, maka median dari data adalah:\n\\[\n\\text{Median} \\;=\\; \\frac{4+5}{2} \\;=\\; 4.5\n\\]",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "3_1_sentral.html#modus",
    "href": "3_1_sentral.html#modus",
    "title": "7  Ukuran Pemusatan Data",
    "section": "7.3 Modus",
    "text": "7.3 Modus\nModus adalah nilai yang paling sering muncul dalam suatu kumpulan data. Tidak seperti mean dan median, modus bisa digunakan pada data kategorikal dan dapat memiliki lebih dari satu nilai (bimodal atau multimodal). Modus cocok digunakan untuk mengidentifikasi nilai yang paling umum dalam suatu populasi atau kelompok.\nLangkah penting untuk memperoleh nilai modus dalam kelompok data adalah dengan membuat tabel distribusi frekuensi. Tabel ini berfungsi untuk mengidentifikasi nilai, skor, atau data apa yang paling sering muncul (frekuensi tertinggi). Masih menggunakan data yang sama dengan yang di atas, perlu dibuat tabel distribusi frekuensi sebagai berikut:\n\n\n\nNilai\nFrekuensi\n\n\n\n\n3\n1\n\n\n4\n4\n\n\n5\n1\n\n\n6\n2\n\n\n7\n2\n\n\n\nBerdasarkan pengelompokan data berdasarkan frekuensi kemunculannya yang ditampilkan pada tabel Distribusi frekuensi tersebut, maka kita dapat menentukan bahwa nilai Modus dari data adalah 4.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ukuran Pemusatan Data</span>"
    ]
  },
  {
    "objectID": "3_2_dispersi.html",
    "href": "3_2_dispersi.html",
    "title": "8  Ukuran Penyebaran Data",
    "section": "",
    "text": "8.1 Range\nSetelah mengetahui nilai pusat dari suatu data melalui ukuran pemusatan data, langkah berikutnya adalah memahami seberapa jauh data menyebar dari nilai pusat tersebut. Ukuran penyebaran data, atau dispersi, memberikan informasi penting tentang variasi atau keragaman dalam kumpulan data. Dua set data bisa memiliki mean yang sama, tetapi penyebarannya bisa sangat berbeda, dan perbedaan ini dapat memengaruhi cara interpretasi data secara keseluruhan. Dalam sub-bab ini, akan dibahas beberapa ukuran utama penyebaran, yaitu rentang (range), standar deviasi, dan varians, yang membantu menggambarkan tingkat homogenitas atau heterogenitas suatu data secara lebih mendalam.\nRange, atau rentang data, adalah selisih antara nilai tertinggi dengan nilai terendah dalam sebuah set data. Range menunjukkan seberapa lebar sebaran nilai dalam data, namun karena hanya mempertimbangkan dua nilai ekstrem, ukuran ini sangat sensitif terhadap outlier dan tidak menggambarkan variasi data secara keseluruhan. Meskipun demikian, range tetap berguna sebagai gambaran awal tentang sebaran data.\nUntuk dapat memahami fungsi range dalam memahami set data, mari kita pelajari kasus berikut ini. Misalnya, seorang peneliti memiliki data nilai tugas mata pelajaran Matematika dari 3 kelas yang berbeda:\nPertanyaan penting mengenai data tersebut adalah apakah ketiga kelas tersebut memperoleh capaian belajar yang sama. Jika hanya mengandalkan nilai rata-rata, maka ketiga kelas tersebut akan tampak sama karena memiliki nilai rata-rata yang sama, yaitu 5. Padahal jika dilihat ke perolehan nilai individual, terlihat berbeda. Nilai range pada data dapat membantu kita untuk menggambarkan seberapa berbeda dan bervariasi data yang dimiliki dan makna variasi tersebut dalam memahami setiap poin data. Untuk itu, kita perlu menghitung selisih skor terbesar dengan skor terkecil untuk setiap data kelas.\n\\[\n\\begin{aligned}\nRange\\; kelas\\; A &= nilai\\; tertinggi - nilai\\; terendah = 7 -3 = 4\\\\\nRange\\; kelas\\; B &= nilai\\; tertinggi - nilai\\; terendah = 8 -2 = 6\\\\\nRange\\; kelas\\; C &= nilai\\; tertinggi - nilai\\; terendah = 6 -2 = 4\n\\end{aligned}\n\\]\nDari hasil penghitungan, dapat dilihat bahwa kelas B memiliki lebar data yang paling besar, artinya terdapat perbedaan atau variasi yang lebih besar di dalam kelas tersebut dibandingkan dengan kelas-kelas lainnya. Sebaliknya, kelas C memiliki rentang skor paling kecil di antara ketiganya. Dalam hal ini, satu skor yang sama (misalnya, 4) dapat dimaknai secara berbeda berdasarkan nilai range tiap kelas.\nSatu hal yang perlu diingat adalah bahwa variasi skor yang digambarkan dalam range hanya menunjukkan perbedaan antara yang mendapatkan nilai paling tinggi dan yang mendapatkan nilai paling rendah. Dari nilai range tersebut kita tidak memiliki informasi mengenai seberapa besar ukuran variabilitas (atau seberapa bervariasi) sebuah set data. Untuk mendapatkan gambaran ini, kita menggunakan ukuran penyebaran data berikutnya, yaitu varians.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_2_dispersi.html#range",
    "href": "3_2_dispersi.html#range",
    "title": "8  Ukuran Penyebaran Data",
    "section": "",
    "text": "Kelas A\n\n4\n4\n6\n6\n7\n4\n7\n3\n5\n4\n\n\nKelas B\n\n2\n6\n6\n7\n7\n8\n4\n4\n3\n3\n\n\nKelas C\n\n6\n5\n6\n4\n5\n6\n4\n4\n5\n5",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_2_dispersi.html#varians",
    "href": "3_2_dispersi.html#varians",
    "title": "8  Ukuran Penyebaran Data",
    "section": "8.2 Varians",
    "text": "8.2 Varians\nVarians (s2) adalah ukuran penyebaran data yang menunjukkan seberapa jauh nilai-nilai dalam suatu kumpulan data menyimpang dari nilai mean. Varians dihitung dengan menjumlahkan kuadrat selisih setiap nilai (X) terhadap mean (\\(\\bar{x}\\)), kemudian dibagi dengan jumlah data (N) (untuk populasi) atau jumlah data dikurangi satu (n-1) (untuk sampel). Dapat juga ditulis sebagai:\n\\[\ns^2 = \\frac{\\sum (X - \\bar{x})^2}{N - 1}\n\\]\nHasil varians menunjukkan “rata-rata kuadrat penyimpangan” dari mean, sehingga semakin besar nilai varians, semakin besar pula variasi data di sekitar mean. Dengan kata lain, varians juga menggambarkan homogenitas data, di mana semakin kecil varians maka semakin kecil perbedaan antar poin data, dan sebaliknya semakin besar varians semakin besar pula perbedaan antar poin data.\nSebagai ilustrasi, misalnya terdapat data set skor skala sikap dari dua kelompok partisipan yang berbeda (a & b), dengan masing-masing sebaran data sebagai berikut:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKelompok a\n\n6\n6\n6\n6\n7\n7\n7\n7\n7\n8\n8\n8\n\\(\\bar{x}\\)=6.9\n\n\nKelompok b\n\n2\n3\n5\n5\n6\n6\n6\n7\n9\n9\n10\n12\n\\(\\bar{x}\\)=6.7\n\n\n\nUntuk dapat memperoleh nilai varians, kita perlu menghitung simpangan atau selisih dari setiap data poin terhadap mean kemudian dikuadratkan, seperti pada Tabel 8.1.\n\n\nTabel 8.1: Perhitungan simpangan dan varians dua kelompok\n\n\n\n\n\n\n\n  \n\n\n\nKelompok a\nKelompok b\n\n\nSkor (X)\nSimpangan (X − x̄)\nKuadrat simpangan (X − x̄)²\nSkor (X)\nSimpangan (X − x̄)\nKuadrat simpangan (X − x̄)²\n\n\n\n\n6\n-0.9\n0.81\n2\n-4.7\n22.09\n\n\n6\n-0.9\n0.81\n3\n-3.7\n13.69\n\n\n6\n-0.9\n0.81\n5\n-1.7\n2.89\n\n\n6\n-0.9\n0.81\n5\n-1.7\n2.89\n\n\n7\n0.1\n0.01\n6\n-0.7\n0.49\n\n\n7\n0.1\n0.01\n6\n-0.7\n0.49\n\n\n7\n0.1\n0.01\n6\n-0.7\n0.49\n\n\n7\n0.1\n0.01\n7\n0.3\n0.09\n\n\n7\n0.1\n0.01\n9\n2.3\n5.29\n\n\n8\n1.1\n1.21\n9\n2.3\n5.29\n\n\n8\n1.1\n1.21\n10\n3.3\n10.89\n\n\n8\n1.1\n1.21\n12\n5.3\n28.09\n\n\nΣ(X − x̄)²\n6.92\nΣ(X − x̄)²\n92.68\n\n\ns² =  Σ(X − x̄)² N − 1 \n0.6\ns² =  Σ(X − x̄)² N − 1 \n8.4\n\n\n\n\n\n\n\nDari hasil penghitungan tersebut, kita menemukan perbedaan varians yang cukup besar antara kedua kelompok, meskipun mean keduanya tidak jauh berbeda. Hal ini menandakan bahwa kelompok b memiliki sebaran data yang jauh lebih beragam (heterogen) dibandingkan kelompok a (lihat Gambar 8.1). Oleh karena itu, pemaknaan terhadap nilai mean tiap kelompok juga berbeda, relatif terhadap variansnya masing-masing.\nVarians memiliki fungsi penting dalam memahami keragaman atau variasi data di sekitar nilai rata-rata. Informasi ini sangat berguna untuk a) menilai konsistensi data (misalnya, dua kelompok dengan rata-rata yang sama bisa memiliki varians yang berbeda; kelompok dengan varians kecil berarti anggotanya lebih homogen.) dan b) dasar dari analisis statistik lanjutan, di mana varians menjadi komponen penting dalam berbagai teknik analisis, seperti standar deviasi, analisis varians (ANOVA), uji-t, dan regresi. Dengan demikian, varians bukan hanya ukuran penyebaran, tetapi juga alat untuk mengevaluasi struktur dan kualitas data sebelum melakukan interpretasi atau pengambilan keputusan lebih lanjut.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_2_dispersi.html#standar-deviasi",
    "href": "3_2_dispersi.html#standar-deviasi",
    "title": "8  Ukuran Penyebaran Data",
    "section": "8.3 Standar Deviasi",
    "text": "8.3 Standar Deviasi\nStandar deviasi (s) adalah ukuran penyebaran data yang menunjukkan rata-rata penyimpangan (deviasi) nilai data dari mean. Ukuran ini memberikan gambaran yang lebih intuitif tentang seberapa besar variasi dalam data. Artinya, semakin besar standar deviasi, semakin lebar sebaran data dari nilai tengahnya. Standar deviasi diperoleh dengan mengambil akar kuadrat dari varians:\n\\[\ns = \\sqrt{s^2}\n\\]\nDengan menggunakan data pada pembahasan varians, kita dapat menghitung standar deviasi dari data tiap kelompok, yaitu:\nKelompok a: \\(s = \\sqrt{s^2} = \\sqrt{0.6} = 0.77\\)\nKelompok a: \\(s = \\sqrt{s^2} = \\sqrt{8.4} = 2.90\\)\nHasil penghitungan standar deviasi di atas memperkuat pemahaman bahwa Kelompok a lebih homogen (s = 0,77) dibandingkan Kelompok b yang lebih bervariasi (s = 2,90). Meskipun informasi ini serupa dengan yang diperoleh dari varians (0,6 vs 8,4), standar deviasi lebih mudah diinterpretasikan karena satuannya kembali ke satuan asli data, tidak dalam bentuk kuadrat seperti varians. Dengan demikian, standar deviasi memberikan gambaran yang lebih intuitif tentang jarak rata-rata setiap data dari mean, sehingga lebih sering digunakan dalam pelaporan dan interpretasi hasil statistik.\n\n\n\n\n\n\nGambar 8.1: Visualisasi data dengan: a) varians kecil & b) varians besar",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Ukuran Penyebaran Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html",
    "href": "3_3_distribusi.html",
    "title": "9  Bentuk Distribusi Data",
    "section": "",
    "text": "9.1 Kurva Normal\nSetiap nilai dalam sekumpulan data memiliki frekuensi kemunculan yang berbeda-beda; nilai ekstrem biasanya muncul lebih jarang, sedangkan nilai yang mendekati mean lebih sering muncul. Pola ini membentuk distribusi data, yang jika digambarkan dalam grafik seperti poligon frekuensi, akan membentuk kurva. Pada distribusi yang ideal, yaitu distribusi normal, kurva berbentuk lonceng (bell-shaped) dan simetris di sekitar nilai ukuran pemusatan data seperti mean atau median. Namun, pada kenyataannya, data bisa saja miring (skewed) jika nilai-nilai terkonsentrasi di satu sisi, atau memiliki kurtosis jika kurvanya lebih runcing atau lebih datar dari distribusi normal. Pemahaman tentang bentuk distribusi ini penting karena banyak analisis statistik, terutama yang bersifat inferensial, mengasumsikan bahwa data terdistribusi normal. Untuk itu, bagian-bagian berikut akan membahas lebih lanjut mengenai kurva normal, skewness, kurtosis, dan z-score sebagai alat untuk menstandarkan data.\nSeperti telah disampaikan sebelumnya, distribusi data dapat dikatakan normal jika kurvanya membentuk lonceng dan simetris. Pada distribusi data yang demikian, frekuensi dari setiap nilai data tersebar secara simetris antara yang terletak di atas tendensi sentral dan yang di bawah tendensi sentral. Data tersebar 50% di atas dan 50% di bawah tendensi sentral, dengan frekuensi yang semakin mengecil pada nilai data yang semakin ekstrem, baik yang kecil maupun yang besar (lihat Gambar 9.1).\nPada kurva normal, tiga pengukuran data terpusat (mean, median, dan modus) berada pada satu titik atau nilai yang relatif sama. Dari Gambar 9.1 dapat lebih terlihat jelas bahwa 50% data tersebar di atas tendensi sentral dan 50% data tersebar di bawah tendensi sentral, di mana semakin jauh dari tendensi sentral maka semakin sedikit frekuensinya.\nUntuk menjawab masalah-masalah tertentu, kita perlu mencari besaran frekuensi sebuah nilai atau cakupan nilai berdasarkan sebaran data yang ada. Misalnya, kita ingin memperkirakan ada berapa jumlah mahasiswa yang nilai ujiannya antara 70 dan 85, di mana nilai mean = 80 SD = 5, dan N = 250. Dengan memanfaatkan informasi standar deviasi (s), proporsi frekuensi data pada distribusi normal dapat kita hitung berdasarkan luas area dalam kurva. Gambar 9.2 menunjukkan besaran proporsi frekuensi pada data dilihat dari luas area berdasarkan nilai standar deviasi.\nDari kurva normal yang ditampilkan pada Gambar 3.3, kita dapat mengetahui bahwa setiap belahan kurva dibagi menjadi 4 area berdasarkan standar deviasi, yaitu (1) mean – +/- 1 SD (34,1%), 1 SD – 2 SD (13,6%), 2 SD – 3 SD (2,1%), dan &gt; 3 SD (0,1%). Artinya, proporsi terbanyak dari data adalah nilai-nilai yang mendekati mean, dan sebaliknya, semakin jauh dari mean maka proporsinya semakin kecil, terutama untuk nilai-nilai ekstrem (&gt; +/- 3 SD).\nProporsi frekuensi data dengan nilai antara mean hingga 1 SD di bawah mean adalah sebesar 34,1% dari keseluruhan data, begitu juga dengan yang 1 SD di atas mean. Selanjutnya, jika kita ingin mengetahui proporsi frekuensi data antara mean hingga 2 SD di atas mean, maka kita menjumlahkan proporsi (mean – 1 SD) + (1 SD – 2 SD) = 34,1% + 13,6% = 47,7%.\nDengan demikian, untuk menjawab pertanyaan sebelumnya (proporsi mahasiswa yang memperoleh nilai ujian 70 (X1) – 85 (X2) dengan mean = 80, SD = 5, dan N = 250), maka kita menghitungnya dengan mencari besaran SD dari batas bawah dan atas rentang skor:\nX1 - mean = 70 – 80 = -10; karena SD = 5, maka skor 70 = -2SD\nX2 - mean = 85 – 80 = 5; karena SD = 5, maka skor 85 = 1SD\nMaka, proporsi X1 – X2 = (proporsi -2SD – mean) + (proporsi mean – 1SD)\n= (13,6% + 34,1%) + (34,1%)\n= 81,8%\nSehingga, jumlah mahasiswa dengan skor antara 70 – 85 = 81,8% × 250 orang = 204 orang (pembulatan).",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#kurva-normal",
    "href": "3_3_distribusi.html#kurva-normal",
    "title": "9  Bentuk Distribusi Data",
    "section": "",
    "text": "Gambar 9.1: Bentuk kurva normal\n\n\n\n\n\n\n\n\n\n\n\nGambar 9.2: Proporsi sebaran data pada kurva normal",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#skewness",
    "href": "3_3_distribusi.html#skewness",
    "title": "9  Bentuk Distribusi Data",
    "section": "9.2 Skewness",
    "text": "9.2 Skewness\nData pada sampel yang diambil dari populasi penelitian tidak selalu terdistribusi secara normal. Sebaran yang tidak normal ini seringnya terjadi pada sekumpulan data yang memiliki nilai ekstrem (outlier) yang proporsinya cukup jauh melebihi data yang tersebar secara normal. Besarnya outlier ini membuat sebaran data seolah-olah terpusat di bawah nilai tengah, atau sebaliknya terpusat di atas nilai tengah.\nJika data yang tersebar secara normal membentuk kurva berbentuk lonceng yang simetris, maka data yang tidak normal tersebut bisa membentuk kurva yang miring atau juling (skewed). Arah kemiringan (skewness) kurva bergantung pada besaran frekuensi data yang menyimpang dari nilai tengah. Jika frekuensi nilai yang berada di bawah mean jauh lebih kecil daripada frekuensi nilai di atas mean, maka puncak kurva akan condong ke kanan, yang disebut sebagai skew negatif (Gambar 10.1 (a)). Sebaliknya, jika frekuensi nilai yang berada di bawah mean jauh lebih besar daripada frekuensi nilai di atas mean, maka puncak kurva akan condong ke kiri, yang disebut sebagai skew positif (Gambar 10.1 (b)).\n\n\n\n\n\n\n\n\n\n\n\n(a) Skew negatif\n\n\n\n\n\n\n\n\n\n\n\n(b) Skew positif\n\n\n\n\n\n\n\nGambar 9.3: Distribusi skewed\n\n\n\nTerdapat dua cara yang umum digunakan untuk mengetahui arah kemiringan (skewness) dari sebuah distribusi data, yaitu dengan (a) menggunakan rumus Pearson, dan (b) membandingkan nilai-nilai ukuran pemusatan data.\n\nRumus Pearson:\n\\[\n\\text{Skewness} = 3 \\times \\frac{\\text{Mean} - \\text{Median}}{\\text{SD}}\n\\]\nJika hasil penghitungan nilai skewness adalah positif, maka disebut dengan kurva skewed positif. Jika hasil hitungnya negatif, maka disebut dengan kurva skewed negatif. Apabila hasil hitungnya (mendekati) nol, maka disebut dengan kurva normal. Tidak ada angka pasti, seberapa dekat dengan nol dapat disebut sebagai kurva normal, tetapi kesepakatan umum adalah ± 0,5.\nMembandingkan nilai ukuran pemusatan data\nJika mean lebih kecil dari median, maka bentuk distribusinya adalah skewed negatif. Sebaliknya, jika mean lebih lebih besar dari median, maka bentuk distribusinya adalah skewed positif. Namun, jika mean, median, dan modus berada pada satu titik yang relatif sama atau berdekatan, maka bentuk distribusi datanya adalah normal (Gambar 9.4).\n\n\n\n\n\n\n\nGambar 9.4: Skewness data berdasarkan lokasi tendensi sentral",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#kurtosis",
    "href": "3_3_distribusi.html#kurtosis",
    "title": "9  Bentuk Distribusi Data",
    "section": "9.3 Kurtosis",
    "text": "9.3 Kurtosis\nKurtosis adalah seberapa berbeda bentuk kurva dari kurva normal, dilihat dari seberapa tebal-tipis bagian ekor dari kurva tersebut. Selain dilihat dari ekor kurva, kurtosis sebenarnya juga menunjukkan seberapa tajam bentuk puncak dari kurva. Terdapat tiga bentuk kurtosis, yaitu normal, ekor panjang (heavy-tailed) dan ekor pendek (light-tailed) (Gambar 9.5).\n\n\n\n\n\n\nGambar 9.5: Visualisai kurtosis dalam distribusi data\n\n\n\nKurtosis pada distribusi data yang normal adalah ketika ekor kurva tersebar secara proporsional dan puncak kurva tidak terlalu curam maupun terlalu landai. Jika nilai kurtosis &gt; 0, maka kurva akan memiliki ekor yang pendek dan puncak yang curam, menandakan data menumpuk di nilai-nilai sekitar nilai tengah. Sebaliknya, jika nilai kurtosis &lt; 0 maka ekor kurva akan memanjang dan puncaknya melandai, yang artinya hampir seluruh nilai memiliki frekuensi atau jumlah kejadian yang serupa. Kurva yang menunjukkan baik ekor panjang maupun ekor pendek menandakan bahwa data tidak terdistribusi secara normal.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_3_distribusi.html#z-score",
    "href": "3_3_distribusi.html#z-score",
    "title": "9  Bentuk Distribusi Data",
    "section": "9.4 Z-Score",
    "text": "9.4 Z-Score\nz-score, yang dikenal juga dengan nama skor baku, menunjukkan posisi sebuah skor dibandingkan dengan rata-rata dalam satuan standar deviasi. Dengan kata lain, z-score menyatakan posisi relatif suatu nilai (X) dalam distribusi data. z = nol berarti nilai tersebut tepat di mean, z-score negatif menandakan bahwa nilainya lebih rendah dari mean, dan z-score positif berarti nilainya di atas mean. z-score dapat dihitung dengan cara:\n\\[\nz = \\frac{X - \\bar{x}}{\\text{SD}}\n\\]\nTujuan utama penggunaan z-score adalah untuk menstandarkan data, sehingga memungkinkan perbandingan antar nilai dari distribusi yang berbeda. Sebagai analogi, kita tidak bisa menilai mana yang memiliki nilai yang lebih tinggi antara nilai dua mata uang yang berbeda (misalnya, 10 Rupee India dengan 10 Baht Thailand) tanpa mengkonversinya ke dalam satuan mata uang yang sama atau standar.\nDalam hal data, dua nilai dari distribusi yang berbeda (misalnya, nilai 8 pada subtes aritmatika dan nilai 8 pada subtest logika numerikal) bisa jadi memiliki posisi yang berbeda dalam distribusi data masing-masing, sehingga tidak dapat dibandingkan secara langsung. Oleh karena itu, kedua nilai tersebut perlu ditransformasi ke z-score agar memiliki satuan yang sama untuk dapat dibandingkan.\nz-score juga bermanfaat dalam mendeteksi outlier, serta dalam berbagai analisis statistik lanjutan seperti uji hipotesis dan analisis distribusi normal. Karena z-score mengubah data ke skala yang seragam, ia menjadi alat penting dalam interpretasi dan generalisasi hasil penelitian.",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Bentuk Distribusi Data</span>"
    ]
  },
  {
    "objectID": "3_latihan.html",
    "href": "3_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bagian 3 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "STATISTIK DESKRIPTIF",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "4_inferensial.html",
    "href": "4_inferensial.html",
    "title": "STATISTIK INFERENSIAL",
    "section": "",
    "text": "Statistik inferensial merupakan salah satu cabang dalam statistik yang digunakan untuk mengambil kesimpulan. Berbeda dengan statistik deskriptif yang lebih bertujuan untuk menyajikan data secara ringkas dan mudah dipahami pembaca, statistik inferensial merupakan teknik perhitungan yang ditujukan untuk dapat lebih melihat makna dari pola-pola yang ditunjukkan oleh data. Misalnya, dari dua set ada yang ada, dengan statistik inferensial ini dapat kita lihat apakah menunjukkan pola teratur yang konsisten sehingga dapat dikatakan terdapat keterkaitan antara dua set data itu. Contoh lainnya, dengan statistik inferensial, kita dapat membandingkan dua set data sehingga kita tahu apakah dua set data itu benar-benar berbeda atau hanya tampak berbeda.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 10. Statistik Parametrik dan Non-Parametrik:\n\nMemahami perbedaan antara statistik parametrik dan non-parametrik\n\nBab 11. Statistical Power:\n\nMemahami konsep statistical power sebagai probabilitas mendeteksi efek yang benar-benar ada.\nMenjelaskan Eror Tipe I & Eror Tipe II dalam statistik\n\nBab 12. Pengujian Hipotesis:\n\nMemahami konsep dasar jenis-jenis hipotesis penelitian dan hipotesis statistik.\n\nBab 13. Signifikansi Statistik dan p-value:\n\nMenjelaskan arti & interpretasi p-value, serta hubungannya dengan tingkat signifikansi.\n\nBab 14. Confidence Interval:\n\nMemahami konsep confidence interval dan level of confidence dalam estimasi parameter populasi.\n\nBab 15. Effect Size:\n\nMenjelaskan konsep dan intepretasi nilai effect size sebagai ukuran besarnya pengaruh atau hubungan dalam data.",
    "crumbs": [
      "STATISTIK INFERENSIAL"
    ]
  },
  {
    "objectID": "4_1_parametrik.html",
    "href": "4_1_parametrik.html",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "",
    "text": "10.1 Asumsi Parametrik\nDalam statistik inferensial, metode analisis dapat dibedakan menjadi dua kelompok besar, yaitu statistik parametrik dan statistik non-parametrik. Pemilihan metode ini berpengaruh pada validitas hasil analisis karena masing-masing memiliki asumsi dan prinsip kerja yang berbeda. Meskipun keduanya bertujuan untuk menarik kesimpulan dari data sampel ke populasi, perbedaan pendekatan dapat memengaruhi akurasi dan kekuatan analisis.\nMetode analisis parametrik bekerja dengan optimal jika data memiliki distribusi normal (lihat Bab 9). Karena berbagai prosedur parametrik—seperti estimasi parameter dan pengujian hipotesis—mengandalkan sifat distribusi normal, penyimpangan yang besar dari normalitas dapat membuat hasil analisis menjadi bias atau kurang akurat. Oleh karena itu, sebelum menggunakan metode parametrik, peneliti perlu memeriksa apakah data mendekati distribusi normal melalui uji statistik maupun pemeriksaan visual.\nPemeriksaan melalui metode visual bisa dilihat berdasarkan kurva sebaran data. Salah satu yang paling umum digunakan adalah grafik histogram. Jika histogram tampak seperti lonceng, maka distribusi data tersebut dikatakan normal. Sebaliknya, jika terdapat kemiringan sehingga kurva terlihat jelas tidak simetris, maka data tidak terdistribusi dengan normal (lihat Gambar 10.1).\nMetode pengujian statsitik dapat menjadi cara yang paling akurat untuk menentukan normalitas distribusi data. Terdapat dua uji statistik yang cukup umum digunakan digunakan dalam konteks riset ilmu sosial, yaitu Kolmogorov-Smirnov (KS) dan Shapiro-Wilk (SW). Sejumlah studi mengungkapkan bahwa uji SW lebih andal dibanding KS karena memiliki daya uji (power) yang lebih tinggi dalam mendeteksi berbagai bentuk penyimpangan dari normalitas, baik akibat skewness maupun kurtosis, pada hampir semua ukuran sampel dan jenis distribusi (M. A., 2014; Razali & Wah, 2011; Yap & Sim, 2011). Oleh karena itu, tes SW lebih disarankan untuk digunakan dalam pengujian normalitas distribusi data.\nData yang memenuhi asumsi parametrik dapat dianalisis lebih lanjut dengan statistik parametrik, sedangkan data yang tidak memenuhi asumsi dianalisis dengan menggunakan teknik statistik non-parametrik. Konsekuensi hasil analisisnya adalah pada generalisasi hasil analsis data. Pada statistik parameterik — karena data sampel terdistibusi normal — maka data tersebut dianggap mewakili populasi, sehingga setiap hasil analisis data tersebut dapat digenerasilasikan kepada populasinya. Dengan kata lain, hasil analisis data dianggap mencerminkan populasinya. Sedangkan jika data tidak memenuhi asumsi dan kemudian dianalisis dengan statistik non-parametrik, maka hasilnya tidak dapat disebut mencerminkan populasi, melainkan hanya menggambarkan sekelompok partisipan penelitian tersebut.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_1_parametrik.html#asumsi-parametrik",
    "href": "4_1_parametrik.html#asumsi-parametrik",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "",
    "text": "(a) Distribusi normal\n\n\n\n\n\n\n\n\n\n\n\n(b) Distribusi tidak normal\n\n\n\n\n\n\n\nGambar 10.1: Kurva distribusi data",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_1_parametrik.html#metode-parametrik",
    "href": "4_1_parametrik.html#metode-parametrik",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "10.2 Metode Parametrik",
    "text": "10.2 Metode Parametrik\nMetode parametrik adalah pendekatan analisis statistik yang mendasarkan perhitungannya pada parameter populasi yang diestimasi dari data sampel, seperti mean, varians, dan standar deviasi. Metode ini beroperasi di bawah asumsi bahwa data berasal dari populasi dengan distribusi tertentu, umumnya distribusi normal, sehingga sifat-sifat distribusi tersebut dapat digunakan untuk membangun model matematis yang akurat. Proses analisis dalam metode parametrik biasanya melibatkan penggunaan rumus yang memanfaatkan parameter-parameter ini untuk menghitung ukuran efek, menguji hipotesis, atau membuat estimasi terhadap populasi.\nKelebihan utama metode parametrik adalah presisi dan kekuatan statistik yang tinggi, artinya metode ini lebih mampu mendeteksi perbedaan atau hubungan yang benar-benar ada dalam data, asalkan asumsi normalitas terpenuhi. Hal ini karena informasi yang digunakan berasal dari seluruh nilai data, bukan hanya peringkat atau kategori. Akan tetapi, jika asumsi distribusi dilanggar—misalnya data tidak normal atau mengandung outlier ekstrem—maka metode parametrik bisa menghasilkan estimasi yang bias dan kesimpulan yang menyesatkan. Oleh sebab itu, pengujian asumsi, khususnya normalitas, menjadi langkah krusial sebelum memilih metode ini.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_1_parametrik.html#metode-non-parametrik",
    "href": "4_1_parametrik.html#metode-non-parametrik",
    "title": "10  Statistik Parametrik dan Non-Parametrik",
    "section": "10.3 Metode Non-Parametrik",
    "text": "10.3 Metode Non-Parametrik\nMetode non-parametrik adalah pendekatan analisis statistik yang tidak bergantung pada asumsi bentuk distribusi tertentu dan tidak secara langsung menggunakan parameter populasi seperti mean atau varians dalam perhitungannya. Metode ini sering digunakan ketika data tidak memenuhi asumsi normalitas atau ketika data yang dimiliki berskala ordinal dan nominal, di mana informasi yang tersedia hanya berupa urutan atau kategori. Dalam praktiknya, metode non-parametrik banyak mengandalkan peringkat (ranking) untuk melakukan perbandingan antar kelompok atau mengukur hubungan antar variabel.\nKelebihan metode non-parametrik terletak pada fleksibilitasnya terhadap bentuk data —metode ini tetap dapat digunakan meskipun data terdistribusi miring, memiliki outlier, atau jumlah sampel relatif kecil. Selain itu, metode ini lebih “aman” digunakan jika peneliti tidak yakin bahwa asumsi parametrik terpenuhi. Namun, konsekuensi dari fleksibilitas ini adalah kekuatan statistik yang umumnya lebih rendah dibandingkan metode parametrik ketika asumsi normalitas sebenarnya terpenuhi. Artinya, metode non-parametrik mungkin kurang sensitif dalam mendeteksi perbedaan atau hubungan yang ada, sehingga hasil yang signifikan memerlukan efek yang lebih besar atau jumlah sampel yang lebih banyak.\nRangkuman perbandingan secara umum antara kedua metode analisis (parametrik vs. non-parametrik) dapat dilihat di Tabel 10.1.\n\n\n\nTabel 10.1: Perbandingan metode statistik parametrik dan non-parametrik\n\n\n\n\n\n\n\n\n\n\nAspek\nStatistik Parametrik\nStatistik Non-parametrik\n\n\n\n\nAsumsi utama\nData berasal dari populasi yang berdistribusi normal.\nTidak memerlukan asumsi distribusi normal\n\n\nJenis data yang cocok\nData berskala interval atau rasio\nData berskala ordinal atau nominal, atau data interval/rasio yang tidak normal\n\n\nKelebihan\nMemiliki daya statistik lebih tinggi jika asumsi normalitas terpenuhi\nLebih fleksibel terhadap pelanggaran asumsi dan dapat digunakan pada data yang tidak normal\n\n\nKekurangan\nData harus memenuhi asumsi-asumsi yang ketat\nUmumnya memiliki kekuatan statistik lebih rendah\n\n\nKonsekuensi praktis\nMemberikan hasil yang lebih presisi pada data yang memenuhi asumsi normalitas\nMemberikan hasil yang kurang sensitif dalam mendeteksi perbedaan atau hubungan yang ada\n\n\n\n\n\n\n\n\n\n\nM. A., H. B. O., Notobroto. (2014). Perbandingan tingkat konsistensi normalitas distribusi metode kolmogorov-smirnov, lilliefors, shapiro-wilk, dan skewness-kurtosis. Jurnal Biometrika dan kependudukan, 3, 127–135.\n\n\nRazali, N., & Wah, Y. (2011). Power comparisons of Shapiro-Wilk , Kolmogorov-Smirnov , Lilliefors and Anderson-Darling test. Journal of Statistical Modeling and Analytics, 2, 21–33.\n\n\nYap, B. W., & Sim, C. H. (2011). Comparisons of various types of normality tests. Journal of Statistical Computation and Simulation, 81, 2141–2155. https://doi.org/10.1080/00949655.2010.520163",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Statistik Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "4_2_power.html",
    "href": "4_2_power.html",
    "title": "11  Statistical Power",
    "section": "",
    "text": "Statistical power, atau tingkat sensitivitas, adalah kemampuan suatu pengujian statistik untuk mendeteksi adanya efek suatu variabel terhadap variabel lain atau perbedaan antar kelompok jika efek atau perbedaan tersebut memang benar-benar ada. Studi dengan power yang tinggi memiliki peluang besar untuk menemukan efek, bahkan jika efek tersebut kecil, selama efek itu memang nyata. Sebaliknya, studi dengan power yang rendah cenderung gagal mendeteksi perbedaan atau hubungan yang sebenarnya ada, dan hasil signifikansinya lebih rentan dipengaruhi oleh error, baik yang bersifat sistematik maupun acak.\nKonsep ini sangat penting karena berkaitan langsung dengan risiko melakukan kesalahan dalam pengujian hipotesis, khususnya kesalahan tipe II (β). Dalam statistik, terdapat dua jenis kesalahan:\n\nKesalahan tipe I (α): Menolak hipotesis nol padahal sebenarnya tidak ada perbedaan atau hubungan.\nKesalahan tipe II (β): Gagal menolak hipotesis nol padahal sebenarnya ada perbedaan atau hubungan.\n\nPower penelitian dihitung sebagai 1 – β, sehingga semakin kecil β, semakin besar power. Misalnya, power sebesar 80% berarti penelitian memiliki peluang 80% untuk mendeteksi perbedaan atau hubungan yang sebenarnya ada di populasi.\nMenentukan tingkat power biasanya dilakukan sebelum pengambilan data agar peneliti dapat memperkirakan ukuran sampel yang memadai. Tingkat power yang umum digunakan adalah 80%, 90%, atau 95%. Penentuan ini mempertimbangkan beberapa faktor utama: ukuran sampel, besaran efek (effect size), tingkat signifikansi (α), dan variabilitas data. Dengan perencanaan yang baik, peneliti dapat meminimalkan risiko kesalahan tipe II dan meningkatkan peluang memperoleh hasil yang akurat dan dapat diandalkan.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>*Statistical Power*</span>"
    ]
  },
  {
    "objectID": "4_3_hipotesis.html",
    "href": "4_3_hipotesis.html",
    "title": "12  Pengujian Hipotesis",
    "section": "",
    "text": "Secara etimologi, hipotesis berasal dari dua kata, yaitu hipo yang berarti “di bawah” dan thesa yang berarti “kebenaran”. Secara harfiah, hipotesis dapat diartikan “di bawah kebenaran” atau kebenaran sementara yang masih harus diuji kesahihannya. Dalam penelitian, hipotesis adalah jawaban sementara terhadap pertanyaan penelitian yang disusun berdasarkan teori, temuan penelitian sebelumnya, maupun logika dan akal sehat peneliti.\nHipotesis dibuat untuk dikonfirmasikan kepada data lapangan; jika terkonfirmasi, maka hipotesis diterima sebagai kebenaran berdasarkan data penelitian. Dalam analisis statistik, terdapat dua macam hipotesis yang wajib dipahami:\n\nHipotesis nol (H₀), yaitu hipotesis yang menyatakan ketiadaan perbedaan antara dua keadaan atau ketiadaan hubungan antar variabel yang diamati. Sebagai contoh:\n\nTidak ada perbedaan tingkat konsentrasi belajar antara kelas A yang diberi sarapan dan kelas B yang tidak diberi sarapan.\nTidak ada hubungan antara tingkat pemahaman bahaya merokok dengan kecenderungan merokok di kalangan remaja perokok.\n\nHipotesis alternatif (H₁), yaitu hipotesis yang menyatakan adanya perbedaan atau hubungan antar variabel yang diamati. Contohnya:\n\nTerdapat perbedaan gaya parenting berdasarkan tingkat pendidikan orang tua.\nTerdapat hubungan antara tingkat keyakinan pada akhirat dengan ketaatan menjalankan sholat lima waktu.\n\n\nHipotesis juga dapat diklasifikasikan berdasarkan tujuan dan teknik analisis data yang dibutuhkan:\n\nHipotesis deskriptif: digunakan pada penelitian yang hanya melibatkan satu variabel. Misalnya: “Terdapat kesadaran yang tinggi pada remaja usia belasan terhadap merek sabun ‘X’”. Analisisnya meliputi statistik deskriptif, tendensi sentral, dispersi, dan uji normalitas.\nHipotesis komparatif: digunakan untuk membandingkan dua atau lebih keadaan. Misalnya: “Terdapat perbedaan konsentrasi belajar antara kelas A yang diberi sarapan dan kelas B yang tidak”. Analisisnya dapat menggunakan uji-t atau ANOVA untuk data parametrik, dan uji Wilcoxon atau Kruskal-Wallis untuk data non-parametrik.\nHipotesis asosiatif: digunakan untuk menilai keterhubungan antara dua peristiwa atau variabel. Misalnya: “Terdapat hubungan antara tingkat ekspose isu di media sosial dengan literasi masyarakat terhadap isu tersebut”. Analisisnya dapat menggunakan korelasi Pearson untuk data parametrik, dan korelasi Spearman untuk data non-parametrik.\n\nDalam pengujian hipotesis, arah pengujian menentukan di sisi mana peneliti mencari bukti untuk menolak hipotesis nol. Uji satu arah (one-tailed test) digunakan jika hipotesis alternatif memprediksi arah perbedaan atau hubungan yang diharapkan, misalnya rata-rata nilai kelas A lebih tinggi daripada kelas B. Seluruh tingkat signifikansi ditempatkan pada satu sisi distribusi sehingga lebih sensitif untuk mendeteksi perbedaan ke arah tersebut, namun tidak dapat menangkap perbedaan ke arah sebaliknya.\nSebaliknya, uji dua arah (two-tailed test) digunakan jika hipotesis alternatif tidak menentukan arah perbedaan, misalnya hanya ingin mengetahui apakah dua rata-rata berbeda tanpa memprediksi lebih tinggi atau lebih rendah. Dalam uji ini, tingkat signifikansi dibagi pada kedua sisi distribusi sehingga dapat mendeteksi perbedaan di kedua arah. Pemilihan jenis uji sebaiknya ditentukan sejak awal penelitian untuk menjaga validitas hasil.\nProses pengujian hipotesis dilakukan secara sistematis. Langkah pertama adalah merumuskan H₀ dan H₁, kemudian menetapkan tingkat signifikansi (α), umumnya 0,05, untuk membatasi risiko kesalahan tipe I. Selanjutnya, peneliti memilih uji statistik yang sesuai dengan jenis data dan desain penelitian, lalu mengumpulkan dan menganalisis data untuk mendapatkan nilai statistik uji. Nilai ini dibandingkan dengan nilai kritis atau diinterpretasikan menggunakan p-value. Jika p-value ≤ α, maka H₀ ditolak; jika p-value &gt; α, maka H₀ tidak dapat ditolak. Penjelasan lebih lanjut mengenai signifikansi dan p-value akan diuraikan pada Bab 13.\nPenting dipahami bahwa menolak H₀ tidak berarti H₀ salah secara mutlak, melainkan data memberikan bukti cukup untuk mendukung H₁ dalam batas risiko yang ditetapkan. Sebaliknya, gagal menolak H₀ tidak berarti H₀ benar, tetapi menunjukkan bukti yang ada belum cukup untuk mendukung H₁. Dengan pemahaman ini, pengujian hipotesis menjadi alat penting untuk menarik kesimpulan ilmiah yang terukur, transparan, dan dapat dipertanggungjawabkan.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Pengujian Hipotesis</span>"
    ]
  },
  {
    "objectID": "4_4_signifikansi.html",
    "href": "4_4_signifikansi.html",
    "title": "13  Signifikansi Statistik & p-value",
    "section": "",
    "text": "13.1 Signifikansi\nSignifikansi statistik dan p-value merupakan dua konsep yang saling terkait dan sangat penting dalam pengujian hipotesis. Keduanya membantu peneliti menentukan apakah hasil penelitian cukup kuat untuk menolak hipotesis nol atau tidak. Pemahaman yang tepat mengenai kedua konsep ini tidak hanya mencegah kesalahan interpretasi, melainkan juga memastikan bahwa keputusan yang diambil mempertimbangkan konteks penelitian, ukuran efek, dan statistical power, sehingga hasil yang diperoleh lebih akurat dan bermakna secara praktis.\nDalam statistik, signifikansi merujuk pada tingkat keyakinan bahwa suatu hasil penelitian bukan semata-mata disebabkan oleh kebetulan. Tingkat signifikansi biasanya dinyatakan dengan simbol α (alpha), yang mewakili probabilitas melakukan kesalahan tipe I — yaitu menolak hipotesis nol (H₀) padahal H₀ benar. Nilai α yang umum digunakan adalah 0,05 (5%) atau 0,01 (1%). Pemilihan nilai ini merupakan batas yang ditetapkan peneliti sebelum analisis, untuk mengontrol risiko salah menolak H₀.\nTingkat signifikansi berfungsi sebagai ambang batas untuk memutuskan apakah bukti yang diperoleh dari data cukup kuat untuk menolak H₀. Semakin kecil nilai α, semakin ketat kriteria yang digunakan, sehingga peluang membuat kesalahan tipe I menjadi lebih kecil, tetapi sekaligus meningkatkan risiko kesalahan tipe II (gagal menolak H₀ padahal H₀ salah). Oleh karena itu, penentuan nilai α harus mempertimbangkan keseimbangan antara ketelitian statistik dan kebutuhan praktis penelitian, termasuk konteks bidang ilmu, risiko kesalahan yang dapat ditoleransi, dan implikasi keputusan yang akan diambil berdasarkan hasil analisis (Moore dkk., 2018) .\nIlmu sosial umumnya menggunakan tingkat signifikansi 0,05 karena fenomena yang diteliti sering kali melibatkan variabilitas tinggi dan faktor-faktor yang sulit dikendalikan sepenuhnya, seperti perilaku, persepsi, atau interaksi sosial (Gravetter & Wallnau, 2017). Variabilitas ini membuat data cenderung mengandung banyak noise, sehingga menetapkan ambang yang terlalu ketat (misalnya 0,01) dapat meningkatkan risiko kesalahan tipe II — gagal mendeteksi efek yang sebenarnya ada. Dengan α = 0,05, peneliti di ilmu sosial masih memiliki keseimbangan yang cukup baik antara menghindari kesalahan tipe I dan tetap sensitif terhadap efek yang relevan.\nSebaliknya, di ilmu eksak seperti fisika, kimia, atau teknik, eksperimen biasanya dilakukan dalam kondisi yang lebih terkontrol, dengan variabel-variabel yang dapat diukur secara presisi dan replikasi yang konsisten. Karena kontrol yang ketat ini, tingkat kesalahan acak (random) lebih rendah, sehingga dimungkinkan untuk menetapkan α lebih kecil (misalnya 0,01 atau 0,001) tanpa mengorbankan terlalu banyak sensitivitas. Di bidang ini, kesalahan tipe I sering kali memiliki konsekuensi besar — misalnya, klaim penemuan efektivitas obat baru — sehingga diperlukan standar bukti yang lebih kuat sebelum menolak H₀.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Signifikansi Statistik & *p-value*</span>"
    ]
  },
  {
    "objectID": "4_4_signifikansi.html#p-value",
    "href": "4_4_signifikansi.html#p-value",
    "title": "13  Signifikansi Statistik & p-value",
    "section": "13.2 p-value",
    "text": "13.2 p-value\np-value atau probability value adalah probabilitas mendapatkan hasil pengamatan, atau hasil yang lebih ekstrem, jika H₀ benar. Nilai ini digunakan untuk menilai apakah hasil yang diperoleh cukup kuat untuk menolak H₀ berdasarkan tingkat signifikansi yang ditetapkan.\nAturan pengambilan keputusan:\n\np-value ≤ α → Hasil signifikan secara statistik, H₀ ditolak, artinya data memberikan bukti yang cukup untuk mendukung H₁.\np-value &gt; α → Hasil tidak signifikan secara statistik, H₀ tidak ditolak, artinya data tidak memberikan bukti yang cukup untuk menolak H₀.\n\nMari kita gunakan ilustrasi sederhana untuk dapat lebih memahami mengenai konsep p-value ini. Bayangkan Anda sedang bermain permainan melempar koin yang menurut klaim teman Anda adalah koin normal (punya peluang 50% muncul gambar dan 50% muncul angka). Jika diterjemahkan ke dalam istilah hipotesis, maka:\n\nHipotesis nol (H₀): Koin itu seimbang (tidak curang)\nHipotesis alternatif (H₁): Koin itu tidak seimbang (curang)\n\nLalu Anda melempar koin 10 kali dan hasilnya 9 kali gambar, 1 kali angka. Sekarang Anda bertanya: “Kalau koin ini benar-benar seimbang (H₀ benar), seberapa besar kemungkinan saya mendapatkan hasil yang ekstrem seperti ini atau lebih ekstrem?”\nDi sinilah p-value berperan, yaitu menghitung peluang mendapatkan hasil se-ekstrem ini jika H₀ benar:\n\nJika peluangnya sangat kecil (misalnya &lt; 5%), maka hasil yang Anda dapatkan tidak cocok dengan asumsi bahwa koin seimbang, sehingga Anda punya alasan kuat untuk menolak H₀ dan curiga koinnya curang.\nJika peluangnya masih cukup besar (misalnya 30%), maka hasil yang Anda dapatkan masih wajar untuk koin seimbang, sehingga Anda tidak punya cukup alasan untuk menolak H₀.\n\nJadi, p-value bukanlah peluang koin curang atau tidak curang, melainkan peluang mendapatkan data yang Anda lihat jika koin benar-benar seimbang.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Signifikansi Statistik & *p-value*</span>"
    ]
  },
  {
    "objectID": "4_4_signifikansi.html#interpretasi-signifikansi-p-value",
    "href": "4_4_signifikansi.html#interpretasi-signifikansi-p-value",
    "title": "13  Signifikansi Statistik & p-value",
    "section": "13.3 Interpretasi Signifikansi & p-value",
    "text": "13.3 Interpretasi Signifikansi & p-value\nTerdapat dua hal penting yang perlu diingat diingat dalam menginterpretasi signifikansi statistik dan p-value. Pertama, signifikan secara statistik tidak selalu berarti signifikan secara praktis; ukuran efek (effect size) perlu dipertimbangkan (lihat Bab 15). Misalnya, ditemukan perbedaan skor ujian antara kelas yang menggunakan metode pembelajaran daring (Mean = 78,2) dan metode pembelajaran hibrid (Mean = 79,2). Meskipun secara statistik perbedaan kedua skor tersebut ditemukan signifikan (kemungkinan karena jumlah sampel yang besar), belum tentu memiliki nilai praktis yang bermakna. Dalam hal ini, perbedaan nilai 1 poin nampaknya terlalu “mahal” untuk dibayar dengan kerumitan dalam pelaksanaan dan pengelolaan metode belajar hibrid.\nKedua, p-value tidak menunjukkan peluang hipotesis benar atau salah, dan tidak membuktikan H₀ atau H₁ secara mutlak. p-value kecil menunjukkan bahwa jika H₀ benar, peluang memperoleh data seperti yang diamati sangat kecil; p-value besar menunjukkan data konsisten dengan H₀, tetapi bukan bukti bahwa H₀ benar.\nDengan memahami hubungan antara signifikansi dan p-value, peneliti dapat membuat keputusan yang lebih tepat dalam pengujian hipotesis, sekaligus menghindari kesalahan interpretasi yang umum terjadi.\n\n\n\n\nMoore, D. S., Notz, W., & Flinger, A. (2018). The basic practice of statistics (7th ed.). W.H. Freeman.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Signifikansi Statistik & *p-value*</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html",
    "href": "4_5_confidence.html",
    "title": "14  Confidence Interval",
    "section": "",
    "text": "14.1 Prinsip Dasar Confidence Interval\nSebelum memahami konsep Confidence Interval (CI), kita perlu mengingat kembali prinsip dasar statistik, yaitu bahwa statistik adalah estimasi parameter-parameter populasi (misalnya, nilai rata-rata, standar deviasi) berdasarkan data yang diambil dari sampel. Dengan kata lain, nilai yang kita peroleh dalam statistik kemungkinan besar (atau bahkan hampir pasti) tidak sama dengan nilai yang sesungguhnya pada populasi. Akan selalu ada selisih (eror) antara nilai pada sampel dan pada populasi.\nConfidence interval adalah rentang nilai yang digunakan untuk memperkirakan posisi parameter populasi berdasarkan data sampel. Interval ini dibentuk dari estimasi titik, seperti mean atau proporsi, kemudian ditambahkan batas bawah dan batas atas yang dihitung dari data.\nPrinsip dasarnya adalah memberikan gambaran bahwa parameter populasi tidak dinyatakan sebagai satu angka pasti, tetapi berada dalam suatu rentang yang masuk akal menurut data yang dikumpulkan. Dengan menggunakan CI, peneliti dapat menyampaikan hasil estimasi secara lebih informatif dan transparan, karena selain nilai estimasi, juga disertakan rentang ketidakpastian yang menyertainya.\nTingkat kesahihan dan keterpercayaan sebuah hasil riset bergantung pada seberapa representatif data yang diperoleh dari sampel dan seberapa yakin bahwa hasil analisis data yang dilakukan menggambarkan kondisi populasi yang sebenarnya. Oleh karena itu, pembahasan mengenai CI tidak dapat dilepaskan dari dua konsep yang terkait, yaitu Margin of Error (MoE) dan derajat keyakinan (Level of Confidence).",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>*Confidence Interval*</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html#margin-of-error",
    "href": "4_5_confidence.html#margin-of-error",
    "title": "14  Confidence Interval",
    "section": "14.2 Margin of Error",
    "text": "14.2 Margin of Error\nMargin of error adalah batas toleransi kesalahan yang menunjukkan seberapa jauh nilai estimasi sampel dapat berbeda dari nilai sebenarnya di populasi. Dalam konteks CI, MoE menentukan jarak antara estimasi titik (misalnya mean sampel) dan batas atas atau batas bawah interval kepercayaan. Semakin kecil MoE, semakin sempit intervalnya, yang berarti estimasi lebih presisi.\nBesarnya MoE dipengaruhi oleh level of confidence (LoC) yang dipilih (misalnya 95%), ukuran sampel, dan variasi data. Pada LoC yang sama, ukuran sampel yang lebih besar atau variasi data yang lebih kecil akan menghasilkan MoE yang lebih kecil, sehingga interval kepercayaan menjadi lebih akurat.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>*Confidence Interval*</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html#level-of-confidence",
    "href": "4_5_confidence.html#level-of-confidence",
    "title": "14  Confidence Interval",
    "section": "14.3 Level of Confidence",
    "text": "14.3 Level of Confidence\nLoC adalah tingkat keyakinan yang digunakan untuk menyatakan seberapa besar kemungkinan CI mencakup nilai parameter sebenarnya di populasi. Misalnya, LoC 95% berarti jika penelitian yang sama diulang berkali-kali dengan metode yang sama, sekitar 95% dari CI yang dihasilkan akan mengandung nilai parameter populasi. Semakin tinggi LoC, semakin besar jaminan bahwa interval mencakup parameter yang benar, namun konsekuensinya interval akan menjadi lebih lebar. Sebaliknya, level yang lebih rendah menghasilkan interval yang lebih sempit tetapi meningkatkan risiko parameter sebenarnya berada di luar interval tersebut.\nMari kita gunakan analogi untuk dapat lebih mudah memahaminya. Misalnya, Anda diminta untuk mengestimasi jarak antara Jakarta (dihitung dari lokasi Monumen Nasional) dan Yogyakarta (dihitung dari lokasi Monumen Yogya Kembali). Jika Anda bukan orang yang terbiasa bepergian Jakarta-Yogyakarta, Anda bisa menjawab bahwa jarak keduanya antara 550-600 KM (rentang sempit) dengan derajat keyakinan 45% (level rendah) karena Anda tidak terlalu yakin bahwa jarak sebenarnya ada di antara rentang tersebut.\nAtau, Anda bisa menjawab dengan tingkat keyakinan yang jauh lebih tinggi (misalnya 99%) bahwa jaraknya antara 100-800KM (rentang sangat lebar). Memang, hampir pasti jawabannya ada di dalam rentang tersebut, tetapi kemampuan estimasi Anda menjadi sangat diragukan karena rentangnya sangat lebar (700 KM), sehingga sulit untuk memperkirakan berapa jarak sebenarnya (menurut perhitungan Google Maps dengan mode kendaraan roda 4, jaraknya adalah 578 KM).",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>*Confidence Interval*</span>"
    ]
  },
  {
    "objectID": "4_5_confidence.html#menginterpretasi-ci-moe-loc",
    "href": "4_5_confidence.html#menginterpretasi-ci-moe-loc",
    "title": "14  Confidence Interval",
    "section": "14.4 Menginterpretasi CI, MoE, & LoC",
    "text": "14.4 Menginterpretasi CI, MoE, & LoC\nRentang keyakinan atau CI diperoleh dengan cara sebagai berikut:\n\\[\\text{CI} = \\bar{x} \\;\\pm\\; \\text{MoE}\n\\]\n\\[\n\\text{di mana MoE} = z \\times \\frac{s}{\\sqrt{n}}\n\\]\nKet.: \\(\\bar{x}\\) = rata-rata (mean) sampel; \\(z\\) = nilai z-score yang sesuai dengan tingkat kepercayaan yang dipilih (misalnya, 1,96 untuk LoC 95% dan 2,58 untuk LoC 99%); \\(s\\) = standar deviasi sampel; \\(n\\) = ukuran sampel\nJika mean dari data adalah 25 dan MoE (LoC 95%) = 4, maka CI = 25 ± 4 = 21–29, yang artinya bahwa nilai populasi diestimasi berada pada kisaran 21 hingga 29. Dengan menggunakan LoC yang lebih tinggi (99%), maka MoE = 5,25, sehingga CI = 25 ± 5,25 = 19,75–30,25. Dengan kata lain, dengan tingkat keyakinan 99%, nilai mean populasi berada di antara 19,75 hingga 30,25. Kita dapat melihat bahwa semakin tinggi LoC maka semakin lebar rentang keyakinannya, begitu pula sebaliknya.\nPemahaman mengenai CI dan MoE ini sangat penting bagi peneliti untuk mengambil kesimpulan dan keputusan dari data yang telah dianalisis. Kesalahan atau kurangnya pemahaman dapat membawa peneliti pada penyimpulan yang keliru. Sebagai ilustrasi, di masa Pemilu sebuah lembaga survei politik melakukan riset tingkat keterpilihan (elektabilitas) para pasangan kandidat presiden dan wakil presiden. Dari dua pasang kandidat, berdasarkan risetnya lembaga survei tersebut menemukan bahwa elektabilitas pasangan A mencapai 48% dan pasangan B 52% dengan MoE 3% pada LoC 95%.\nJika tidak memahami bagaimana hasil ini seharusnya diinterpretasikan, maka mereka dapat berkesimpulan bahwa pasangan B unggul dan akan memenangi persaingan dengan pasangan A. Padahal, jika memperhitungkan MoE dalam memahami hasil tersebut, kita akan menemukan bahwa pada kondisi aktualnya, elektabilitas A berada di antara 45–51%, sedangkan B 49–55%. Artinya, masih ada kemungkinan bahwa pasangan A meraih skor lebih tinggi (misalnya 51%) dibandingkan B (misalnya 49%). Oleh karena itu, kemenangan di antara kedua pasangan tersebut masih belum dapat diestimasi secara meyakinkan karena ada area skor elektabilitas yang beririsan. Terlebih lagi jika penghitungannya menggunakan LoC 99%, maka irisan skornya akan makin besar, sehingga makin sulit menentukan siapa di antara mereka yang secara aktual lebih unggul.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>*Confidence Interval*</span>"
    ]
  },
  {
    "objectID": "4_6_effect_size.html",
    "href": "4_6_effect_size.html",
    "title": "15  Effect Size",
    "section": "",
    "text": "15.1 Prinsip Dasar\nEffect size adalah ukuran yang menunjukkan seberapa besar perbedaan atau hubungan yang benar-benar berarti dalam penelitian, melampaui sekadar signifikansi statistik. Jika nilai p hanya memberi tahu apakah suatu efek ada, maka effect size menjelaskan seberapa kuat atau penting efek tersebut secara praktis. Dengan demikian, memahami effect size menjadi penting agar peneliti tidak hanya tahu “ada atau tidaknya perbedaan”, tetapi juga “seberapa besar perbedaan itu” dalam konteks nyata. Dari titik inilah pembahasan dapat diarahkan pada prinsip dasar effect size yang menjelaskan konsep, jenis, hingga cara menghitungnya.\nEffect size berangkat dari gagasan bahwa signifikansi statistik saja tidak cukup untuk menjawab apakah suatu temuan penelitian benar-benar penting secara praktis. Sebuah hasil bisa saja signifikan karena ukuran sampelnya besar, padahal perbedaan yang ditemukan sebenarnya sangat kecil dan tidak relevan dalam praktik. Di sinilah effect size berperan, karena ia memberi informasi mengenai kekuatan hubungan antar variabel atau besarnya perbedaan antar kelompok dengan satuan yang lebih mudah dipahami secara kuantitatif.\nSecara prinsip, effect size mengukur seberapa besar “efek nyata” yang terjadi dalam sebuah studi. Efek ini bisa berupa perbedaan rata-rata antar kelompok, kekuatan korelasi antara dua variabel, atau besarnya varians yang dapat dijelaskan oleh suatu model. Dengan demikian, effect size menjadi jembatan penting yang menghubungkan antara hasil analisis statistik dan implikasi praktis dari penelitian. Ia membantu peneliti untuk tidak hanya menjawab “apakah ada efek?” tetapi juga “seberapa besar efek itu?”.\nPelaporan effect size penting karena melengkapi informasi yang tidak diberikan oleh p-value. Nilai signifikansi hanya menunjukkan apakah hasil mungkin terjadi karena kebetulan atau tidak, tetapi tidak menjelaskan seberapa besar pengaruh yang sebenarnya. Dengan menyertakan effect size, peneliti dapat menilai apakah temuan yang signifikan juga memiliki arti praktis, serta memungkinkan perbandingan lintas penelitian secara lebih adil, misalnya dalam meta-analisis. Hal ini mencegah kesalahpahaman bahwa hasil signifikan selalu berarti penting, padahal efeknya bisa saja sangat kecil dan kurang relevan secara praktis.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Effect Size*</span>"
    ]
  },
  {
    "objectID": "4_6_effect_size.html#klasifikasi-effect-size",
    "href": "4_6_effect_size.html#klasifikasi-effect-size",
    "title": "15  Effect Size",
    "section": "15.2 Klasifikasi Effect Size",
    "text": "15.2 Klasifikasi Effect Size\nEffect size dapat dinyatakan dalam beberapa bentuk tergantung pada teknik analisis statistik yang digunakan. Secara umum, ada dua kategori utama:\n\nPerbedaan mean yang distandarisasi\nUkuran ini digunakan untuk membandingkan rata-rata dua kelompok atau lebih. Rumus yang paling populer adalah Cohen’s d:\n\\[\nd = \\frac{M_{1} - M_{2}}{SD_{\\text{pooled}}}\n\\]\ndengan\n\\[\nSD_{\\text{pooled}} =\n\\sqrt{ \\frac{(n_{1}-1)SD_{1}^{2} + (n_{2}-1)SD_{2}^{2}}{\\,n_{1} + n_{2} - 2} }\n\\]\n\nProporsi varians yang dapat dijelaskan\nUkuran ini menjawab pertanyaan: seberapa besar varians pada suatu variabel dapat dijelaskan oleh varians variabel lain. Bentuk yang sering digunakan antara lain:\n\nr² untuk uji beda mean\nDari uji t, effect size dapat dihitung dengan:\n\n\\[\nr^{2} = \\frac{t^{2}}{t^{2} + \\text{df}}\n\\]\n\nr² untuk korelasi\nJika analisis berupa korelasi, effect size dihitung dengan menguadratkan koefisien korelasi:\n\n\\[\nr^{2} = \\left(r_{xy}\\right)^{2}\n\\]\nSemakin besar nilai r², semakin banyak varians satu variabel yang dapat dijelaskan oleh variabel lain.\n\nR² dalam regresi\nDalam analisis regresi, effect size dinyatakan dengan proporsi varians total yang dijelaskan oleh model:\n\\[\nR^{2} = \\frac{JK_{\\text{reg}}}{JK_{\\text{tot}}}\n\\]Nilai R² berkisar antara 0–1, dengan interpretasi bahwa semakin tinggi R², semakin baik model regresi menjelaskan varians variabel dependen.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Effect Size*</span>"
    ]
  },
  {
    "objectID": "4_6_effect_size.html#ukuran-effect-size-lainnya",
    "href": "4_6_effect_size.html#ukuran-effect-size-lainnya",
    "title": "15  Effect Size",
    "section": "15.3 Ukuran Effect Size Lainnya",
    "text": "15.3 Ukuran Effect Size Lainnya\nSelain Cohen’s d dan korelasi (r), terdapat ukuran effect size lain yang digunakan sesuai jenis analisis. Setiap ukuran ini membantu peneliti membaca makna praktis hasil penelitian dalam konteks yang lebih spesifik (lihat ?tbl-effect).\n\nCramer’s V/Phi coefficient\nDigunakan pada uji chi-square atau tabel kontingensi untuk melihat kekuatan hubungan antar variabel kategorikal. Nilainya mirip dengan korelasi, semakin mendekati 1 berarti hubungan semakin kuat.\nEta squared (η²)/Partial eta squared (ηp²)\nSering digunakan pada ANOVA. Menunjukkan proporsi varians yang dijelaskan oleh faktor independen. Partial eta squared lebih umum dipakai dalam penelitian psikologi karena memperhitungkan pengaruh faktor lain.\nOdds ratio\nDigunakan dalam penelitian dengan data kategorikal (terutama di ilmu kesehatan). Menggambarkan seberapa besar peluang suatu kejadian terjadi pada satu kelompok dibandingkan kelompok lain.\n\n\n\nTabel interpretasi effect size (Cumming, 2011)\n\n\n\n\n\n\n\n\nUkuran\nKecil\nSedang\nBesar\n\n\n\n\nCohen’s d\n0.2\n0.5\n0.8\n\n\nr/r²\nr = 0.1 (r² ≈ 0.01)\nr = 0.3 (r² ≈ 0.09)\nr = 0.5 (r² ≈ 0.25)\n\n\nCramer’s V/Phi\n0.1\n0.3\n0.5\n\n\nEta squared (η²)\n0.01\n0.06\n0.14\n\n\nPartial eta squared (ηp²)\n0.01\n0.06\n0.14\n\n\nOdds ratio (OR)\n~1.2\n~1.5\n≥2.0\n\n\n\n\n\n\n\n\nCumming, G. (2011). Understanding the New Statistics: Effect Sizes, Confidence Intervals, and Meta-Analysis. Routledge.",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>*Effect Size*</span>"
    ]
  },
  {
    "objectID": "4_latihan.html",
    "href": "4_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bagian 4 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "STATISTIK INFERENSIAL",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "5_t-test.html",
    "href": "5_t-test.html",
    "title": "PERBEDAAN RATA-RATA DUA KELOMPOK",
    "section": "",
    "text": "Pada bagian ini akan dibahas mengenai perbedaan mean variabel yang sama antara dua kelompok berbeda. Pemahaman mengenai hal ini diperlukan untuk membandingkan antara dua karakteristik atau kondisi yang berbeda, misalnya perbedaan antara kelompok eksperimen/treatment group (KE) dan kelompok kontrol/control group (KK), atau perbedaan antara kelompok pertama dan kelompok kedua, atau perbedaan antara sebelum dan sesudah mendapatkan treatment.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 16. Memahami Perbedaan Rata-rata Antar Kelompok:\n\nMemahami perbedaan antara kelompok eksperimen dan kelompok kontrol.\n\nBab 17. Analisis Perbedaan Rata-rata Antar Kelompok vs. Dalam Kelompok:\n\nMengidentifikasi perbedaan penggunaan uji beda antar kelompok dan dalam kelompok.\nMemahami makna perbedaan rata-rata dalam konteks analisa statistik.\n\nBab 18. Asumsi, Interpretasi, dan Pelaporan Analisis Independent Samples t-test: Parametrik dan Non-Parametrik:\n\nMenjelaskan asumsi yang perlu dipenuhi dalam uji independent samples t-test (parametrik dan non-parametrik), interpretasi dan cara penulisannya dalam laporan.\n\nBab 19. Asumsi, Interpretasi, dan Pelaporan Analisis Paired Samples t-test: Parmetrik dan Non-Parametrik:\n\nMenjelaskan asumsi yang perlu dipenuhi dalam uji paired samples t-test test (parametrik dan non-parametrik), interpretasi dan cara penulisannya dalam laporan.",
    "crumbs": [
      "PERBEDAAN RATA-RATA DUA KELOMPOK"
    ]
  },
  {
    "objectID": "5_1_perbedaan.html",
    "href": "5_1_perbedaan.html",
    "title": "16  Memahami Perbedaan Rata-rata Antar Kelompok",
    "section": "",
    "text": "Meneliti dan memahami bagaimana suatu kelompok dapat berbeda jika dibandingkan dengan kelompok lainnya, merupakan salah satu hal penting dan sering menjadi tujuan penelitian pada ranah ilmu sosial, termasuk psikologi. Pemahaman ini sangat diperlukan ketika peneliti ingin mengetahui efektivitas dari intervensi atau manipulasi yang dilakukan. Misalnya, seorang dosen ingin mengetahui apakah penjelasan materi dengan pemberian video pembelajaran dapat meningkatkan pemahaman mahasiswa pada mata kuliah statistik. Untuk mengujinya, dosen tersebut melakukan penelitian eksperimental di mana satu kelompok/kelas mahasiswa mendapatkan video pembelajaran, sedangkan kelompok/kelas lainnya tidak.\nKelompok yang mendapatkan video pembelajaran disebut dengan kelompok eksperimen/treatment group (KE). KE adalah sekelompok partisipan penelitian yang mendapatkan perlakuan atau intervensi tertentu yang diharapkan dapat menyebabkan terjadinya perbedaan hasil (misalnya, penurunan atau peningkatan skor). Pada contoh sebelumnya, video pembelajaran adalah intervensi yang diberikan untuk meningkatkan skor pemahaman mahasiswa. Sementara itu, kelompok yang tidak mendapatkan perlakuan atau intervensi, disebut dengan kelompok kontrol/control group (KK).\nDesain penelitian yang melibatkan KE dan KK ini umumnya ditemui pada setting eksperimental, di mana peneliti dengan sengaja membagi kelompok dan memberikan perlakuan yang berbeda, seperti pada uji coba klinis. Akan tetapi, dalam konteks ilmu sosial, sangat memungkinkan kelompok tertentu mendapatkan perlakukan atau mengalami hal yang berbeda, dan seolah menjadi “treatment” yang terjadi secara alami/natural. Misalnya, adanya pembentukan kelompok karena perbedaan kelas di sekolah, kelompok pekerja, perbedaan generasi, dan sebagainya.\nAdanya perbedaan kelompok tersebut sangat memungkinkan untuk menimbulkan perbedaan karakteristik, perilaku atau performa antar kelompok. Contohnya, variabel “risk-taking behavior” pada karyawan. Apakah perilaku tersebut akan sama antara karyawan yang baru masuk perusahaan (awal karier) dengan mereka yang sudah mendekati masa pensiun (akhir karier)? Kedua kelompok tersebut akan memiliki perbedaan pemikiran, keterikatan terhadap organisasi dan perilaku kerja. Jika tidak ada perbedaan perlakuan yang dengan sengaja diciptakan atau dimanipulasi oleh peneliti, peneliti umumnya membedakan kedua kelompok dengan menyebutkan Kelompok 1 vs Kelompok 2 atau secara spesifik menyebutkan hal yang membedakan kedua kelompok (misal: kelompok awal karier vs kelompok akhir karier).",
    "crumbs": [
      "PERBEDAAN RATA-RATA DUA KELOMPOK",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Memahami Perbedaan Rata-rata Antar Kelompok</span>"
    ]
  },
  {
    "objectID": "5_2_between_within.html",
    "href": "5_2_between_within.html",
    "title": "17  Analisis Perbedaan Rata-rata Antar Kelompok vs. Dalam Kelompok",
    "section": "",
    "text": "Secara statistik, uji beda dilakukan untuk mengetahui apakah terdapat perbedaan antar kelompok (between groups) atau perbedaan dalam kelompok (within groups). Perbedaan antar kelompok dilakukan untuk mengetahui apakah dua kelompok independent (kelompok yang tidak sama) memiliki perbedaan satu sama lain dalam hal yang sedang diteliti (dependent variable).\nUji beda ini umum digunakan untuk mengukur seberapa efektif sebuah treatment atau intervensi yang diberikan. Misalnya, peneliti ingin mengetahui apakah intervensi yang dirancang efektif dalam menurunkan tingkat kecemasan mahasiswa terhadap pelajaran statistik. Satu kelompok akan mendapatkan treatment penurunan kecemasan (KE), sementara kelompok lain sebagai kelompok pembanding, yaitu mereka yang tidak mendapatkan treatment (KK). Kedua kelompok kemudian diukur tingkat kecemasannya setelah mendapatkan treatment (sebagai outcome), untuk selanjutnya dibandingkan apakah ada perbedaan tingkat kecemasan antara kedua kelompok.\nPerbedaan dalam kelompok dapat digunakan untuk mengetahui efektivitas dari sebuah program intervensi, hanya saja tidak membandingkan dua kelompok yang berbeda. Melainkan, perbedaan dilihat pada kelompok yang sama namun dalam dua kondisi atau waktu yang berbeda. Misalnya, peneliti ingin mengetahui apakah program olah raga yang dirancang efektif dalam menurunkan berat badan dengan membandingkan BMI partisipan antara sebelum (waktu 1) dengan sesudah (waktu 2) mengikuti program olah raga.\nPada kedua jenis uji beda yang telah dibahas, hal yang dibandingkan adalah perbedaan rata-rata (mean differences) variabel yang diteliti. Pada uji beda antar kelompok, hal yang dilihat adalah perbedaan rata-rata antara KE dan KK (perbedaan rata-rata skor kecemasan antara kelompok yang mendapatkan dan tidak mendapatkan intervensi kecemasan). Sementara itu, ketika melakukan uji beda dalam kelompok, hal yang dibandingkan adalah perbedaan rata-rata pada dua waktu pengukuran yang berbeda (perbedaan rata-rata BMI antara sebelum dan sesudah mengikuti program).\nSelain perbedaan rata-rata, hal yang juga perlu diperhatikan adalah simpangan baku dari rata-rata yang dibandingkan (standar deviasi/SD) dan jumlah partisipan pada kedua kelompok. Jika ketiga hal tersebut diketahui, maka uji beda antar dan dalam kelompok dapat dilakukan dengan penghitungan t-test, untuk mengetahui apakah perbedaan rata-rata tersebut signifikan secara statistik. Terdapat dua jenis uji t-test yang akan dibahas lebih lanjut, yaitu independent sample t-test (uji beda antar kelompok berbeda) dan paired sample t-test (uji beda dalam kelompok).",
    "crumbs": [
      "PERBEDAAN RATA-RATA DUA KELOMPOK",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Analisis Perbedaan Rata-rata Antar Kelompok vs. Dalam Kelompok</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Daftar Pustaka",
    "section": "",
    "text": "Buuren, S. van. (2018). Flexible imputation of missing data.\nCRC Press.\n\n\nCoolican, H. (2014). Research methods and statistics in\npsychology (p. 773). Psychology Press, Taylor & Francis Group.\n\n\nCowles, M. (2000). Statistics in psychology: An historical\nperspective. Psychology Press.\n\n\nCumming, G. (2011). Understanding the new statistics: Effect sizes,\nconfidence intervals, and meta-analysis. Routledge.\n\n\nDancey, C. P., & Reidy, J. (2017). Statistics without maths for\npsychology (7th ed.). Pearson Education Limited.\n\n\nGelfond, J. A. L., Klugman, C. M., Welty, L. J., Heitman, E., Louden,\nC., & Pollock, B. H. (2014). How to tell the\ntruth with statistics: The case for accountable data analyses in\nteam-based science. Journal of Translational Medicine &\nEpidemiology, 2.\n\n\nGravetter, F. J., & Wallnau, L. B. (2017). Statistics for the\nbehavioral sciences. Cengage Learning.\n\n\nMoore, D. S., Notz, W., & Flinger, A. (2018). The basic practice\nof statistics (7th ed.). W.H. Freeman.\n\n\nOktaviani, M. A., & Notobroto, H. B. (2014). Perbandingan tingkat\nkonsistensi normalitas distribusi metode kolmogorov-smirnov, lilliefors,\nshapiro-wilk, dan skewness-kurtosis. Jurnal Biometrika Dan\nKependudukan, 3, 127–135.\n\n\nRazali, N., & Wah, Y. (2011). Power comparisons of shapiro-wilk ,\nkolmogorov-smirnov , lilliefors and anderson-darling test. Journal\nof Statistical Modeling and Analytics, 2, 21–33.\n\n\nSalsburg, D. (2002). The lady tasting tea: How statistics\nrevolutionized science in the twentieth century. Henry Holt;\nCompany.\n\n\nTabachnick, B. G., & Fidell, L. S. (2014). Using multivariate\nstatistics (6th ed.). Pearson Education Limited.\n\n\nYap, B. W., & Sim, C. H. (2011). Comparisons of various types of\nnormality tests. Journal of Statistical Computation and\nSimulation, 81, 2141–2155. https://doi.org/10.1080/00949655.2010.520163",
    "crumbs": [
      "Daftar Pustaka"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistik untuk Psikologi dan Ilmu Sosial",
    "section": "",
    "text": "Selamat Datang!\nAlhamdulillah, akhirnya buku Statistik untuk Psikologi dan Ilmu Sosial ini bisa sampai ke tangan Anda. Buku ini lahir dari pengalaman sehari-hari di kelas, saat mendampingi mahasiswa yang sering kali merasa “alergi” begitu mendengar kata statistik. Padahal, kalau dipahami dengan cara yang tepat, statistik bukan sesuatu yang menakutkan. Justru ia adalah alat yang sangat membantu kita untuk membaca, memahami, dan menjelaskan fenomena psikologi secara lebih objektif.\nDalam buku ini, kami mencoba menyajikan konsep-konsep statistik dengan bahasa yang sederhana, runtut, dan dekat dengan dunia psikologi. Setiap bab tidak hanya berisi teori, tetapi juga contoh nyata serta latihan soal yang bisa membantu pembaca melatih pemahaman. Harapannya, buku ini bisa menjadi jembatan agar mahasiswa lebih percaya diri ketika berhadapan dengan data penelitian.\nKami menyadari buku ini masih jauh dari sempurna. Kritik dan saran dari para pembaca tentu sangat kami nantikan, agar pada edisi-edisi berikutnya buku ini bisa semakin baik.\nAkhir kata, semoga buku ini tidak hanya menjadi pegangan dalam belajar, tetapi juga menjadi sahabat yang menemani perjalanan Anda meneliti, menulis, dan memahami psikologi dengan lebih ilmiah.\nJakarta, Agustus 2025\n\nTim Penulis",
    "crumbs": [
      "Selamat Datang!"
    ]
  },
  {
    "objectID": "5_4_paired_ttest.html",
    "href": "5_4_paired_ttest.html",
    "title": "19  Asumsi, Interpretasi, dan Pelaporan Analisis Paired Samples t-test: Parametrik dan Non-Parametrik",
    "section": "",
    "text": "Asumsi dasar yang perlu dipenuhi untuk melakukan uji beda menggunakan paired samples t-test adalah:\n\nDependent Variable berupa data kontinum (data interval atau rasio).\nIndependent Variable adalah dua kelompok partisipan yang sama dan memiliki data berpasangan (misalnya: pre-test dan post-test). Dengan kata lain, pengukuran dilakukan pada orang yang sama sebanyak dua kali.\nData harus terdistribusi normal. Gunakan uji beda non parametrik jika data tidak terdistribusi dengan normal.\nTidak ada outliers.\n\nUji paired samples t-test digunakan untuk menganalisis perbedaan dalam satu kelompok yang sama. Responden untuk kedua pengukuran dalam pasangan adalah orang yang sama, sehingga skor pada kedua pengukuran tersebut saling berkaitan. Bentuk yang umum ditemui adalah partisipan yang sama, memiliki dua skor atau hasil pengukuran yang dilakukan pada waktu yang berbeda. Misalnya, skor saat sebelum dan sesudah mendapatkan treatment, pengukuran pada pagi dan malam hari, dan sebagainya.\nInterpretasi dari hasil uji beda menggunakan paired samples t-test juga perlu dilakukan secara bertahap. Misalnya, peneliti ingin mengetahui perbedaan waktu reaksi partisipan ketika melihat tulisan berwarna hitam dan kuning. Tahapan interpretasi hasil paired samples t-test dapat dipahami dengan mempelajari contoh berikut:\n\nUji asumsi\nHal pertama yang perlu dilihat adalah uji asumsi terkait distribusi data; data harus terdistribusi normal. Tabel 19.1 menunjukkan hasil uji normalitas data (Shapiro-Wilk). Diketahui bahwa skor waktu reaksi partisipan terdistribusi normal (p = .34; p &gt; .05). Artinya, sebaran data waktu reaksi pada kedua kondisi (stimulus hitam dan kuning) tidak berbeda secara signifikan dibandingkan sebaran data kurva normal. Dengan demikian, uji beda dapat dilakukan dengan statistik parametrik, paired samples t-test. Jika data tidak memenuhi uji asumsi normalitas data, maka uji parametrik tidak dapat dilanjutkan, perlu dilakukan uji non parametrik (Wilcoxon signed-rank).\n\n\n\nTabel 19.1: Contoh hasil uji normalitas normalitas sampel berpasangan\n\n\n\n\n\n\n\nW\np\n\n\n\n\nHitam\nKuning\n0.974\n0.344\n\n\n\n\n\n\nUji Hipotesis\nSelanjutnya, hal yang perlu dilihat adalah nilai p pada tabel paired samples t-test. Nilai p &lt; .001 (p &lt; .05) menunjukkan terdapat perbedaan signifikan waktu reaksi antara stimulus berwarna hitam dan kuning (lihat Tabel 19.2). Pada tabel output uji paired samples t-test juga dapat dilihat nilai Cohen’s d yang menunjukkan seberapa besar efek dari perbedaan warna stimulus terhadap perbedaan waktu reaksi pada kedua kelompok (effect size). Nilai t, df, p dan Cohen’s d diperlukan dalam penulisan interpretasi hasil uji beda antar kelompok, yang dapat dilihat pada contoh interpretasi hasil uji paired samples t-test.\n\n\n\nTabel 19.2: Contoh hasil analisis paired samples t-test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPengukuran 1\nPengukuran 2\nt\ndf\np\nCohen’s d\nSE Cohen’s d\n\n\n\n\nHitam\nKuning\n5.546\n49\n&lt; .001\n0.784\n0.224\n\n\n\n\n\n\nData deskriptif\nTerakhir, informasi mengenai Mean dan SD diperlukan untuk mengetahui kelompok mana yang menunjukkan rata-rata skor paling tinggi. Contoh Tabel 19.3 menunjukkan stimulus hitam memiliki rata-rata waktu reaksi yang lebih lama dibandingkan stimulus kuning.\n\n\n\nTabel 19.3: Contoh statistik deskriptif paired samples t-test\n\n\n\n\n\n\nN\nMean\nSD\nSE\nCoefficient of Variation\n\n\n\n\nHitam\n50\n67.840\n9.303\n1.316\n0.137\n\n\nKuning\n50\n58.560\n7.680\n1.086\n0.131\n\n\n\n\n\n\n\nPelaporan hasil uji beda paired samples t-test dengan mengikuti format penulisan APA, sama dengan pelaporan uji independent samples t-test. Hasil paired samples t-test menunjukkan terdapat perbedaan waktu reaksi yang signifikan (t (49) = 5.55, p &lt; .001, d = .78) antara stimulus berwarna hitam (M = 67.84, SD = 9.30) dan stimulus kuning (M = 58.56, SD = 7.68). Atau, waktu reaksi partisipan (t (49) = 5.55, p &lt; .001, d = .78) ketika melihat stimulus hitam (M = 67.84, SD = 9.30) lebih lama dibandingkan ketika melihat stimulus kuning (M = 58.56, SD = 7.68).\nPrinsip yang sama juga dapat diterapkan untuk interpretasi dan melaporkan hasil uji beda non parametrik, dengan melihat hasil uji Wilcoxon signed-rank, seperti pada contoh di Tabel 19.4.\nHasil uji Wilcoxon signed-rank menunjukkan bahwa partisipan menunjukkan perbedaan waktu reaksi yang signifikan antara stimulus berwarna hitam dan kuning (z= 4.45, p &lt; .001). Output JASP uji Wilcoxon signed-rank tidak menampilkan secara otomatis Median (Mdn) masing-masing kelompok, sehingga jika diperlukan Median masing-masing kelompok, dapat dihitung dengan menggunakan menu Descriptive pada software JASP.\n\n\n\nTabel 19.4: Contoh hasil analisis Wilcoxon signed-rank\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPengukuran 1\nPengukuran 2\nW\nz\ndf\np\nRank-Biserial Correlation\nSE Rank-Biserial Correlation\n\n\n\n\nHitam\nKuning\n1021.5\n4.446\n\n&lt; .001\n0.737\n0.164",
    "crumbs": [
      "PERBEDAAN RATA-RATA DUA KELOMPOK",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Asumsi, Interpretasi, dan Pelaporan Analisis Paired Samples t-test: Parametrik dan Non-Parametrik</span>"
    ]
  },
  {
    "objectID": "5_latihan.html",
    "href": "5_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bagian 5 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "PERBEDAAN RATA-RATA DUA KELOMPOK",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "6_anova.html",
    "href": "6_anova.html",
    "title": "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
    "section": "",
    "text": "Pada bab sebelumnya, kita telah mempelajari bagaimana membandingkan rata-rata dua kelompok menggunakan uji-t dan uji Mann-Whitney. Namun, dalam banyak situasi penelitian, kita dihadapkan pada lebih dari dua kelompok yang perlu dibandingkan sekaligus. Misalnya, seorang peneliti ingin mengetahui apakah tingkat stres berbeda antara mahasiswa tahun pertama, kedua, dan ketiga. Untuk keperluan ini, menggunakan serangkaian uji-t antar pasangan kelompok bukanlah pilihan yang tepat, karena meningkatkan risiko kesalahan Tipe I. Di sinilah Analisis Varians (ANOVA) menjadi penting. ANOVA memungkinkan kita membandingkan rata-rata tiga kelompok atau lebih secara serempak dalam satu kerangka uji statistik, sambil menjaga tingkat kesalahan tetap terkendali. Pendekatan ini jauh lebih efisien dan akurat dibandingkan mengandalkan uji-t berulang-ulang.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 20. Tujuan Perbandingan Tiga Kelompok atau Lebih:\n\nMemahami alasan mengapa perbandingan rata-rata tiga kelompok atau lebih diperlukan dalam penelitian.\n\nBab 21. Prinsip-prinsip Dasar dan Asumsi-Asumsi ANOVA:\n\nMenjelaskan prinsip kerja ANOVA dalam membandingkan variasi antar dan dalam kelompok.\nMemahami dan mengenali asumsi-asumsi dasar ANOVA yang harus dipenuhi untuk analisis yang valid.\nMemahami perbedaan antara planned contrasts dan uji post-hoc dalam analisis data.\n\nBab 22. Jenis-Jenis ANOVA:\n\nMengenali berbagai jenis ANOVA (one-way, two-way, repeated measures, dan mixed-design) serta aplikasinya.\n\nBab 23. Interpretasi Hasil Analisis:\n\nMembaca, menginterpretasikan, dan menuliskan hasil analisis ANOVA sesuai kaidah akademik.\n\nBab 24. Alternatif Non-Parametrik untuk ANOVA:\n\nMenginterpretasikan dan menuliskan hasil uji non-parametrik sebagai alternatif ANOVA.",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK"
    ]
  },
  {
    "objectID": "6_1_tujuan_anova.html",
    "href": "6_1_tujuan_anova.html",
    "title": "20  Tujuan Perbandingan Tiga Kelompok atau Lebih",
    "section": "",
    "text": "Dalam penelitian di bidang sosial dan perilaku, kita sering kali menghadapi kebutuhan untuk mengetahui apakah rata-rata suatu variabel berbeda di antara beberapa kelompok. Misalnya, seorang peneliti mungkin ingin mengetahui apakah tingkat stres mahasiswa berbeda antara tahun pertama, kedua, dan ketiga. Dalam situasi seperti ini, membandingkan rata-rata menggunakan uji-t berulang-ulang tidaklah efisien, karena dapat meningkatkan risiko kesalahan Tipe I. Oleh karena itu, analisis varians (ANOVA) digunakan sebagai pendekatan yang lebih tepat.\nTujuan utama dari membandingkan tiga kelompok atau lebih adalah untuk menguji apakah terdapat perbedaan rata-rata yang signifikan di antara kelompok-kelompok tersebut, tanpa meningkatkan tingkat kesalahan statistik. Dengan menggunakan ANOVA, peneliti dapat menganalisis variasi yang terjadi antara kelompok serta variasi yang terjadi di dalam kelompok, sehingga memungkinkan pengambilan kesimpulan yang lebih akurat. Teknik ini juga membantu menghindari kesalahan dalam interpretasi data yang dapat terjadi bila banyak uji-t dilakukan secara terpisah.\nSebagai contoh, seorang peneliti pendidikan dapat menggunakan ANOVA untuk membandingkan nilai rata-rata siswa yang mengikuti tiga metode pengajaran berbeda, yaitu metode konvensional, blended learning, dan pembelajaran daring penuh. Demikian pula, seorang psikolog klinis dapat menggunakan ANOVA untuk menguji perbedaan tingkat kecemasan antara pasien yang menjalani terapi kognitif, terapi perilaku, dan terapi kombinasi. Dalam kedua contoh tersebut, ANOVA memberikan cara yang terstruktur untuk menguji satu pertanyaan penting: apakah rata-rata dari setidaknya satu kelompok berbeda secara signifikan dibandingkan dengan kelompok lain.\nJika hasil ANOVA menunjukkan adanya perbedaan yang signifikan, langkah selanjutnya adalah melakukan analisis lanjutan, seperti uji post-hoc atau planned contrasts (Bagian 22.5), untuk mengidentifikasi kelompok mana yang berbeda. Dengan demikian, memahami tujuan perbandingan tiga kelompok atau lebih merupakan landasan penting sebelum mempelajari prinsip-prinsip, jenis-jenis, serta cara penulisan laporan hasil analisis varians.",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Tujuan Perbandingan Tiga Kelompok atau Lebih</span>"
    ]
  },
  {
    "objectID": "6_2_prinsip_anova.html",
    "href": "6_2_prinsip_anova.html",
    "title": "21  Prinsip-prinsip Dasar dan Asumsi-asumsi ANOVA",
    "section": "",
    "text": "21.1 Statistik f: Rasio Variabilitas\nAnalisis Varians, atau ANOVA, adalah metode statistik yang digunakan untuk menentukan apakah terdapat perbedaan yang signifikan secara statistik antara rata-rata tiga atau lebih kelompok penelitian. Teknik ini sangat berguna dalam penelitian eksperimental di mana beberapa kelompok dibandingkan dalam kondisi atau perlakuan yang berbeda. Dengan menganalisis varians dalam dan antar kelompok, ANOVA membantu peneliti memahami bagaimana faktor-faktor berbeda memengaruhi hasil tertentu, memberikan informasi penting tentang hubungan antar variabel.\nANOVA didasarkan pada prinsip membandingkan variasi yang terjadi antar kelompok dengan variasi yang terjadi di dalam kelompok. Ketika perbedaan antar kelompok lebih besar dibandingkan variasi di dalam kelompok, hal ini mengindikasikan bahwa ada kemungkinan rata-rata kelompok memang berbeda secara nyata. Dengan kata lain, ANOVA menilai apakah variabilitas yang diamati dalam data lebih banyak dijelaskan oleh perbedaan antar kelompok (true variance) daripada oleh variasi acak di dalam kelompok (error variance).\nIde utama ANOVA adalah untuk membandingkan kedua jenis variabilitas ini melalui rasio yang disebut Statistik F (F statistics), yang dapat digambarkan dalam persamaan berikut:\n\\[\nF = \\frac{\\text{varians antar kelompok}}{\\text{varians dalam kelompok}}\n\\]\nJika nilai F besar, ini berarti perbedaan antar kelompok lebih besar dibandingkan variasi dalam kelompok. Artinya, perbedaan rata-rata kelompok bukan kebetulan dan kemungkinan disebabkan oleh variabel independen. Dengan kata lain, efek perlakuan lebih kuat daripada variasi acak. Jika nilai F melebihi nilai kritis dari tabel distribusi F, hipotesis nol dapat ditolak.\nJika statistik F kecil (mendekati 1 atau kurang), ini berarti variabilitas antar kelompok serupa dengan variabilitas dalam kelompok. Ini menunjukkan bahwa perbedaan antara rata-rata kelompok mungkin hanya disebabkan oleh kebetulan atau variasi acak, dan variabel independen mungkin tidak memiliki efek yang signifikan.",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Prinsip-prinsip Dasar dan Asumsi-asumsi *ANOVA*</span>"
    ]
  },
  {
    "objectID": "6_2_prinsip_anova.html#asumsi-asumsi-dasar-anova",
    "href": "6_2_prinsip_anova.html#asumsi-asumsi-dasar-anova",
    "title": "21  Prinsip-prinsip Dasar dan Asumsi-asumsi ANOVA",
    "section": "21.2 Asumsi-asumsi Dasar ANOVA",
    "text": "21.2 Asumsi-asumsi Dasar ANOVA\nUntuk memastikan hasil ANOVA valid dan dapat diandalkan, terdapat beberapa asumsi dasar yang perlu dipenuhi (Gambar 21.1). Pertama, data dari setiap kelompok yang dibandingkan harus saling independen, artinya nilai-nilai dari satu kelompok tidak boleh memengaruhi nilai-nilai dari kelompok lain. Independensi ini biasanya dijaga melalui prosedur pengambilan sampel yang tepat atau penugasan acak dalam eksperimen.\nKedua, ANOVA mengasumsikan bahwa data dalam setiap kelompok mengikuti distribusi normal. Meskipun ANOVA cukup robust terhadap pelanggaran normalitas pada ukuran sampel besar, penyimpangan yang berat dari normalitas dapat mengurangi keakuratan hasil. Oleh karena itu, sebelum melakukan analisis, sebaiknya dilakukan pemeriksaan normalitas melalui visualisasi data, seperti histogram atau plot Q-Q, ataupun menggunakan uji statistik seperti Shapiro-Wilk.\nKetiga, variansi antar kelompok yang dibandingkan diharapkan homogen atau seragam. Homogenitas varians ini penting karena ANOVA membandingkan rata-rata dengan memperhitungkan variabilitas dalam kelompok. Apabila variansi antar kelompok sangat berbeda, maka kesimpulan yang dihasilkan dari ANOVA bisa menjadi bias. Untuk menguji asumsi ini, dapat digunakan uji Levene atau uji Bartlett. Uji Levene sering digunakan untuk menilai homogenitas ini.\nApabila asumsi-asumsi tersebut tidak sepenuhnya terpenuhi, ada beberapa strategi yang bisa ditempuh. Transformasi data, penggunaan ANOVA varian robust seperti ANOVA Welch, atau beralih ke pendekatan non-parametrik menjadi pilihan untuk menjaga validitas hasil analisis. Penting untuk diingat bahwa pengecekan asumsi bukan sekadar prosedur teknis, melainkan bagian integral dari proses analisis yang memastikan bahwa interpretasi hasil ANOVA merefleksikan kondisi data dengan akurat.\n\n\n\n\n\n\nGambar 21.1: Asumsi-asumsi ANOVA\n\n\n\nDengan memahami prinsip-prinsip dasar ini dan memastikan terpenuhinya asumsi-asumsi yang mendasarinya serta peran plannedcontrasts dan uji post-hoc, kita dapat menggunakan ANOVA secara efektif untuk menganalisis perbedaan antar kelompok dalam berbagai konteks penelitian. Prinsip-prinsip ini menjadi fondasi penting sebelum melangkah lebih jauh ke dalam ragam jenis ANOVA yang lebih kompleks.",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Prinsip-prinsip Dasar dan Asumsi-asumsi *ANOVA*</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html",
    "href": "6_3_jenis_anova.html",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "",
    "text": "22.1 ANOVA Satu Arah\nJenis-jenis ANOVA mengacu pada model statistik berbeda yang digunakan untuk menganalisis varians di antara rata-rata kelompok dalam berbagai desain eksperimental. Jenis yang paling umum digunakan adalah ANOVA Satu Arah (One-Way ANOVA) dan ANOVA Dua Arah (Two-Way ANOVA). Setiap jenis memiliki tujuan berbeda dan sesuai untuk skenario penelitian tertentu. Memahami jenis-jenis ini sangat penting untuk memilih metode analisis yang tepat berdasarkan struktur data dan desain eksperimen Anda.\nPemilihan jenis ANOVA yang akan digunakan bergantung pada desain penelitian dan sifat data yang dianalisis. Pemahaman menyeluruh tentang jenis-jenis yang berbeda memungkinkan peneliti untuk membuat keputusan yang terinformasi, memastikan bahwa analisis statistik secara akurat mencerminkan hubungan dan perbedaan yang ada dalam data. Landasan ini penting tidak hanya untuk melakukan analisis statistik yang efektif tetapi juga untuk menafsirkan hasil dengan cara yang bermakna yang berkontribusi pada bidang studi yang lebih luas.\nANOVA Satu Arah digunakan ketika peneliti ingin membandingkan rata-rata tiga atau lebih kelompok independen berdasarkan satu variabel independen. Misalnya, jika seorang peneliti sedang memeriksa dampak metode pengajaran yang berbeda terhadap kinerja siswa, mereka dapat mengelompokkan siswa ke dalam tiga kelompok berdasarkan metode yang digunakan. ANOVA Satu Arah membantu menentukan apakah ada perbedaan yang signifikan secara statistik dalam skor kinerja rata-rata di antara kelompok-kelompok ini. Jenis ANOVA ini menjawab pertanyaan mendasar tentang apakah setidaknya satu rata-rata kelompok berbeda dari yang lain tanpa mendalami interaksi antara beberapa variabel.\nMenghitung hasil dalam ANOVA satu arah melibatkan beberapa langkah kunci yang memungkinkan peneliti untuk menarik kesimpulan bermakna dari data yang diperoleh. Tujuan utama ANOVA satu arah adalah untuk menentukan apakah ada perbedaan yang signifikan secara statistik di antara rata-rata tiga atau lebih kelompok independen. Proses ini dimulai dengan perumusan hipotesis nol, yang menyatakan bahwa semua rata-rata kelompok adalah sama, dan hipotesis alternatif, yang menunjukkan bahwa setidaknya satu rata-rata kelompok berbeda. Dengan menggunakan perangkat lunak statistik atau perhitungan manual, Anda dapat memperoleh statistik F, yang membandingkan varians antar kelompok dengan varians dalam kelompok. Tabel 22.1 memuat contoh hasil analisis ANOVA satu-arah dengan menggunakan perangkat lunak JASP.\nPada ANOVA satu arah, interpretasi dimulai dengan menilai nilai F dan p-value. Jika p-value lebih kecil dari batas signifikansi, misalnya 0,05, maka dapat disimpulkan bahwa ada perbedaan signifikan di antara kelompok yang dibandingkan. Interpretasi ANOVA satu arah hanya berfokus pada satu variabel independen sehingga lebih sederhana, namun penting untuk memperhatikan ukuran efek seperti eta-squared untuk memahami seberapa besar pengaruh faktor tersebut terhadap variabel dependen. Dalam pelaporan, hasil ANOVA satu arah disusun dengan mencantumkan nilai F, derajat kebebasan antar dan dalam kelompok, nilai p, dan ukuran efek. Misalnya: “Analisis varians satu arah menunjukkan perbedaan signifikan antara kelompok, F(2, 87) = 4,76, p = 0,011, η² = 0,098.”",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html#anova-dua-arah",
    "href": "6_3_jenis_anova.html#anova-dua-arah",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "22.2 ANOVA Dua Arah",
    "text": "22.2 ANOVA Dua Arah\nANOVA Dua Arah memungkinkan pengujian dua variabel independen secara bersamaan dan efek interaksi kedua variabel tersebut terhadap variabel dependen. Misalnya, sebuah penelitian bertujuan mengeksplorasi bagaimana metode pengajaran dan jenis kelamin siswa memengaruhi kinerja. Dengan menggunakan ANOVA dua arah, peneliti dapat menilai tidak hanya efek utama dari setiap variabel independen tetapi juga apakah efek dari satu variabel berbeda tergantung pada tingkat variabel lainnya. Jenis ini sangat berguna dalam desain eksperimental yang lebih kompleks di mana interaksi antar faktor diharapkan memainkan peran penting.\nDalam ANOVA Dua Arah, interpretasi mencakup dua komponen utama: efek utama dari masing-masing variabel independen dan efek interaksi antara keduanya. Peneliti perlu menilai apakah setiap efek utama dan interaksi menunjukkan signifikansi. Memahami efek interaksi sangat penting untuk menginterpretasikan hasil ANOVA dua arah. Ketika peneliti menyelidiki pengaruh dua variabel independen terhadap variabel dependen, mereka tidak hanya tertarik pada efek utama dari masing-masing variabel independen tetapi juga bagaimana variabel-variabel ini dapat berinteraksi satu sama lain. Efek interaksi terjadi ketika pengaruh satu variabel independen terhadap variabel dependen berubah tergantung pada level variabel independen lainnya. Ini berarti bahwa pengaruh gabungan dari variabel-variabel tersebut tidak hanya bersifat aditif; sebaliknya, hubungannya lebih kompleks dan memerlukan pemeriksaan yang cermat.\n\n\n\n\n\n\nANOVA desain faktorial\n\n\n\nPenelitian yang melibatkan lebih dari satu variabel independen (faktor) untuk melihat pengaruhnya terhadap variabel dependen disebut juga sebagai ANOVA desain faktorial. Umumnya, desain ini dituliskan dalam bentuk “faktorial 2x2” (atau 3x2, 2x4, dan seterusnya). Notasi tersebut menunjukkan jumlah level dari masing-masing faktor; misalnya, desain 2x2 berarti ada dua faktor, dan masing-masing faktor memiliki dua level.\n\n\nUntuk mengilustrasikan efek interaksi, perhatikan sebuah penelitian yang menguji pengaruh metode pengajaran dan jenis kelamin siswa terhadap kinerja akademik. Jika kinerja siswa laki-laki dan perempuan berbeda secara signifikan berdasarkan metode pengajaran yang digunakan, ini menunjukkan efek interaksi (lihat Tabel 22.2). Misalnya, metode pengajaran tertentu mungkin lebih efektif untuk siswa perempuan sementara metode lain mungkin menguntungkan siswa laki-laki. Memahami interaksi ini memungkinkan peneliti untuk menyesuaikan strategi pendidikan untuk meningkatkan hasil bagi kelompok siswa yang berbeda, menekankan pentingnya mempertimbangkan bagaimana variabel-variabel bekerja bersama daripada secara terpisah.\nPenulisan hasil mengikuti urutan pelaporan efek utama terlebih dahulu, baru kemudian efek interaksi. Sebagai contoh: “Terdapat efek utama yang signifikan dari metode pengajaran terhadap prestasi siswa, F(2, 84) = 5,23, p = 0,007, η² = 0,111, namun tidak ditemukan interaksi yang signifikan antara metode pengajaran dan jenis kelamin, F(2, 84) = 1,04, p = 0,358.”\n\n\n\nTabel 22.2: Contoh tabel output hasil ANOVA dua-arah\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum of Squares\ndf\nMean Square\nF\np\nη²\n\n\n\n\nMetode\n11.341\n2\n4.341\n5.232\n.007\n.111\n\n\nJenis kelamin\n2.234\n1\n0.653\n2.331\n.105\n.012\n\n\nMetode ✻ Jenis kelamin\n0.351\n2\n0.121\n1.042\n.358\n.008\n\n\nResiduals\n6.748\n84\n2.548",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html#anova-pengukuran-berulang",
    "href": "6_3_jenis_anova.html#anova-pengukuran-berulang",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "22.3 ANOVA Pengukuran Berulang",
    "text": "22.3 ANOVA Pengukuran Berulang\nSelain Satu Arah dan Dua Arah, ada bentuk khusus ANOVA seperti ANOVA Pengukuran Berulang (Repeated Measures ANOVA), yang digunakan ketika partisipan yang sama diukur beberapa kali dalam kondisi berbeda. Metode ini dapat terjadi dalam studi longitudinal atau eksperimen di mana individu terpapar pada semua tingkat variabel independen.\nPada ANOVA Pengukuran Berulang, interpretasi memperhatikan signifikansi perubahan antar kondisi atau waktu. Karena pengukuran dilakukan berulang pada individu yang sama, penyesuaian untuk sphericity sering diperlukan, misalnya menggunakan koreksi Greenhouse-Geisser.\nSphericity mengacu pada kondisi di mana varians perbedaan antara setiap pasangan tingkat pengukuran berulang adalah sama. Dengan kata lain, kovarians antara setiap pasangan pengukuran berulang harus sama. Pelanggaran sphericity dapat menyebabkan peningkatan risiko kesalahan Tipe I (menolak H0​ padahal benar) dan Tipe II (gagal menolak H0​ padahal salah), sehingga hasil F-statistik menjadi tidak akurat.\nTabel 22.3 menunjukkan contoh hasil ANOVA pengukuran berulang mengenai efektivitas terapi meditasi dalam mengurangi kecemasan Penulisan hasil mencantumkan statistik F, derajat kebebasan yang telah disesuaikan (jika perlu), nilai p, dan ukuran efek, misalnya: “Analisis pengukuran berulang menunjukkan perubahan signifikan tingkat kecemasan antar sesi terapi, F(2, 29) = 8,57, p = 0,006, η²partial = 0,228. Uji post-hoc dengan koreksi Bonferroni mengungkapkan bahwa tingkat kecemasan menurun secara signifikan dari awal (M = 35.2, SD = 5.1) ke tengah (M = 28.9, SD = 4.8, p = .002) dan dari tengah ke akhir (M = 22.5, SD = 4.5, p = .001).”\n\n\n\nTabel 22.3: Contoh tabel output hasil ANOVA pengukuran berulang\n\n\nWithin-subjects effects\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum of squares\ndf1\nMean square\nF\np\nη²p\n\n\n\n\nKecemasan\n19.443\n2\n5.341\n8.567\n.006\n.228\n\n\nResiduals\n8.458\n29\n2.547\n\n\n\n\n\n\nGroup Descriptives\n\n\n\nWaktu pengukuran\nN\nMean\nSD\nSE\n\n\n\n\nAwal\n30\n35.212\n5.125\n1.123\n\n\nTengah\n30\n28.871\n4.756\n1.031\n\n\nAkhir\n30\n22.534\n4.531\n.0902",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html#anova-desain-campuran",
    "href": "6_3_jenis_anova.html#anova-desain-campuran",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "22.4 ANOVA Desain Campuran",
    "text": "22.4 ANOVA Desain Campuran\nVariasi lainnya adalah ANOVA Desain Campuran (Mixed-Design ANOVA), yang menggabungkan faktor independen dan pengukuran berulang, memungkinkan analisis data yang lebih terperinci. Memahami variasi-variasi ini memungkinkan peneliti untuk memilih metode statistik yang paling efektif untuk pertanyaan penelitian mereka yang spesifik.\nInterpretasi hasil analisis ANOVA Desain Campuran lebih kompleks karena mencakup efek utama untuk faktor between-subjects, faktor within-subjects, serta interaksi keduanya. Peneliti perlu mengevaluasi apakah ada perbedaan antar kelompok, perubahan dalam kelompok dari waktu ke waktu, dan apakah pola perubahan berbeda antar kelompok. Contoh hasil analisisnya dapat dilihat di Tabel 22.4. Penulisan hasil memuat masing-masing efek secara sistematis. Misalnya: “Terdapat efek utama yang signifikan dari kelompok perlakuan terhadap tingkat stres, F(1, 58) = 10,12, p = 0,002, serta efek waktu yang signifikan, F(2, 116) = 6,87, p = 0,002. Interaksi antara kelompok dan waktu juga signifikan, F(2, 116) = 4,21, p = 0,017, menunjukkan bahwa perubahan stres antar waktu berbeda berdasarkan kelompok perlakuan.”\n\n\n\nTabel 22.4: Contoh tabel output hasil ANOVA campuran\n\n\nWithin-subjects effects\n\n\n\n\n\n\n\n\n\n\n\n\nCases\nSum of squares\ndf\nMean square\nF\np\nη²p\n\n\n\n\nWaktu\n28.212\n1\n7.311\n6.871\n.002\n.311\n\n\nWaktu ✻ Treatment\n23.553\n2\n6.431\n4.212\n.017\n.124\n\n\nResiduals\n29.221\n116\n7.531\n\n\n\n\n\n\nBetween-subjects effects\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum of squares\ndf\nMean square\nF\np\nη²\n\n\n\n\nTreatment\n45.112\n1\n12.477\n10.124\n.002\n.398\n\n\nResiduals\n60.211\n58\n13.415",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html#uji-post-hoc-vs.-planned-contrasts",
    "href": "6_3_jenis_anova.html#uji-post-hoc-vs.-planned-contrasts",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "22.5 Uji Post-hoc vs. Planned Contrasts",
    "text": "22.5 Uji Post-hoc vs. Planned Contrasts\nSetelah uji ANOVA menunjukkan adanya perbedaan rata-rata yang signifikan, peneliti perlu mengidentifikasi lebih jauh kelompok mana yang berbeda. Di sinilah planned contrasts dan uji post-hoc berperan. Planned contrasts digunakan ketika peneliti sejak awal telah menetapkan hipotesis spesifik mengenai kelompok mana yang diharapkan berbeda. Misalnya, dalam studi tentang efektivitas tiga metode pengajaran, seorang peneliti mungkin sejak awal ingin menguji apakah metode A lebih efektif dibandingkan metode B dan C secara gabungan.\nSementara itu, uji post-hoc digunakan ketika peneliti tidak memiliki prediksi spesifik tentang kelompok mana yang berbeda sebelum analisis dilakukan. Setelah menemukan hasil ANOVA yang signifikan, uji post-hoc dijalankan untuk mengeksplorasi semua kemungkinan perbedaan antar pasangan kelompok.\nBeberapa uji post-hoc yang umum meliputi:\n\nUji Tukey HSD: Uji ini digunakan ketika varians kelompok sama dan ukuran sampel sama.\nUji Bonferroni: Uji ini digunakan ketika varians kelompok tidak sama atau ukuran sampel tidak sama.\nUji Scheffe: Uji ini adalah uji yang paling konservatif dan digunakan ketika ada banyak perbandingan yang dibuat.\n\nMemahami perbedaan antara planned contrasts dan uji post-hoc penting dalam desain analisis, karena keduanya menjadi metode yang menjawab kebutuhan penelitian yang berbeda. Planned contrasts lebih terfokus dan lebih kuat secara statistik untuk hipotesis yang sudah direncanakan, sedangkan uji post-hoc memberikan fleksibilitas eksploratif dalam menganalisis data setelah hasil utama ditemukan.",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html#effect-size-dan-visualisasi-hasil-analisis",
    "href": "6_3_jenis_anova.html#effect-size-dan-visualisasi-hasil-analisis",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "22.6 Effect Size dan Visualisasi Hasil Analisis",
    "text": "22.6 Effect Size dan Visualisasi Hasil Analisis\nDalam semua jenis ANOVA, ukuran efek seperti eta-squared atau partial eta-squared sangat dianjurkan untuk dilaporkan karena memberikan informasi tambahan tentang besarnya pengaruh yang ditemukan. Selain itu, visualisasi hasil menggunakan diagram batang atau plot garis dapat memperjelas interpretasi perbedaan antar kelompok atau perubahan dalam waktu, seperti yang ditampilkan dalam Gambar 22.1.\n\n\n\n\n\n\nGambar 22.1: Contoh penggunaan visualisasi hasil analisis",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html#sec-posthoc",
    "href": "6_3_jenis_anova.html#sec-posthoc",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "22.5 Uji Post-hoc vs. Planned Contrasts",
    "text": "22.5 Uji Post-hoc vs. Planned Contrasts\nSetelah uji ANOVA menunjukkan adanya perbedaan rata-rata yang signifikan, peneliti perlu mengidentifikasi lebih jauh kelompok mana yang berbeda. Di sinilah planned contrasts dan uji post-hoc berperan. Planned contrasts digunakan ketika peneliti sejak awal telah menetapkan hipotesis spesifik mengenai kelompok mana yang diharapkan berbeda. Misalnya, dalam studi tentang efektivitas tiga metode pengajaran, seorang peneliti mungkin sejak awal ingin menguji apakah metode A lebih efektif dibandingkan metode B dan C secara gabungan.\nSementara itu, uji post-hoc digunakan ketika peneliti tidak memiliki prediksi spesifik tentang kelompok mana yang berbeda sebelum analisis dilakukan. Setelah menemukan hasil ANOVA yang signifikan, uji post-hoc dijalankan untuk mengeksplorasi semua kemungkinan perbedaan antar pasangan kelompok.\nMisalnya, kita melakukan uji post hoc dari data Tabel 22.1. Hasil ANOVA menunjukkan adanya perbedaan yang signifikan antar kelompok metode terapi, F(2, 87) = 4,76, p = 0,011. Namun, dari hasil tersebut kita belum bisa mengidentifikasi antar kelompok mana yang berbeda. Uji post hoc bisa membantu kita menyimpulkan perbedaan dari masing-masing kelompok yang diteliti. Dari hasil yang dipaparkan pada Tabel 22.5, data menunjukkan bahwa terdapat perbedaan yang signifikan antara kelompok CBT dan Journaling (t(87) = 4.360, ptukey = .002). Begitu juga dengan perbedaan antara Journaling dan Placebo (t(87) = 5.876, ptukey &lt; .001). Namun, tidak ditemukan adanya perbedaan antara kelompok CBT dan Placebo (t(87) = 1.516, ptukey = .012). Dari hasil ini kita dapat menyimpulkan bahwa metode Journaling adalah metode yang paling efektif dalam mereduksi stres pada partisipan, sedangkan metode CBT dan Placebo menunjukkan efek yang tidak berbeda.\n\n\n\nTabel 22.5: Contoh hasil uji post hoc\n\n\nPost hoc comparisons: Metode terapi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMean difference\nSE\ndf\nt\nptukey\n\n\n\n\nCBT\nJournaling\n-0.766\n0.176\n87\n-4.360\n.002\n\n\n\nPlacebo\n0.267\n0.176\n87\n1.516\n.012\n\n\nJournaling\nPlacebo\n1.033\n0.176\n87\n5.876\n&lt;.001\n\n\n\n\n\n\nBeberapa uji post-hoc yang umum meliputi:\n\nUji Tukey HSD: Uji ini digunakan ketika varians kelompok sama dan ukuran sampel sama.\nUji Bonferroni: Uji ini digunakan ketika varians kelompok tidak sama atau ukuran sampel tidak sama.\nUji Scheffe: Uji ini adalah uji yang paling konservatif dan digunakan ketika ada banyak perbandingan yang dibuat.\n\nMemahami perbedaan antara planned contrasts dan uji post-hoc penting dalam desain analisis, karena keduanya menjadi metode yang menjawab kebutuhan penelitian yang berbeda. Planned contrasts lebih terfokus dan lebih kuat secara statistik untuk hipotesis yang sudah direncanakan, sedangkan uji post-hoc memberikan fleksibilitas eksploratif dalam menganalisis data setelah hasil utama ditemukan.",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_3_jenis_anova.html#anova-satu-arah",
    "href": "6_3_jenis_anova.html#anova-satu-arah",
    "title": "22  Jenis-jenis ANOVA dan Interpretasi Hasil Analisis",
    "section": "",
    "text": "Tabel 22.1: Contoh tabel output hasil ANOVA satu-arah\n\n\nOne-Way ANOVA\n\n\n\n\n\n\n\n\n\n\n\n\n\nSum of squares\ndf1\nMean square\nF\np\nη²\n\n\n\n\nMetode terapi\n24.420\n2\n8.140\n4.761\n.011\n.098\n\n\nResiduals\n613.139\n87\n2.813\n\n\n\n\n\n\nGroup Descriptives\n\n\n\nMetode terapi\nN\nMean\nSD\nSE\n\n\n\n\nCBT\n30\n0.717\n0.392\n0.160\n\n\nJournaling\n31\n1.483\n0.214\n0.087\n\n\nPlacebo\n29\n0.450\n0.281\n0.115",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Jenis-jenis *ANOVA* dan Interpretasi Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "6_4_anova_nonpar.html",
    "href": "6_4_anova_nonpar.html",
    "title": "23  Alternatif Non-Parametrik untuk ANOVA",
    "section": "",
    "text": "23.1 Uji Kruskal-Wallis: Alternatif Non-Parametrik untuk ANOVA Satu Arah\nKetika data tidak memenuhi asumsi-asumsi parametrik dalam pengujian ANOVA, atau memiliki skala pengukuran yang berbeda, pendekatan non-parametrik menjadi alternatif yang tepat. Uji non-parametrik tidak memerlukan asumsi distribusi data yang ketat dan cocok untuk data ordinal atau nominal. Oleh karena itu, teknik ini memungkinkan analisis yang lebih fleksibel tanpa mengorbankan validitas hasil.\nSalah satu uji non-parametrik yang paling umum digunakan untuk menggantikan ANOVA Satu Arah adalah Uji Kruskal-Wallis. Uji ini digunakan untuk menguji apakah ada perbedaan yang signifikan dalam median antar tiga kelompok atau lebih. Berbeda dengan ANOVA yang membandingkan rata-rata, uji Kruskal-Wallis membandingkan peringkat data dalam setiap kelompok.\nKapan menggunakan Kruskal-Wallis?\nProsedur analisis:\nDalam penulisan laporan, hasil uji non-parametrik harus dilaporkan dengan cara yang jelas dan sistematis. Contoh penulisan laporan untuk uji Kruskal-Wallis:\n“Uji Kruskal-Wallis menunjukkan bahwa terdapat perbedaan yang signifikan dalam peringkat antara kelompok, H(2) = 6,32, p = 0,042. Post-hoc dengan uji Mann-Whitney menunjukkan bahwa kelompok A memiliki peringkat yang lebih tinggi dibandingkan kelompok B (p = 0,012).”",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Alternatif Non-Parametrik untuk *ANOVA*</span>"
    ]
  },
  {
    "objectID": "6_4_anova_nonpar.html#uji-kruskal-wallis-alternatif-non-parametrik-untuk-anova-satu-arah",
    "href": "6_4_anova_nonpar.html#uji-kruskal-wallis-alternatif-non-parametrik-untuk-anova-satu-arah",
    "title": "23  Alternatif Non-Parametrik untuk ANOVA",
    "section": "",
    "text": "Data variabel dependen tidak terdistribusi normal di setiap kelompok.\nUkuran sampel kecil dan data menunjukkan penyimpangan yang jelas dari normalitas.\nVariabel dependen adalah ordinal (misalnya, peringkat, skala Likert yang dianggap ordinal).\n\n\n\nData diurutkan dan diberi peringkat (ranking).\nUji ini menguji apakah distribusi peringkat antar kelompok berbeda secara signifikan.\nJika p-value dari uji Kruskal-Wallis lebih kecil dari tingkat signifikansi (biasanya 0,05), kita menolak hipotesis nol, yang berarti ada perbedaan yang signifikan antar kelompok.\nJika uji Kruskal-Wallis signifikan, Anda perlu melakukan perbandingan berpasangan (post-hoc) untuk mengidentifikasi kelompok mana yang berbeda. Namun, tidak ada uji post-hoc standar tunggal seperti Tukey untuk Kruskal-Wallis. Umumnya, Anda dapat melakukan uji Mann-Whitney U secara berpasangan untuk setiap kombinasi kelompok, dan menerapkan koreksi Bonferroni untuk mengontrol kesalahan Tipe I.",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Alternatif Non-Parametrik untuk *ANOVA*</span>"
    ]
  },
  {
    "objectID": "6_4_anova_nonpar.html#uji-friedman-alternatif-non-parametrik-untuk-anova-pengukuran-berulang",
    "href": "6_4_anova_nonpar.html#uji-friedman-alternatif-non-parametrik-untuk-anova-pengukuran-berulang",
    "title": "23  Alternatif Non-Parametrik untuk ANOVA",
    "section": "23.2 Uji Friedman: Alternatif Non-Parametrik untuk ANOVA Pengukuran Berulang",
    "text": "23.2 Uji Friedman: Alternatif Non-Parametrik untuk ANOVA Pengukuran Berulang\nUntuk desain eksperimen dengan pengukuran berulang yang tidak memenuhi asumsi normalitas, Uji Friedman dapat digunakan sebagai alternatif non-parametrik untuk Repeated Measures ANOVA. Uji Friedman membandingkan peringkat data pada lebih dari dua kondisi pengukuran yang dilakukan pada subjek yang sama.\nUji Friedman adalah perpanjangan non-parametrik dari uji Wilcoxon Signed-Rank untuk lebih dari dua pengukuran. Prosedur analisisnya meliputi:\n\nMemberikan peringkat pada observasi dalam setiap subjek di antara kondisi/titik waktu.\nMenjumlahkan peringkat untuk setiap kondisi/titik waktu.\nMenghitung statistik Friedman (χ2​), yang membandingkan jumlah peringkat yang diamati dengan jumlah peringkat yang diharapkan jika tidak ada perbedaan antar kondisi.\n\nJika uji Friedman signifikan, Anda perlu melakukan uji post hoc untuk mengidentifikasi pasangan kondisi/titik waktu mana yang berbeda secara signifikan. Anda dapat menggunakan uji Wilcoxon Signed-Rank berpasangan untuk setiap kombinasi dan menerapkan koreksi Bonferroni untuk mengontrol kesalahan Tipe I.\nContoh penulisan hasil (non-parametrik):\n“Karena asumsi normalitas dilanggar, uji Friedman dilakukan untuk membandingkan peringkat kinerja tugas siswa pada tiga sesi pelatihan yang berbeda (Sesi 1, Sesi 2, Sesi 3). Ditemukan perbedaan yang signifikan secara statistik di antara sesi-sesi pelatihan, χ2​(2) =9 .87, p = .007. Uji post-hoc Wilcoxon Signed-Rank dengan koreksi Bonferroni menunjukkan bahwa kinerja meningkat secara signifikan dari Sesi 1 ke Sesi 2 (p = .008) dan dari Sesi 2 ke Sesi 3 (p = .015).”",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Alternatif Non-Parametrik untuk *ANOVA*</span>"
    ]
  },
  {
    "objectID": "6_latihan.html",
    "href": "6_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bagian 6 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "MEMBANDINGKAN RATA-RATA TIGA ATAU LEBIH KELOMPOK",
      "Soal Latihan"
    ]
  },
  {
    "objectID": "7_1_karakteristik_korelasi.html",
    "href": "7_1_karakteristik_korelasi.html",
    "title": "24  Karakteristik Hubungan Antara Dua Variabel",
    "section": "",
    "text": "24.1 Arah Hubungan Korelasi\nHubungan antara dua variabel dalam statistik dapat dilihat dari uji korelasi, yaitu suatu teknik yang digunakan untuk mengukur dan menggambarkan sebuah keterkaitan antara dua variabel. Dalam uji korelasi, terdapat tiga karakteristik hubungan antara variabel X dan Y yaitu arah hubungan (positif atau negatif), bentuk hubungan (linear atau non linear) dan kekuatan hubungan.\nBerdasarkan arah hubungan, korelasi dapat dibedakan menjadi korelasi positif dan negatif. Korelasi positif (+) adalah ketika kedua variabel berubah dengan arah yang sama (X dan Y sama-sama naik/ meningkat atau X dan Y sama-sama turun). Dengan kata lain, jika variabel X mengalami peningkatan skor, maka variabel Y juga mengalami peningkatan skor. Atau, jika variabel X mengalami penurunan skor, maka variabel Y juga menurun. Misalnya, jika suhu di luar panas (terik), penjualan es teh manis meningkat; sedangkan jika cuaca mendung (suhu lebih dingin), penjualan es teh manis menurun. Hal ini menunjukkan bahwa suhu berkorelasi positif dengan penjualan es teh manis. Sementara itu, korelasi negatif (-) terjadi ketika kedua variabel berubah dengan arah yang berlawanan (X naik maka Y turun, atau X turun maka Y naik). Peningkatan skor pada variabel X diikuti dengan penurunan skor pada variabel Y. Misalnya, seorang dengan tingkat stres yang tinggi cenderung memiliki tingkat kebahagiaan yang rendah; stres berkorelasi negatif dengan kebahagiaan. Arah hubungan dapat divisualisasikan dalam scatter plot (lihat Gambar 24.1).",
    "crumbs": [
      "ANALISIS KORELASI",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Karakteristik Hubungan Antara Dua Variabel</span>"
    ]
  },
  {
    "objectID": "7_1_karakteristik_korelasi.html#arah-hubungan-korelasi",
    "href": "7_1_karakteristik_korelasi.html#arah-hubungan-korelasi",
    "title": "24  Karakteristik Hubungan Antara Dua Variabel",
    "section": "",
    "text": "Gambar 24.1: Visualisasi arah korelasi",
    "crumbs": [
      "ANALISIS KORELASI",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Karakteristik Hubungan Antara Dua Variabel</span>"
    ]
  },
  {
    "objectID": "7_1_karakteristik_korelasi.html#bentuk-hubungan-korelasi",
    "href": "7_1_karakteristik_korelasi.html#bentuk-hubungan-korelasi",
    "title": "24  Karakteristik Hubungan Antara Dua Variabel",
    "section": "24.2 Bentuk Hubungan Korelasi",
    "text": "24.2 Bentuk Hubungan Korelasi\nBentuk hubungan antara dua variabel  dibedakan menjadi hubungan linear dan non linear. Bentuk hubungan ini akan terlihat lebih jelas ketika data kedua variabel divisualisasikan dalam sebuah plot. Hubungan linear adalah ketika titik-titik dalam scatter plot cenderung membentuk garis lurus. Sedangkan, hubungan non linear terjadi jika titik-titik dalam scatter plot cenderung membentuk garis lengkung. Visualisasi hubungan linear dapat dilihat pada Gambar 7.1., sedangkan hubungan non linear dapat dilihat pada Gambar 24.2.\n\n\n\n\n\n\nGambar 24.2: Visualisasi korelasi non-linear",
    "crumbs": [
      "ANALISIS KORELASI",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Karakteristik Hubungan Antara Dua Variabel</span>"
    ]
  },
  {
    "objectID": "7_1_karakteristik_korelasi.html#besaran-hubungan-korelasi",
    "href": "7_1_karakteristik_korelasi.html#besaran-hubungan-korelasi",
    "title": "24  Karakteristik Hubungan Antara Dua Variabel",
    "section": "24.3 Besaran Hubungan Korelasi",
    "text": "24.3 Besaran Hubungan Korelasi\nBesarnya kekuatan korelasi ditentukan oleh angka hasil pengujian korelasi atau disebut dengan koefisien korelasi. Koefisien korelasi mencerminkan tingkat konsistensi hubungan antara dua variabel. Koefisien korelasi berada pada rentang 0.00 (tidak berkorelasi) dan 1.00 (korelasi sempurna), semakin mendekati 1.00 menunjukkan derajat hubungan yang semakin kuat. Koefisien korelasi .72 memiliki hubungan yang lebih kuat dibandingkan .55. Ketika divisualisasikan dalam scatter plot, kuat atau lemahnya korelasi dapat dilihat dari kepadatan sebaran data di sekitar garis korelasi. Visualisasi dapat dilihat pada Gambar 24.3, sedangkan kekuatan korelasi dapat diinterpretasikan dengan mengacu pada Tabel 24.1.\n\n\n\n\n\n\nGambar 24.3: Visualisasi kekuatan korelasi\n\n\n\n\n\n\nTabel 24.1: Kekuatan koefisien korelasi\n\n\n\n\n\n\n\n\n\n\nKekuatan korelasi\nKoefisien korelasi Positif\nKoefisien korelasi Negatif\n\n\n\n\nLemah\n0 – .30\n0 – -.30\n\n\nSedang\n.31 – .50\n-.31 – -.50\n\n\nKuat\n.51 – .70\n-.51 – -.70\n\n\nSangat kuat\n.71 – 1.00\n-.71 – -1.00",
    "crumbs": [
      "ANALISIS KORELASI",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Karakteristik Hubungan Antara Dua Variabel</span>"
    ]
  },
  {
    "objectID": "7_korelasi.html",
    "href": "7_korelasi.html",
    "title": "ANALISIS KORELASI",
    "section": "",
    "text": "Pada bagian ini akan dibahas mengenai hubungan atau korelasi antara dua variabel penelitian, yaitu melihat apakah dua variabel mengalami perubahan secara bersama-sama. Untuk melihat hubungan ini, setiap individu yang menjadi sampel atau yang diukur, harus memiliki skor kedua variabel (Variabel X dan Y). Uji korelasi umumnya digunakan untuk uji validitas alat ukur, reliabilitas aitem dalam sebuah alat ukur, dan untuk verifikasi atau menguji keterhubungan variabel-variabel dalam teori yang dikembangkan.\n\n\n\n\n\n\nTujuan Pembelajaran\n\n\n\nBab 25. Karakteristik Hubungan Antara Dua Variabel:\n\nMemahami konsep-konsep dasar analisis korelasi.\nMemahami arah, bentuk, dan besaran hubungan antar variabel.\n\nBab 26. Asumsi-asumsi Korelasi, Interpretasi, dan Penulisan Hasil Analisis:\n\nMemahami asumsi yang perlu dipenuhi dalam hubungan antara dua variabel\nMampu menginterpretasikan hasil analisis dan menulis laporan hasil korelasi sesuai standar akademik.",
    "crumbs": [
      "ANALISIS KORELASI"
    ]
  },
  {
    "objectID": "7_2_asumsi_korelasi.html",
    "href": "7_2_asumsi_korelasi.html",
    "title": "25  Asumsi-asumsi Korelasi, Interpretasi, dan Penulisan Hasil Analisis",
    "section": "",
    "text": "25.1 Asumsi dalam Hubungan Antara Dua Variabel\nTujuan analisis korelasi utamanya adalah untuk mengukur kekuatan dan arah hubungan antara dua variabel. Meskipun metode ini sering digunakan dalam berbagai disiplin ilmu, agar hasilnya valid, ada beberapa asumsi dasar yang harus dipenuhi, seperti normalitas distribusi data. Memahami asumsi-asumsi ini sangat penting agar peneliti dapat menarik kesimpulan yang akurat dan tidak bias. Selain itu, interpretasi hasil analisis korelasi perlu dilakukan dengan hati-hati, mengingat korelasi tidak membuktikan sebab-akibat, melainkan hanya mengukur derajat hubungan antar variabel. Sub-bab ini akan membahas asumsi-asumsi yang perlu dipenuhi dalam analisis korelasi, serta bagaimana menginterpretasikan hasil korelasi dan menuliskan laporan hasil analisis dengan cara yang jelas dan sistematis.\nUji asumsi hubungan antara dua variabel digunakan untuk menentukan teknik statistik yang digunakan dalam menghitung koefisien korelasi, apakah akan menggunakan uji korelasi parametrik (Pearson correlation; r) atau non-parametrik (Spearman correlation; rs). Terdapat empat asumsi yang perlu dipenuhi jika ingin menggunakan uji korelasi parametrik (Pearson correlation), yaitu:\nJika terdapat asumsi yang tidak terpenuhi, maka dilakukan uji korelasi non-parametrik menggunakan analisis korelasi Spearman.",
    "crumbs": [
      "ANALISIS KORELASI",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Asumsi-asumsi Korelasi, Interpretasi, dan Penulisan Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "7_2_asumsi_korelasi.html#asumsi-dalam-hubungan-antara-dua-variabel",
    "href": "7_2_asumsi_korelasi.html#asumsi-dalam-hubungan-antara-dua-variabel",
    "title": "25  Asumsi-asumsi Korelasi, Interpretasi, dan Penulisan Hasil Analisis",
    "section": "",
    "text": "Kedua variabel yang diteliti atau yang ingin dikorelasikan harus berupa skala kontinum.\nKedua variabel memiliki hubungan yang linear yang dapat dipastikan dengan menggunakan scatter plot.\nData tidak memiliki banyak outliers.\nData terdistribusi dengan normal.",
    "crumbs": [
      "ANALISIS KORELASI",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Asumsi-asumsi Korelasi, Interpretasi, dan Penulisan Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "7_2_asumsi_korelasi.html#interpretasi-dan-penulisan-hasil-uji-korelasi",
    "href": "7_2_asumsi_korelasi.html#interpretasi-dan-penulisan-hasil-uji-korelasi",
    "title": "25  Asumsi-asumsi Korelasi, Interpretasi, dan Penulisan Hasil Analisis",
    "section": "25.2 Interpretasi dan Penulisan Hasil Uji Korelasi",
    "text": "25.2 Interpretasi dan Penulisan Hasil Uji Korelasi\nDalam melakukan interpretasi, hal pertama yang perlu dilihat adalah nilai signifikansi (p-value). Uji hubungan antara dua variabel dikatakan signifikan jika nilai p-value lebih kecil dari .05 (p &lt; .05), artinya terdapat hubungan yang signifikan antara variabel X dan variabel Y. Jika terdapat hubungan, maka interpretasi dilanjutkan dengan melihat arah korelasi (positif atau negatif) dan besaran koefisien korelasi. Jika tidak terdapat hubungan yang signifikan (p &gt; .05), maka interpretasi terkait arah dan derajat korelasi tidak perlu dilanjutkan. Interpretasi hasil uji korelasi dapat lebih dipahami melalui output dari analisis JASP (Gambar 25.1).\n\n\n\n\n\n\nGambar 25.1: Output hasil uji korelasi\n\n\n\nDari output yang ditampilkan pada Gambar 25.1 diketahui bahwa well-being berkorelasi secara signifikan dengan learning engagement dan aspek kepribadian neuroticism (p &lt; .001), namun tidak berkorelasi dengan aspek kepribadian opennes to experiences, karena p value lebih besar dari .05 (p = .052). Interpretasi terkait arah dan besaran korelasi dapat dilanjutkan pada hasil yang signifikan, diketahui terdapat hubungan positif antara well-being dan learning engagement (rs = .669), sementara itu, hubungan antara well-being dan neuroticism berkorelasi negatif (rs = -.396). Derajat kekuatan korelasi antara antara well-being dan learning engagement tergolong kuat (rentang .51 hingga .70), dan korelasi antara well-being dan neuroticism tergolong sedang/cukup kuat (rentang .31 hingga .50).\nHasil uji korelasi umumnya dilaporkan dalam bentuk tabel, jika peneliti melakukan uji korelasi beberapa variabel sekaligus, atau dalam bentuk kalimat naratif. Pelaporan hasil uji korelasi dengan menggunakan tabel dan narasi merujuk kepada gaya penulisan Publication Manual of the APA edisi ke-7. Berikut adalah contoh pelaporan hasil uji korelasi menggunakan tabel (Tabel 25.1).\n\n\n\nTabel 25.1: Koefisien korelasi variabel penelitian (N = 267)\n\n\n\n\n\n\n\n1\n2\n3\n\n\n\n\n1.\nWll-being\n-\n\n\n\n\n2.\nLearning engagement\n.669**\n-\n\n\n\n3.\nNeuroticism\n-.396**\n-.384**\n-\n\n\n4.\nOpennes to experience\n.119\n1.89**\n-.128\n\n\n\n\n\n\nCatatan: *p &lt; .05, **p &lt; .01, ***p &lt; .001\nPelaporan hasil uji korelasi dalam bentuk naratif perlu mencantumkan beberapa unsur penting, yaitu: jenis uji korelasi yang digunakan (Pearson correlation – r, atau Spearman correlation – rs), degree of freedom (n-2), nilai signifikansi, arah dan besaran korelasi. Format penulisannya adalah:\nr(df) = “koefisien korelasi”, “p-value”\nContoh:\nTerdapat hubungan positif yang sangat kuat antara learning engagment dengan well-being pada mahasiswa, rs(265) = .669, p &lt;.001.\nFormulasi dan redaksi kalimat dalam menyampaikan hasil korelasi dapat disesuaikan dengan gaya bahasa peneliti, dengan memastikan bahwa seluruh unsur penting tetap disertakan dalam pelaporan. Hasil uji korelasi dapat dibuat dalam bentuk narasi seperti berikut:\n“Hasil uji korelasi Pearson menunjukkan bahwa terdapat hubungan positif yang sangat kuat antara learning engagement dengan well-being pada mahasiswa (rs(265) = .669, p &lt;.001). Selain itu, semakin tinggi karakteristik kepribadian neuroticism yang dimiliki individu, semakin rendah well-being yang dimiliki. Korelasi antara kedua variabel tergolong sedang (rs(265) = -.396, p &lt;.001). Sementara itu, karakteristik kepribadian opennes to experiences tidak berkorelasi dengan well-being individu (rs(265) = .119, p = .052).”",
    "crumbs": [
      "ANALISIS KORELASI",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Asumsi-asumsi Korelasi, Interpretasi, dan Penulisan Hasil Analisis</span>"
    ]
  },
  {
    "objectID": "7_latihan.html",
    "href": "7_latihan.html",
    "title": "Soal Latihan",
    "section": "",
    "text": "Penilaian mengenai hasil belajar merupakan bagian penting dalam sebuah proses pembelajaran. Ujilah pengetahuan dan pemahaman Anda mengenai materi Bagian 7 ini dengan menjawab sejumlah pertanyaan di bawah ini:",
    "crumbs": [
      "ANALISIS KORELASI",
      "Soal Latihan"
    ]
  }
]